{"./":{"url":"./","title":"前言","keywords":"","body":" Kubernetes 简介 基本概念 架构设计 集群监控仪表盘 kubectl namespace 集群安装部署 使用 kubeadm 部署 kubernetes(CRI 使用 containerd) 在 Docker Desktop 使用 一步步部署 kubernetes 集群 部署 Dashboard Etcd 简介 安装 集群 使用 etcdctl 批量调度 Volcano Kueue Docker Docker 简介 什么是 Docker 为什么要用 Docker 基本概念 镜像 容器 仓库 安装 Docker Ubuntu Debian Fedora CentOS Raspberry Pi Linux 离线安装 macOS Windows 10 镜像加速器 开启实验特性 操作镜像 获取镜像 列出镜像 删除本地镜像 利用 commit 理解镜像构成 使用 Dockerfile 定制镜像 Dockerfile 指令详解 COPY 复制文件 ADD 更高级的复制文件 CMD 容器启动命令 ENTRYPOINT 入口点 ENV 设置环境变量 ARG 构建参数 VOLUME 定义匿名卷 EXPOSE 暴露端口 WORKDIR 指定工作目录 USER 指定当前用户 HEALTHCHECK 健康检查 ONBUILD 为他人作嫁衣裳 LABEL 为镜像添加元数据 SHELL 指令 参考文档 Dockerfile 多阶段构建 实战多阶段构建 Laravel 镜像 构建多种系统架构支持的 Docker 镜像 其它制作镜像的方式 实现原理 操作容器 启动 守护态运行 终止 进入容器 导出和导入 删除 访问仓库 Docker Hub 私有仓库 私有仓库高级配置 Nexus 3 数据管理 数据卷 挂载主机目录 使用网络 外部访问容器 容器互联 配置 DNS 高级网络配置 快速配置指南 容器访问控制 端口映射实现 配置 docker0 网桥 自定义网桥 工具和示例 编辑网络配置文件 实例：创建一个点到点连接 Docker Buildx BuildKit 使用 buildx 构建镜像 使用 buildx 构建多种系统架构支持的 Docker 镜像 Docker Compose 简介 Compose v2 安装与卸载 使用 命令说明 Compose 模板文件 实战 Django 实战 Rails 实战 WordPress 实战 LNMP 安全 内核命名空间 控制组 服务端防护 内核能力机制 其它安全特性 总结 底层实现 基本架构 命名空间 控制组 联合文件系统 容器格式 网络 实战案例 - 操作系统 Busybox Alpine Debian Ubuntu CentOS Fedora 本章小结 附录 附录一：常见问题总结 附录二：热门镜像介绍 Ubuntu CentOS Nginx PHP Node.js MySQL WordPress MongoDB Redis Minio 附录三：Docker 命令查询 客户端命令 - docker 服务端命令 - dockerd 附录四：Dockerfile 最佳实践 附录五：如何调试 Docker 附录六：资源链接 CI/CD GitHub Actions Drone 部署 Drone GitHub 数据库 PostgreSQL 日志设置 备份/恢复 WAL-G Copyright © Zhenhai Gao 2021 all right reserved发布时间： 2024-06-10 23:04:45 "},"kubernetes/":{"url":"kubernetes/","title":"Kubernetes","keywords":"","body":"KubernetesKubernetes Kubernetes 是 Google 团队发起并维护的基于 Docker 的开源容器集群管理系统，它不仅支持常见的云平台，而且支持内部数据中心。 建于 Docker 之上的 Kubernetes 可以构建一个容器的调度服务，其目的是让用户透过 Kubernetes 集群来进行云端容器集群的管理，而无需用户进行复杂的设置工作。系统会自动选取合适的工作节点来执行具体的容器集群调度处理工作。其核心概念是 Container Pod。一个 Pod 由一组工作于同一物理工作节点的容器构成。这些组容器拥有相同的网络命名空间、IP以及存储配额，也可以根据实际情况对每一个 Pod 进行端口映射。此外，Kubernetes 工作节点会由主系统进行管理，节点包含了能够运行 Docker 容器所用到的服务。 本章将分为 5 节介绍 Kubernetes，包括 项目简介 快速入门 基本概念 实践例子 架构分析等高级话题 Copyright © Zhenhai Gao 2021 all right reserved发布时间： 2024-06-10 23:03:15 "},"kubernetes/introduce.html":{"url":"kubernetes/introduce.html","title":"简介","keywords":"","body":"项目简介项目简介 Kubernetes 是 Google 团队发起的开源项目，它的目标是管理跨多个主机的容器，提供基本的部署，维护以及应用伸缩，主要实现语言为 Go 语言。Kubernetes 是： 易学：轻量级，简单，容易理解 便携：支持公有云，私有云，混合云，以及多种云平台 可拓展：模块化，可插拔，支持钩子，可任意组合 自修复：自动重调度，自动重启，自动复制 Kubernetes 构建于 Google 数十年经验，一大半来源于 Google 生产环境规模的经验。结合了社区最佳的想法和实践。 在分布式系统中，部署，调度，伸缩一直是最为重要的也最为基础的功能。Kubernetes 就是希望解决这一序列问题的。 Kubernetes 目前在GitHub进行维护。 Kubernetes 能够运行在任何地方！ 虽然 Kubernetes 最初是为 GCE 定制的，但是在后续版本中陆续增加了其他云平台的支持，以及本地数据中心的支持。 Copyright © Zhenhai Gao 2021 all right reserved发布时间： 2024-06-10 23:03:15 "},"kubernetes/basic-concepts/":{"url":"kubernetes/basic-concepts/","title":"基本概念","keywords":"","body":"基本概念节点容器状态节点管理节点控制容器组容器组设计的初衷资源共享和通信容器组管理容器组的使用替代方案容器组的生命状态容器组生命周期Replication Controllers服务卷标签接口权限web界面命令行操作基本概念 节点（Node）：一个节点是一个运行 Kubernetes 中的主机。 容器组（Pod）：一个 Pod 对应于由若干容器组成的一个容器组，同个组内的容器共享一个存储卷(volume)。 容器组生命周期（pos-states）：包含所有容器状态集合，包括容器组状态类型，容器组生命周期，事件，重启策略，以及 replication controllers。 Replication Controllers：主要负责指定数量的 pod 在同一时间一起运行。 服务（services）：一个 Kubernetes 服务是容器组逻辑的高级抽象，同时也对外提供访问容器组的策略。 卷（volumes）：一个卷就是一个目录，容器对其有访问权限。 标签（labels）：标签是用来连接一组对象的，比如容器组。标签可以被用来组织和选择子对象。 接口权限（accessing_the_api）：端口，IP 地址和代理的防火墙规则。 web 界面（ux）：用户可以通过 web 界面操作 Kubernetes。 命令行操作（cli）：kubectl命令。 节点 在 Kubernetes 中，节点是实际工作的点，节点可以是虚拟机或者物理机器，依赖于一个集群环境。每个节点都有一些必要的服务以运行容器组，并且它们都可以通过主节点来管理。必要服务包括 Docker，kubelet 和代理服务。 容器状态 容器状态用来描述节点的当前状态。现在，其中包含三个信息： 主机IP 主机 IP 需要云平台来查询，Kubernetes 把它作为状态的一部分来保存。如果 Kubernetes 没有运行在云平台上，节点 ID 就是必需的。IP 地址可以变化，并且可以包含多种类型的 IP 地址，如公共 IP，私有 IP，动态 IP，ipv6 等等。 节点周期 通常来说节点有 Pending，Running，Terminated 三个周期，如果 Kubernetes 发现了一个节点并且其可用，那么 Kubernetes 就把它标记为 Pending。然后在某个时刻，Kubernetes 将会标记其为 Running。节点的结束周期称为 Terminated。一个已经 Terminated 的节点不会接受和调度任何请求，并且已经在其上运行的容器组也会删除。 节点状态 节点的状态主要是用来描述处于 Running 的节点。当前可用的有 NodeReachable 和 NodeReady。以后可能会增加其他状态。NodeReachable 表示集群可达。NodeReady 表示 kubelet 返回 Status Ok 并且 HTTP 状态检查健康。 节点管理 节点并非 Kubernetes 创建，而是由云平台创建，或者就是物理机器、虚拟机。在 Kubernetes 中，节点仅仅是一条记录，节点创建之后，Kubernetes 会检查其是否可用。在 Kubernetes 中，节点用如下结构保存： { \"id\": \"10.1.2.3\", \"kind\": \"Minion\", \"apiVersion\": \"v1beta1\", \"resources\": { \"capacity\": { \"cpu\": 1000, \"memory\": 1073741824 }, }, \"labels\": { \"name\": \"my-first-k8s-node\", }, } Kubernetes 校验节点可用依赖于 ID。在当前的版本中，有两个接口可以用来管理节点：节点控制和 Kube 管理。 节点控制 在 Kubernetes 主节点中，节点控制器是用来管理节点的组件。主要包含： 集群范围内节点同步 单节点生命周期管理 节点控制有一个同步轮寻，主要监听所有云平台的虚拟实例，会根据节点状态创建和删除。可以通过 --node_sync_period标志来控制该轮寻。如果一个实例已经创建，节点控制将会为其创建一个结构。同样的，如果一个节点被删除，节点控制也会删除该结构。在 Kubernetes 启动时可用通过 --machines标记来显示指定节点。同样可以使用 kubectl 来一条一条的添加节点，两者是相同的。通过设置 --sync_nodes=false标记来禁止集群之间的节点同步，你也可以使用 api/kubectl 命令行来增删节点。 容器组 在 Kubernetes 中，使用的最小单位是容器组，容器组是创建，调度，管理的最小单位。 一个容器组使用相同的 Docker 容器并共享卷（挂载点）。一个容器组是一个特定应用的打包集合，包含一个或多个容器。 和运行的容器类似，一个容器组被认为只有很短的运行周期。容器组被调度到一组节点运行，直到容器的生命周期结束或者其被删除。如果节点死掉，运行在其上的容器组将会被删除而不是重新调度。（也许在将来的版本中会添加容器组的移动）。 容器组设计的初衷 资源共享和通信 容器组主要是为了数据共享和它们之间的通信。 在一个容器组中，容器都使用相同的网络地址和端口，可以通过本地网络来相互通信。每个容器组都有独立的 IP，可用通过网络来和其他物理主机或者容器通信。 容器组有一组存储卷（挂载点），主要是为了让容器在重启之后可以不丢失数据。 容器组管理 容器组是一个应用管理和部署的高层次抽象，同时也是一组容器的接口。容器组是部署、水平放缩的最小单位。 容器组的使用 容器组可以通过组合来构建复杂的应用，其本来的意义包含： 内容管理，文件和数据加载以及本地缓存管理等。 日志和检查点备份，压缩，快照等。 监听数据变化，跟踪日志，日志和监控代理，消息发布等。 代理，网桥 控制器，管理，配置以及更新 替代方案 为什么不在一个单一的容器里运行多个程序？ 1.透明化。为了使容器组中的容器保持一致的基础设施和服务，比如进程管理和资源监控。这样设计是为了用户的便利性。 2.解偶软件之间的依赖。每个容器都可能重新构建和发布，Kubernetes 必须支持热发布和热更新（将来）。 3.方便使用。用户不必运行独立的程序管理，也不用担心每个应用程序的退出状态。 4.高效。考虑到基础设施有更多的职责，容器必须要轻量化。 容器组的生命状态 包括若干状态值：pending、running、succeeded、failed。 pending 容器组已经被节点接受，但有一个或多个容器还没有运行起来。这将包含某些节点正在下载镜像的时间，这种情形会依赖于网络情况。 running 容器组已经被调度到节点，并且所有的容器都已经启动。至少有一个容器处于运行状态（或者处于重启状态）。 succeeded 所有的容器都正常退出。 failed 容器组中所有容器都意外中断了。 容器组生命周期 通常来说，如果容器组被创建了就不会自动销毁，除非被某种行为触发，而触发此种情况可能是人为，或者复制控制器所为。唯一例外的是容器组由 succeeded 状态成功退出，或者在一定时间内重试多次依然失败。 如果某个节点死掉或者不能连接，那么节点控制器将会标记其上的容器组的状态为 failed。 举例如下。 容器组状态 running，有 1 容器，容器正常退出 记录完成事件 如果重启策略为： 始终：重启容器，容器组保持 running 失败时：容器组变为 succeeded 从不：容器组变为 succeeded 容器组状态 running，有1容器，容器异常退出 记录失败事件 如果重启策略为： 始终：重启容器，容器组保持 running 失败时：重启容器，容器组保持 running 从不：容器组变为 failed 容器组状态 running，有2容器，有1容器异常退出 记录失败事件 如果重启策略为： 始终：重启容器，容器组保持 running 失败时：重启容器，容器组保持 running 从不：容器组保持 running 当有2容器退出 记录失败事件 如果重启策略为： 始终：重启容器，容器组保持 running 失败时：重启容器，容器组保持 running 从不：容器组变为 failed 容器组状态 running，容器内存不足 标记容器错误中断 记录内存不足事件 如果重启策略为： 始终：重启容器，容器组保持 running 失败时：重启容器，容器组保持 running 从不：记录错误事件，容器组变为 failed 容器组状态 running，一块磁盘死掉 杀死所有容器 记录事件 容器组变为 failed 如果容器组运行在一个控制器下，容器组将会在其他地方重新创建 容器组状态 running，对应的节点段溢出 节点控制器等到超时 节点控制器标记容器组 failed 如果容器组运行在一个控制器下，容器组将会在其他地方重新创建 Replication Controllers 服务 卷 标签 接口权限 web界面 命令行操作 Copyright © Zhenhai Gao 2021 all right reserved发布时间： 2024-06-10 23:03:15 "},"kubernetes/architecture-design.html":{"url":"kubernetes/architecture-design.html","title":"架构设计","keywords":"","body":"基本架构基本考虑运行原理控制平面主节点服务Etcd工作节点基本架构 任何优秀的项目都离不开优秀的架构设计。本小节将介绍 Kubernetes 在架构方面的设计考虑。 基本考虑 如果让我们自己从头设计一套容器管理平台，有如下几个方面是很容易想到的： 分布式架构，保证扩展性； 逻辑集中式的控制平面 + 物理分布式的运行平面； 一套资源调度系统，管理哪个容器该分配到哪个节点上； 一套对容器内服务进行抽象和 HA 的系统。 运行原理 下面这张图完整展示了 Kubernetes 的运行原理。 可见，Kubernetes 首先是一套分布式系统，由多个节点组成，节点分为两类：一类是属于管理平面的主节点/控制节点（Master Node）；一类是属于运行平面的工作节点（Worker Node）。 显然，复杂的工作肯定都交给控制节点去做了，工作节点负责提供稳定的操作接口和能力抽象即可。 从这张图上，我们没有能发现 Kubernetes 中对于控制平面的分布式实现，但是由于数据后端自身就是一套分布式的数据库 Etcd，因此可以很容易扩展到分布式实现。 控制平面 主节点服务 主节点上需要提供如下的管理服务： apiserver 是整个系统的对外接口，提供一套 RESTful 的 Kubernetes API，供客户端和其它组件调用； scheduler 负责对资源进行调度，分配某个 pod 到某个节点上。是 pluggable 的，意味着很容易选择其它实现方式； controller-manager 负责管理控制器，包括 endpoint-controller（刷新服务和 pod 的关联信息）和 replication-controller（维护某个 pod 的复制为配置的数值）。 Etcd 这里 Etcd 即作为数据后端，又作为消息中间件。 通过 Etcd 来存储所有的主节点上的状态信息，很容易实现主节点的分布式扩展。 组件可以自动的去侦测 Etcd 中的数值变化来获得通知，并且获得更新后的数据来执行相应的操作。 工作节点 kubelet 是工作节点执行操作的 agent，负责具体的容器生命周期管理，根据从数据库中获取的信息来管理容器，并上报 pod 运行状态等； kube-proxy 是一个简单的网络访问代理，同时也是一个 Load Balancer。它负责将访问到某个服务的请求具体分配给工作节点上的 Pod（同一类标签）。 Copyright © Zhenhai Gao 2021 all right reserved发布时间： 2024-06-10 23:03:15 "},"kubernetes/dashboard/":{"url":"kubernetes/dashboard/","title":"集群监控仪表盘","keywords":"","body":"dashboard on kubernetes apiVersion: v1 kind: Namespace metadata: name: kubernetes-dashboard --- apiVersion: v1 kind: ServiceAccount metadata: labels: k8s-app: kubernetes-dashboard name: kubernetes-dashboard namespace: kubernetes-dashboard --- kind: Service apiVersion: v1 metadata: labels: k8s-app: kubernetes-dashboard name: kubernetes-dashboard namespace: kubernetes-dashboard spec: type: NodePort ports: - port: 443 targetPort: 8443 nodePort: 31730 selector: k8s-app: kubernetes-dashboard --- apiVersion: v1 kind: Secret metadata: labels: k8s-app: kubernetes-dashboard name: kubernetes-dashboard-certs namespace: kubernetes-dashboard type: Opaque --- apiVersion: v1 kind: Secret metadata: labels: k8s-app: kubernetes-dashboard name: kubernetes-dashboard-csrf namespace: kubernetes-dashboard type: Opaque data: csrf: \"\" --- apiVersion: v1 kind: Secret metadata: labels: k8s-app: kubernetes-dashboard name: kubernetes-dashboard-key-holder namespace: kubernetes-dashboard type: Opaque --- kind: ConfigMap apiVersion: v1 metadata: labels: k8s-app: kubernetes-dashboard name: kubernetes-dashboard-settings namespace: kubernetes-dashboard --- kind: Role apiVersion: rbac.authorization.k8s.io/v1 metadata: labels: k8s-app: kubernetes-dashboard name: kubernetes-dashboard namespace: kubernetes-dashboard rules: # Allow Dashboard to get, update and delete Dashboard exclusive secrets. - apiGroups: [\"\"] resources: [\"secrets\"] resourceNames: [\"kubernetes-dashboard-key-holder\", \"kubernetes-dashboard-certs\", \"kubernetes-dashboard-csrf\"] verbs: [\"get\", \"update\", \"delete\"] # Allow Dashboard to get and update 'kubernetes-dashboard-settings' config map. - apiGroups: [\"\"] resources: [\"configmaps\"] resourceNames: [\"kubernetes-dashboard-settings\"] verbs: [\"get\", \"update\"] # Allow Dashboard to get metrics. - apiGroups: [\"\"] resources: [\"services\"] resourceNames: [\"heapster\", \"dashboard-metrics-scraper\"] verbs: [\"proxy\"] - apiGroups: [\"\"] resources: [\"services/proxy\"] resourceNames: [\"heapster\", \"http:heapster:\", \"https:heapster:\", \"dashboard-metrics-scraper\", \"http:dashboard-metrics-scraper\"] verbs: [\"get\"] - apiGroups: - policy - extensions resourceNames: - system resources: - podsecuritypolicies verbs: - use --- kind: ClusterRole apiVersion: rbac.authorization.k8s.io/v1 metadata: labels: k8s-app: kubernetes-dashboard name: kubernetes-dashboard rules: # Allow Metrics Scraper to get metrics from the Metrics server - apiGroups: [\"metrics.k8s.io\"] resources: [\"pods\", \"nodes\"] verbs: [\"get\", \"list\", \"watch\"] --- apiVersion: rbac.authorization.k8s.io/v1 kind: RoleBinding metadata: labels: k8s-app: kubernetes-dashboard name: kubernetes-dashboard namespace: kubernetes-dashboard roleRef: apiGroup: rbac.authorization.k8s.io kind: Role name: kubernetes-dashboard subjects: - kind: ServiceAccount name: kubernetes-dashboard namespace: kubernetes-dashboard --- apiVersion: rbac.authorization.k8s.io/v1 kind: ClusterRoleBinding metadata: name: kubernetes-dashboard roleRef: apiGroup: rbac.authorization.k8s.io kind: ClusterRole name: kubernetes-dashboard subjects: - kind: ServiceAccount name: kubernetes-dashboard namespace: kubernetes-dashboard --- kind: Deployment apiVersion: apps/v1 metadata: labels: k8s-app: kubernetes-dashboard name: kubernetes-dashboard namespace: kubernetes-dashboard spec: replicas: 1 revisionHistoryLimit: 10 selector: matchLabels: k8s-app: kubernetes-dashboard template: metadata: labels: k8s-app: kubernetes-dashboard spec: securityContext: seccompProfile: type: RuntimeDefault containers: - name: kubernetes-dashboard image: kubernetesui/dashboard:v2.7.0 imagePullPolicy: Always ports: - containerPort: 8443 protocol: TCP args: - --auto-generate-certificates - --namespace=kubernetes-dashboard # Uncomment the following line to manually specify Kubernetes API server Host # If not specified, Dashboard will attempt to auto discover the API server and connect # to it. Uncomment only if the default does not work. # - --apiserver-host=http://my-address:port volumeMounts: - name: kubernetes-dashboard-certs mountPath: /certs # Create on-disk volume to store exec logs - mountPath: /tmp name: tmp-volume livenessProbe: httpGet: scheme: HTTPS path: / port: 8443 initialDelaySeconds: 30 timeoutSeconds: 30 securityContext: allowPrivilegeEscalation: false readOnlyRootFilesystem: true runAsUser: 1001 runAsGroup: 2001 volumes: - name: kubernetes-dashboard-certs secret: secretName: kubernetes-dashboard-certs - name: tmp-volume emptyDir: {} serviceAccountName: kubernetes-dashboard nodeSelector: \"kubernetes.io/os\": linux # Comment the following tolerations if Dashboard must not be deployed on master tolerations: - key: node-role.kubernetes.io/master effect: NoSchedule --- kind: Service apiVersion: v1 metadata: labels: k8s-app: dashboard-metrics-scraper name: dashboard-metrics-scraper namespace: kubernetes-dashboard spec: ports: - port: 8000 targetPort: 8000 selector: k8s-app: dashboard-metrics-scraper --- kind: Deployment apiVersion: apps/v1 metadata: labels: k8s-app: dashboard-metrics-scraper name: dashboard-metrics-scraper namespace: kubernetes-dashboard spec: replicas: 1 revisionHistoryLimit: 10 selector: matchLabels: k8s-app: dashboard-metrics-scraper template: metadata: labels: k8s-app: dashboard-metrics-scraper spec: securityContext: seccompProfile: type: RuntimeDefault containers: - name: dashboard-metrics-scraper image: kubernetesui/metrics-scraper:v1.0.8 ports: - containerPort: 8000 protocol: TCP livenessProbe: httpGet: scheme: HTTP path: / port: 8000 initialDelaySeconds: 30 timeoutSeconds: 30 volumeMounts: - mountPath: /tmp name: tmp-volume securityContext: allowPrivilegeEscalation: false readOnlyRootFilesystem: true runAsUser: 1001 runAsGroup: 2001 serviceAccountName: kubernetes-dashboard nodeSelector: \"kubernetes.io/os\": linux # Comment the following tolerations if Dashboard must not be deployed on master tolerations: - key: node-role.kubernetes.io/master effect: NoSchedule volumes: - name: tmp-volume emptyDir: {} Copyright © Zhenhai Gao 2021 all right reserved发布时间： 2024-06-10 23:03:15 "},"kubernetes/kubectl/":{"url":"kubernetes/kubectl/","title":"kubectl","keywords":"","body":"kubectl 使用getdescribecreateupdatedeletelogrolling-updateexecport-forwardproxyrunexposelabelconfigcluster-infoapi-versionsversionhelpkubectl 使用 kubectl 是 Kubernetes 自带的客户端，可以用它来直接操作 Kubernetes。 使用格式有两种： kubectl [flags] kubectl [command] get 显示一个或多个资源 describe 显示资源详情 create 从文件或标准输入创建资源 update 从文件或标准输入更新资源 delete 通过文件名、标准输入、资源名或者 label selector 删除资源 log 输出 pod 中一个容器的日志 rolling-update 对指定的 replication controller 执行滚动升级 exec 在容器内部执行命令 port-forward 将本地端口转发到Pod proxy 为 Kubernetes API server 启动代理服务器 run 在集群中使用指定镜像启动容器 expose 将 replication controller service 或 pod 暴露为新的 kubernetes service label 更新资源的 label config 修改 kubernetes 配置文件 cluster-info 显示集群信息 api-versions 以 \"组/版本\" 的格式输出服务端支持的 API 版本 version 输出服务端和客户端的版本信息 help 显示各个命令的帮助信息 Copyright © Zhenhai Gao 2021 all right reserved发布时间： 2024-06-10 23:03:15 "},"kubernetes/kubectl/namespace/":{"url":"kubernetes/kubectl/namespace/","title":"namespace","keywords":"","body":"kubectl 操作 namespace强制删除 namespacekubectl 操作 namespace 强制删除 namespace 通常我们删除 namespace 之后会经常卡在 Terminating 的状态，需要我们额外处理一下 namespace 中的 spec.finalizers 字段 [~]$ kubectl proxy [~]$ kubectl get namespace postgres-ns -o json | jq '.spec = {\"finalizers\":[]}' > ns.json [~]$ curl -k -X PUT -H \"Content-Type: application/json\" --data-binary @ns.json 127.0.0.1:8001/api/v1/namespaces/postgres-ns/finalize Copyright © Zhenhai Gao 2021 all right reserved发布时间： 2024-06-10 23:03:15 "},"kubernetes/install/":{"url":"kubernetes/install/","title":"集群安装部署","keywords":"","body":"部署 Kubernetes部署 Kubernetes 目前，Kubernetes 支持在多种环境下使用，包括本地主机（Ubuntu、Debian、CentOS、Fedora 等）、云服务（腾讯云、阿里云、百度云 等）。 你可以使用以下几种方式部署 Kubernetes： kubeadm docker-desktop k3s 接下来的小节会对以上几种方式进行详细介绍。 Copyright © Zhenhai Gao 2021 all right reserved发布时间： 2024-06-10 23:03:15 "},"kubernetes/install/kubeadm.html":{"url":"kubernetes/install/kubeadm.html","title":"使用 kubeadm 部署 kubernetes(CRI 使用 containerd)","keywords":"","body":"使用 kubeadm 部署 kubernetes(CRI 使用 containerd)安装 containerd配置 containerd安装 kubelet kubeadm kubectl cri-tools kubernetes-cniUbuntu/DebianCentOS/Fedora修改内核的运行参数配置 kubelet修改 kubelet.service部署masternode 工作节点查看服务主节点服务工作节点服务其它服务使用部署 CNIflannelmaster 节点默认不能运行 pod参考文档使用 kubeadm 部署 kubernetes(CRI 使用 containerd) kubeadm 提供了 kubeadm init 以及 kubeadm join 这两个命令作为快速创建 kubernetes 集群的最佳实践。 安装 containerd 参考 安装 Docker 一节添加 apt/yum 源，之后执行如下命令。 # debian 系 $ sudo apt install containerd.io # rhel 系 $ sudo yum install containerd.io 配置 containerd 新建 /etc/systemd/system/cri-containerd.service 文件 [Unit] Description=containerd container runtime for kubernetes Documentation=https://containerd.io After=network.target local-fs.target [Service] ExecStartPre=-/sbin/modprobe overlay ExecStart=/usr/bin/containerd --config //etc/cri-containerd/config.toml Type=notify Delegate=yes KillMode=process Restart=always RestartSec=5 # Having non-zero Limit*s causes performance problems due to accounting overhead # in the kernel. We recommend using cgroups to do container-local accounting. LimitNPROC=infinity LimitCORE=infinity LimitNOFILE=infinity # Comment TasksMax if your systemd version does not supports it. # Only systemd 226 and above support this version. TasksMax=infinity OOMScoreAdjust=-999 [Install] WantedBy=multi-user.target 新建 /etc/cri-containerd/config.toml containerd 配置文件 version = 2 # persistent data location root = \"/var/lib/cri-containerd\" # runtime state information state = \"/run/cri-containerd\" plugin_dir = \"\" disabled_plugins = [] required_plugins = [] # set containerd's OOM score oom_score = 0 [grpc] address = \"/run/cri-containerd/cri-containerd.sock\" tcp_address = \"\" tcp_tls_cert = \"\" tcp_tls_key = \"\" # socket uid uid = 0 # socket gid gid = 0 max_recv_message_size = 16777216 max_send_message_size = 16777216 [debug] address = \"\" format = \"json\" uid = 0 gid = 0 level = \"\" [metrics] address = \"127.0.0.1:1338\" grpc_histogram = false [cgroup] path = \"\" [timeouts] \"io.containerd.timeout.shim.cleanup\" = \"5s\" \"io.containerd.timeout.shim.load\" = \"5s\" \"io.containerd.timeout.shim.shutdown\" = \"3s\" \"io.containerd.timeout.task.state\" = \"2s\" [plugins] [plugins.\"io.containerd.gc.v1.scheduler\"] pause_threshold = 0.02 deletion_threshold = 0 mutation_threshold = 100 schedule_delay = \"0s\" startup_delay = \"100ms\" [plugins.\"io.containerd.grpc.v1.cri\"] disable_tcp_service = true stream_server_address = \"127.0.0.1\" stream_server_port = \"0\" stream_idle_timeout = \"4h0m0s\" enable_selinux = false selinux_category_range = 1024 sandbox_image = \"registry.cn-hangzhou.aliyuncs.com/google_containers/pause:3.5\" stats_collect_period = 10 # systemd_cgroup = false enable_tls_streaming = false max_container_log_line_size = 16384 disable_cgroup = false disable_apparmor = false restrict_oom_score_adj = false max_concurrent_downloads = 3 disable_proc_mount = false unset_seccomp_profile = \"\" tolerate_missing_hugetlb_controller = true disable_hugetlb_controller = true ignore_image_defined_volumes = false [plugins.\"io.containerd.grpc.v1.cri\".containerd] snapshotter = \"overlayfs\" default_runtime_name = \"runc\" no_pivot = false disable_snapshot_annotations = false discard_unpacked_layers = false [plugins.\"io.containerd.grpc.v1.cri\".containerd.runtimes] [plugins.\"io.containerd.grpc.v1.cri\".containerd.runtimes.runc] runtime_type = \"io.containerd.runc.v2\" pod_annotations = [] container_annotations = [] privileged_without_host_devices = false base_runtime_spec = \"\" [plugins.\"io.containerd.grpc.v1.cri\".containerd.runtimes.runc.options] # SystemdCgroup enables systemd cgroups. SystemdCgroup = true # BinaryName is the binary name of the runc binary. # BinaryName = \"runc\" # BinaryName = \"crun\" # NoPivotRoot disables pivot root when creating a container. # NoPivotRoot = false # NoNewKeyring disables new keyring for the container. # NoNewKeyring = false # ShimCgroup places the shim in a cgroup. # ShimCgroup = \"\" # IoUid sets the I/O's pipes uid. # IoUid = 0 # IoGid sets the I/O's pipes gid. # IoGid = 0 # Root is the runc root directory. Root = \"\" # CriuPath is the criu binary path. # CriuPath = \"\" # CriuImagePath is the criu image path # CriuImagePath = \"\" # CriuWorkPath is the criu work path. # CriuWorkPath = \"\" [plugins.\"io.containerd.grpc.v1.cri\".cni] bin_dir = \"/opt/cni/bin\" conf_dir = \"/etc/cni/net.d\" max_conf_num = 1 conf_template = \"\" [plugins.\"io.containerd.grpc.v1.cri\".registry] config_path = \"/etc/cri-containerd/certs.d\" [plugins.\"io.containerd.grpc.v1.cri\".registry.headers] # Foo = [\"bar\"] [plugins.\"io.containerd.grpc.v1.cri\".image_decryption] key_model = \"\" [plugins.\"io.containerd.grpc.v1.cri\".x509_key_pair_streaming] tls_cert_file = \"\" tls_key_file = \"\" [plugins.\"io.containerd.internal.v1.opt\"] path = \"/opt/cri-containerd\" [plugins.\"io.containerd.internal.v1.restart\"] interval = \"10s\" [plugins.\"io.containerd.metadata.v1.bolt\"] content_sharing_policy = \"shared\" [plugins.\"io.containerd.monitor.v1.cgroups\"] no_prometheus = false [plugins.\"io.containerd.runtime.v2.task\"] platforms = [\"linux/amd64\"] [plugins.\"io.containerd.service.v1.diff-service\"] default = [\"walking\"] [plugins.\"io.containerd.snapshotter.v1.devmapper\"] root_path = \"\" pool_name = \"\" base_image_size = \"\" async_remove = false 安装 kubelet kubeadm kubectl cri-tools kubernetes-cni Ubuntu/Debian $ apt-get update && apt-get install -y apt-transport-https $ curl https://mirrors.aliyun.com/kubernetes/apt/doc/apt-key.gpg | apt-key add - $ cat CentOS/Fedora $ cat 修改内核的运行参数 $ cat 配置 kubelet 修改 kubelet.service /etc/systemd/system/kubelet.service.d/10-proxy-ipvs.conf 写入以下内容 # 启用 ipvs 相关内核模块 [Service] ExecStartPre=-/sbin/modprobe ip_vs ExecStartPre=-/sbin/modprobe ip_vs_rr ExecStartPre=-/sbin/modprobe ip_vs_wrr ExecStartPre=-/sbin/modprobe ip_vs_sh 执行以下命令应用配置。 $ sudo systemctl daemon-reload 部署 master $ systemctl enable cri-containerd $ systemctl start cri-containerd $ sudo kubeadm init \\ --image-repository registry.cn-hangzhou.aliyuncs.com/google_containers \\ --pod-network-cidr 10.244.0.0/16 \\ --cri-socket /run/cri-containerd/cri-containerd.sock \\ --v 5 \\ --ignore-preflight-errors=all --pod-network-cidr 10.244.0.0/16 参数与后续 CNI 插件有关，这里以 flannel 为例，若后续部署其他类型的网络插件请更改此参数。 执行可能出现错误，例如缺少依赖包，根据提示安装即可。 执行成功会输出 ... [addons] Applied essential addon: CoreDNS I1116 12:35:13.270407 86677 request.go:538] Throttling request took 181.409184ms, request: POST:https://192.168.199.100:6443/api/v1/namespaces/kube-system/serviceaccounts I1116 12:35:13.470292 86677 request.go:538] Throttling request took 186.088112ms, request: POST:https://192.168.199.100:6443/api/v1/namespaces/kube-system/configmaps [addons] Applied essential addon: kube-proxy Your Kubernetes control-plane has initialized successfully! To start using your cluster, you need to run the following as a regular user: mkdir -p $HOME/.kube sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config sudo chown $(id -u):$(id -g) $HOME/.kube/config You should now deploy a pod network to the cluster. Run \"kubectl apply -f [podnetwork].yaml\" with one of the options listed at: https://kubernetes.io/docs/concepts/cluster-administration/addons/ Then you can join any number of worker nodes by running the following on each as root: kubeadm join 192.168.199.100:6443 --token cz81zt.orsy9gm9v649e5lf \\ --discovery-token-ca-cert-hash sha256:5edb316fd0d8ea2792cba15cdf1c899a366f147aa03cba52d4e5c5884ad836fe node 工作节点 在 另一主机 重复 部署 小节以前的步骤，安装配置好 kubelet。根据提示，加入到集群。 $ systemctl enable cri-containerd $ systemctl start cri-containerd $ kubeadm join 192.168.199.100:6443 \\ --token cz81zt.orsy9gm9v649e5lf \\ --discovery-token-ca-cert-hash sha256:5edb316fd0d8ea2792cba15cdf1c899a366f147aa03cba52d4e5c5884ad836fe \\ --cri-socket /run/cri-containerd/cri-containerd.sock 查看服务 所有服务启动后，通过 crictl 查看本地实际运行的容器。这些服务大概分为三类：主节点服务、工作节点服务和其它服务。 CONTAINER_RUNTIME_ENDPOINT=/run/cri-containerd/cri-containerd.sock crictl ps -a 主节点服务 apiserver 是整个系统的对外接口，提供 RESTful 方式供客户端和其它组件调用； scheduler 负责对资源进行调度，分配某个 pod 到某个节点上； controller-manager 负责管理控制器，包括 endpoint-controller（刷新服务和 pod 的关联信息）和 replication-controller（维护某个 pod 的复制为配置的数值）。 工作节点服务 proxy 为 pod 上的服务提供访问的代理。 其它服务 Etcd 是所有状态的存储数据库； 使用 将 /etc/kubernetes/admin.conf 复制到 ~/.kube/config 执行 $ kubectl get all -A 查看启动的服务。 由于未部署 CNI 插件，CoreDNS 未正常启动。如何使用 Kubernetes，请参考后续章节。 部署 CNI 这里以 flannel 为例进行介绍。 flannel 检查 podCIDR 设置 $ kubectl get node -o yaml | grep CIDR # 输出 podCIDR: 10.244.0.0/16 podCIDRs: $ kubectl apply -f https://raw.githubusercontent.com/coreos/flannel/v0.11.0/Documentation/kube-flannel.yml master 节点默认不能运行 pod 如果用 kubeadm 部署一个单节点集群，默认情况下无法使用，请执行以下命令解除限制 $ kubectl taint nodes --all node-role.kubernetes.io/master- # 恢复默认值 # $ kubectl taint nodes NODE_NAME node-role.kubernetes.io/master=true:NoSchedule 参考文档 官方文档 Container runtimes Copyright © Zhenhai Gao 2021 all right reserved发布时间： 2024-06-10 23:03:15 "},"kubernetes/install/docker-desktop.html":{"url":"kubernetes/install/docker-desktop.html","title":"在 Docker Desktop 使用","keywords":"","body":"Docker Desktop 启用 Kubernetes获取 k8s.gcr.io 镜像启用 Kubernetes测试Docker Desktop 启用 Kubernetes 使用 Docker Desktop 可以很方便的启用 Kubernetes，由于国内获取不到 k8s.gcr.io 镜像，我们必须首先解决这一问题。 获取 k8s.gcr.io 镜像 由于国内拉取不到 k8s.gcr.io 镜像，我们可以使用开源项目 AliyunContainerService/k8s-for-docker-desktop 来获取所需的镜像。 启用 Kubernetes 在 Docker Desktop 设置页面，点击 Kubernetes，选择 Enable Kubernetes，稍等片刻，看到左下方 Kubernetes 变为 running，Kubernetes 启动成功。 测试 $ kubectl version 如果正常输出信息，则证明 Kubernetes 成功启动。 Copyright © Zhenhai Gao 2021 all right reserved发布时间： 2024-06-10 23:03:15 "},"kubernetes/install/systemd.html":{"url":"kubernetes/install/systemd.html","title":"一步步部署 kubernetes 集群","keywords":"","body":"一步步部署 kubernetes 集群一步步部署 kubernetes 集群 可以参考 opsnull/follow-me-install-kubernetes-cluster 项目一步步部署 kubernetes 集群。 Copyright © Zhenhai Gao 2021 all right reserved发布时间： 2024-06-10 23:03:15 "},"kubernetes/install/dashboard.html":{"url":"kubernetes/install/dashboard.html","title":"部署 Dashboard","keywords":"","body":"Kubernetes Dashboard部署访问登录参考文档Kubernetes Dashboard Kubernetes Dashboard 是基于网页的 Kubernetes 用户界面。 部署 执行以下命令即可部署 Dashboard： kubectl apply -f https://raw.githubusercontent.com/kubernetes/dashboard/v2.0.0/aio/deploy/recommended.yaml 访问 通过命令行代理访问，执行以下命令： $ kubectl proxy 到 http://localhost:8001/api/v1/namespaces/kubernetes-dashboard/services/https:kubernetes-dashboard:/proxy/ 即可访问。 登录 目前，Dashboard 仅支持使用 Bearer 令牌登录。下面教大家如何创建该令牌： $ kubectl create sa dashboard-admin -n kube-system $ kubectl create clusterrolebinding dashboard-admin --clusterrole=cluster-admin --serviceaccount=kube-system:dashboard-admin $ ADMIN_SECRET=$(kubectl get secrets -n kube-system | grep dashboard-admin | awk '{print $1}') $ DASHBOARD_LOGIN_TOKEN=$(kubectl describe secret -n kube-system ${ADMIN_SECRET} | grep -E '^token' | awk '{print $2}') echo ${DASHBOARD_LOGIN_TOKEN} 将结果粘贴到登录页面，即可登录。 参考文档 官方文档 Copyright © Zhenhai Gao 2021 all right reserved发布时间： 2024-06-10 23:03:15 "},"kubernetes/etcd/":{"url":"kubernetes/etcd/","title":"Etcd","keywords":"","body":"etcdetcd etcd 是 CoreOS 团队发起的一个管理配置信息和服务发现（Service Discovery）的项目，在这一章里面，我们将基于 etcd 3.x 版本介绍该项目的目标，安装和使用，以及实现的技术。 Copyright © Zhenhai Gao 2021 all right reserved发布时间： 2024-06-10 23:03:15 "},"kubernetes/etcd/intro.html":{"url":"kubernetes/etcd/intro.html","title":"简介","keywords":"","body":"什么是 etcd什么是 etcd etcd 是 CoreOS 团队于 2013 年 6 月发起的开源项目，它的目标是构建一个高可用的分布式键值（key-value）数据库，基于 Go 语言实现。我们知道，在分布式系统中，各种服务的配置信息的管理分享，服务的发现是一个很基本同时也是很重要的问题。CoreOS 项目就希望基于 etcd 来解决这一问题。 etcd 目前在 github.com/etcd-io/etcd 进行维护。 受到 Apache ZooKeeper 项目和 doozer 项目的启发，etcd 在设计的时候重点考虑了下面四个要素： 简单：具有定义良好、面向用户的 API (gRPC) 安全：支持 HTTPS 方式的访问 快速：支持并发 10 k/s 的写操作 可靠：支持分布式结构，基于 Raft 的一致性算法 Apache ZooKeeper 是一套知名的分布式系统中进行同步和一致性管理的工具。 doozer 是一个一致性分布式数据库。 Raft 是一套通过选举主节点来实现分布式系统一致性的算法，相比于大名鼎鼎的 Paxos 算法，它的过程更容易被人理解，由 Stanford 大学的 Diego Ongaro 和 John Ousterhout 提出。更多细节可以参考 raftconsensus.github.io。 一般情况下，用户使用 etcd 可以在多个节点上启动多个实例，并添加它们为一个集群。同一个集群中的 etcd 实例将会保持彼此信息的一致性。 Copyright © Zhenhai Gao 2021 all right reserved发布时间： 2024-06-10 23:03:15 "},"kubernetes/etcd/install.html":{"url":"kubernetes/etcd/install.html","title":"安装","keywords":"","body":"安装二进制文件方式下载Docker 镜像方式运行macOS 中运行安装 etcd 基于 Go 语言实现，因此，用户可以从 项目主页 下载源代码自行编译，也可以下载编译好的二进制文件，甚至直接使用制作好的 Docker 镜像文件来体验。 注意：本章节内容基于 etcd 3.4.x 版本 二进制文件方式下载 编译好的二进制文件都在 github.com/etcd-io/etcd/releases 页面，用户可以选择需要的版本，或通过下载工具下载。 例如，使用 curl 工具下载压缩包，并解压。 $ curl -L https://github.com/etcd-io/etcd/releases/download/v3.4.0/etcd-v3.4.0-linux-amd64.tar.gz -o etcd-v3.4.0-linux-amd64.tar.gz # 国内用户可以使用以下方式加快下载 $ curl -L https://download.fastgit.org/etcd-io/etcd/releases/download/v3.4.0/etcd-v3.4.0-linux-amd64.tar.gz -o etcd-v3.4.0-linux-amd64.tar.gz $ tar xzvf etcd-v3.4.0-linux-amd64.tar.gz $ cd etcd-v3.4.0-linux-amd64 解压后，可以看到文件包括 $ ls Documentation README-etcdctl.md README.md READMEv2-etcdctl.md etcd etcdctl 其中 etcd 是服务主文件，etcdctl 是提供给用户的命令客户端，其他文件是支持文档。 下面将 etcd etcdctl 文件放到系统可执行目录（例如 /usr/local/bin/）。 $ sudo cp etcd* /usr/local/bin/ 默认 2379 端口处理客户端的请求，2380 端口用于集群各成员间的通信。启动 etcd 显示类似如下的信息： $ etcd ... 2017-12-03 11:18:34.411579 I | embed: listening for peers on http://localhost:2380 2017-12-03 11:18:34.411938 I | embed: listening for client requests on localhost:2379 此时，可以使用 etcdctl 命令进行测试，设置和获取键值 testkey: \"hello world\"，检查 etcd 服务是否启动成功： $ ETCDCTL_API=3 etcdctl member list 8e9e05c52164694d, started, default, http://localhost:2380, http://localhost:2379 $ ETCDCTL_API=3 etcdctl put testkey \"hello world\" OK $ etcdctl get testkey testkey hello world 说明 etcd 服务已经成功启动了。 Docker 镜像方式运行 镜像名称为 quay.io/coreos/etcd，可以通过下面的命令启动 etcd 服务监听到 2379 和 2380 端口。 $ docker run \\ -p 2379:2379 \\ -p 2380:2380 \\ --mount type=bind,source=/tmp/etcd-data.tmp,destination=/etcd-data \\ --name etcd-gcr-v3.4.0 \\ quay.io/coreos/etcd:v3.4.0 \\ /usr/local/bin/etcd \\ --name s1 \\ --data-dir /etcd-data \\ --listen-client-urls http://0.0.0.0:2379 \\ --advertise-client-urls http://0.0.0.0:2379 \\ --listen-peer-urls http://0.0.0.0:2380 \\ --initial-advertise-peer-urls http://0.0.0.0:2380 \\ --initial-cluster s1=http://0.0.0.0:2380 \\ --initial-cluster-token tkn \\ --initial-cluster-state new \\ --log-level info \\ --logger zap \\ --log-outputs stderr 打开新的终端按照上一步的方法测试 etcd 是否成功启动。 macOS 中运行 $ brew install etcd $ etcd $ etcdctl member list Copyright © Zhenhai Gao 2021 all right reserved发布时间： 2024-06-10 23:03:15 "},"kubernetes/etcd/cluster.html":{"url":"kubernetes/etcd/cluster.html","title":"集群","keywords":"","body":"etcd 集群etcd 集群 下面我们使用 Docker Compose 模拟启动一个 3 节点的 etcd 集群。 编辑 docker-compose.yml 文件 version: \"3.6\" services: node1: image: quay.io/coreos/etcd:v3.4.0 volumes: - node1-data:/etcd-data expose: - 2379 - 2380 networks: cluster_net: ipv4_address: 172.16.238.100 environment: - ETCDCTL_API=3 command: - /usr/local/bin/etcd - --data-dir=/etcd-data - --name - node1 - --initial-advertise-peer-urls - http://172.16.238.100:2380 - --listen-peer-urls - http://0.0.0.0:2380 - --advertise-client-urls - http://172.16.238.100:2379 - --listen-client-urls - http://0.0.0.0:2379 - --initial-cluster - node1=http://172.16.238.100:2380,node2=http://172.16.238.101:2380,node3=http://172.16.238.102:2380 - --initial-cluster-state - new - --initial-cluster-token - docker-etcd node2: image: quay.io/coreos/etcd:v3.4.0 volumes: - node2-data:/etcd-data networks: cluster_net: ipv4_address: 172.16.238.101 environment: - ETCDCTL_API=3 expose: - 2379 - 2380 command: - /usr/local/bin/etcd - --data-dir=/etcd-data - --name - node2 - --initial-advertise-peer-urls - http://172.16.238.101:2380 - --listen-peer-urls - http://0.0.0.0:2380 - --advertise-client-urls - http://172.16.238.101:2379 - --listen-client-urls - http://0.0.0.0:2379 - --initial-cluster - node1=http://172.16.238.100:2380,node2=http://172.16.238.101:2380,node3=http://172.16.238.102:2380 - --initial-cluster-state - new - --initial-cluster-token - docker-etcd node3: image: quay.io/coreos/etcd:v3.4.0 volumes: - node3-data:/etcd-data networks: cluster_net: ipv4_address: 172.16.238.102 environment: - ETCDCTL_API=3 expose: - 2379 - 2380 command: - /usr/local/bin/etcd - --data-dir=/etcd-data - --name - node3 - --initial-advertise-peer-urls - http://172.16.238.102:2380 - --listen-peer-urls - http://0.0.0.0:2380 - --advertise-client-urls - http://172.16.238.102:2379 - --listen-client-urls - http://0.0.0.0:2379 - --initial-cluster - node1=http://172.16.238.100:2380,node2=http://172.16.238.101:2380,node3=http://172.16.238.102:2380 - --initial-cluster-state - new - --initial-cluster-token - docker-etcd volumes: node1-data: node2-data: node3-data: networks: cluster_net: driver: bridge ipam: driver: default config: - subnet: 172.16.238.0/24 使用 docker-compose up 启动集群之后使用 docker exec 命令登录到任一节点测试 etcd 集群。 / # etcdctl member list daf3fd52e3583ff, started, node3, http://172.16.238.102:2380, http://172.16.238.102:2379 422a74f03b622fef, started, node1, http://172.16.238.100:2380, http://172.16.238.100:2379 ed635d2a2dbef43d, started, node2, http://172.16.238.101:2380, http://172.16.238.101:2379 Copyright © Zhenhai Gao 2021 all right reserved发布时间： 2024-06-10 23:03:15 "},"kubernetes/etcd/etcdctl.html":{"url":"kubernetes/etcd/etcdctl.html","title":"使用 etcdctl","keywords":"","body":"使用 etcdctl数据库操作putgetdel非数据库操作watchmember使用 etcdctl etcdctl 是一个命令行客户端，它能提供一些简洁的命令，供用户直接跟 etcd 服务打交道，而无需基于 HTTP API 方式。这在某些情况下将很方便，例如用户对服务进行测试或者手动修改数据库内容。我们也推荐在刚接触 etcd 时通过 etcdctl 命令来熟悉相关的操作，这些操作跟 HTTP API 实际上是对应的。 etcd 项目二进制发行包中已经包含了 etcdctl 工具，没有的话，可以从 github.com/etcd-io/etcd/releases 下载。 etcdctl 支持如下的命令，大体上分为数据库操作和非数据库操作两类，后面将分别进行解释。 NAME: etcdctl - A simple command line client for etcd3. USAGE: etcdctl VERSION: 3.4.0 API VERSION: 3.4 COMMANDS: get Gets the key or a range of keys put Puts the given key into the store del Removes the specified key or range of keys [key, range_end) txn Txn processes all the requests in one transaction compaction Compacts the event history in etcd alarm disarm Disarms all alarms alarm list Lists all alarms defrag Defragments the storage of the etcd members with given endpoints endpoint health Checks the healthiness of endpoints specified in `--endpoints` flag endpoint status Prints out the status of endpoints specified in `--endpoints` flag watch Watches events stream on keys or prefixes version Prints the version of etcdctl lease grant Creates leases lease revoke Revokes leases lease timetolive Get lease information lease keep-alive Keeps leases alive (renew) member add Adds a member into the cluster member remove Removes a member from the cluster member update Updates a member in the cluster member list Lists all members in the cluster snapshot save Stores an etcd node backend snapshot to a given file snapshot restore Restores an etcd member snapshot to an etcd directory snapshot status Gets backend snapshot status of a given file make-mirror Makes a mirror at the destination etcd cluster migrate Migrates keys in a v2 store to a mvcc store lock Acquires a named lock elect Observes and participates in leader election auth enable Enables authentication auth disable Disables authentication user add Adds a new user user delete Deletes a user user get Gets detailed information of a user user list Lists all users user passwd Changes password of user user grant-role Grants a role to a user user revoke-role Revokes a role from a user role add Adds a new role role delete Deletes a role role get Gets detailed information of a role role list Lists all roles role grant-permission Grants a key to a role role revoke-permission Revokes a key from a role check perf Check the performance of the etcd cluster help Help about any command OPTIONS: --cacert=\"\" verify certificates of TLS-enabled secure servers using this CA bundle --cert=\"\" identify secure client using this TLS certificate file --command-timeout=5s timeout for short running command (excluding dial timeout) --debug[=false] enable client-side debug logging --dial-timeout=2s dial timeout for client connections --endpoints=[127.0.0.1:2379] gRPC endpoints --hex[=false] print byte strings as hex encoded strings --insecure-skip-tls-verify[=false] skip server certificate verification --insecure-transport[=true] disable transport security for client connections --key=\"\" identify secure client using this TLS key file --user=\"\" username[:password] for authentication (prompt if password is not supplied) -w, --write-out=\"simple\" set the output format (fields, json, protobuf, simple, table) 数据库操作 数据库操作围绕对键值和目录的 CRUD （符合 REST 风格的一套操作：Create）完整生命周期的管理。 etcd 在键的组织上采用了层次化的空间结构（类似于文件系统中目录的概念），用户指定的键可以为单独的名字，如 testkey，此时实际上放在根目录 / 下面，也可以为指定目录结构，如 cluster1/node2/testkey，则将创建相应的目录结构。 注：CRUD 即 Create, Read, Update, Delete，是符合 REST 风格的一套 API 操作。 put $ etcdctl put /testdir/testkey \"Hello world\" OK get 获取指定键的值。例如 $ etcdctl put testkey hello OK $ etcdctl get testkey testkey hello 支持的选项为 --sort 对结果进行排序 --consistent 将请求发给主节点，保证获取内容的一致性 del 删除某个键值。例如 $ etcdctl del testkey 1 非数据库操作 watch 监测一个键值的变化，一旦键值发生更新，就会输出最新的值。 例如，用户更新 testkey 键值为 Hello world。 $ etcdctl watch testkey PUT testkey 2 member 通过 list、add、update、remove 命令列出、添加、更新、删除 etcd 实例到 etcd 集群中。 例如本地启动一个 etcd 服务实例后，可以用如下命令进行查看。 $ etcdctl member list 422a74f03b622fef, started, node1, http://172.16.238.100:2380, http://172.16.238.100:23 Copyright © Zhenhai Gao 2021 all right reserved发布时间： 2024-06-10 23:03:15 "},"kubernetes/batch-schedule/":{"url":"kubernetes/batch-schedule/","title":"批量调度","keywords":"","body":"Volcano & KueueVolcano & Kueue 任务队列批量调度是云原生 MLOps 中必备的功能。由于原生 Kubernetes 无法支持机器学习、并行计算等特殊场景的任务调度，因此出现了 Kueue 和 Volcano 这些调度组件。举例来说，tensorflow 分布式训练中需要一个参数服务器和多个 worker 功能配合执行，就需要同时保证这 n 个 pod 正常执行或者等待，kubernetes 原生的调度器是无法做到这些的，需要有队列组件配合 tensorflowi 对应的 operator 共同来完成该作业。 相同点 都支持队列资源的划分 不同点 Kueue具备多租户的概念，Volcano不具备此功能 Kueue可以用命名空间隔离队列资源，Volcano不具备此功能 Volcano支持多种调度策略，Kueue目前应该支持的调度策略较少 Kueue是谷歌背书，Volcano是华为背书 两者资源借用的方式不同，原理类似 Volcano只有一层队列，Kueue有两个层级的队列 从代码更新的角度看Kueue社区更加活跃 Volcano还支持GPU共享、工作流等功能，功能更加丰富 Copyright © Zhenhai Gao 2021 all right reserved发布时间： 2024-06-10 23:03:15 "},"kubernetes/batch-schedule/volcano/":{"url":"kubernetes/batch-schedule/volcano/","title":"Volcano","keywords":"","body":"Volcano架构CRD 资源说明QueuePodGroupVolcanoJob安装部署Volcano 生态Volcano Volcano 是基于 Kubernetes 的批处理系统，源自于华为云开源出来的。Volcano 方便 AI、大数据、基因、渲染等诸多行业通用计算框架接入，提供高性能任务调度引擎，高性能异构芯片管理，高性能任务运行管理等能力。 架构 Volcano 由 scheduler、controllermanager、admission 组成: Scheduler: Volcano scheduler 通过一系列的 action 和 plugin 调度 Job，并为它找到一个最适合的节点。与 Kubernetes default-scheduler 相比，Volcano 与众不同的地方是它支持针对 Job 的多种调度算法。 Controllermanager: Volcano controllermanager 管理 CRD 资源的生命周期。它主要由 Queue ControllerManager、 PodGroupControllerManager、 VCJob ControllerManager 构成。 Admission Volcano: admission 负责对 CRD API 资源进行校验。 CRD 资源说明 Volcano 主要用到的 CRD 资源有 Queue、PodGroup、VolcanoJob 等。 Queue queue 是容纳一组 podgroup 的队列，也是该组 podgroup 获取集群资源的划分依据 apiVersion: scheduling.volcano.sh/v1beta1 kind: Queue metadata: name: default spec: reclaimable: true weight: 1 capability: cpu: \"4\" memory: \"4096Mi\" status: state: Open weight: 表示该 queue 在集群资源划分中所占的相对比重，该 queue 应得资源总量为 (weight/total-weight) * total-resource。其中， total-weight 表示所有的 queue 的 weight 总和，total-resource 表示集群的资源总量。weight 是一个软约束，取值范围为[1, 2^31-1] capability: 表示该 queue 内所有 podgroup 使用资源量之和的上限，它是一个硬约束 reclaimable: 表示该 queue 在资源使用量超过该queue所应得的资源份额时，是否允许其他 queue 回收该 queue 使用超额的资源，默认值为 true status: queue 队列状态 Open: 该 queue 当前处于可用状态，可接收新的 podgroup Closed: 该 queue 当前处于不可用状态，不可接收新的 podgroup Closing: 该 queue 正在转化为不可用状态，不可接收新的 podgroup Unknown: 该 queue 当前处于不可知状态，可能是网络或其他原因导致 queue 的状态暂时无法感知 PodGroup podgroup 是一组强关联 pod 的集合，主要用于批处理工作负载场景，比如 Tensorflow 中的一组 ps 和 worker。它是 volcano 自定义资源类型。 apiVersion: scheduling.volcano.sh/v1beta1 kind: PodGroup metadata: name: test namespace: default spec: minMember: 1 minResources: cpu: \"3\" memory: \"2048Mi\" priorityClassName: high-prority queue: default status: conditions: - lastTransitionTime: \"2020-08-11T12:29:02Z\" reason: tasks in gang are ready to be scheduled status: \"True\" transitionID: 54514401-5c90-4b11-840d-90c1cda93096 type: Scheduled phase: Running running: 1 minMember: 表示该 podgroup 下最少需要运行的 pod 或任务数量。如果集群资源不满足 miniMember 数量任务的运行需求，调度器将不会调度任何一个该 podgroup 内的任务。 queue: 表示该 podgroup 所属的 queue。queue 必须提前已创建且状态为 open。 priorityClassName: 表示该 podgroup 的优先级，用于调度器为该 queue 中所有 podgroup 进行调度时进行排序。system-node-critical 和 system-cluster-critical 是2个预留的值，表示最高优先级。不特别指定时，默认使用 default 优先级或 zero 优先级。 minResources: 表示运行该 podgroup 所需要的最少资源。当集群可分配资源不满足 minResources 时，调度器将不会调度任何一个该 podgroup 内的任务。 phase: 表示该 podgroup 当前的状态。 running: 表示该 podgroup 中当前处于 running 状态的 pod 或任务的数量。 succeed: 表示该 podgroup 中当前处于 succeed 状态的 pod 或任务的数量。 failed: 表示该 podgroup 中当前处于 failed 状态的 pod 或任务的数量。 说明事项: 当创建 vcjob（Volcano Job的简称）时，若没有指定该 vcjob 所属的 podgroup，默认会为该 vcjob 创建同名的 podgroup。 VolcanoJob Volcano Job，简称 vcjob，是 Volcano 自定义的 Job 资源类型。区别于 Kubernetes Job，vcjob 提供了更多高级功能，如可指定调度器、支持最小运行 pod 数、 支持 task、支持生命周期管理、支持指定队列、支持优先级调度等。Volcano Job 更加适用于机器学习、大数据、科学计算等高性能计算场景。 apiVersion: batch.volcano.sh/v1alpha1 kind: Job metadata: name: test-job spec: minAvailable: 3 maxRetry: 5 queue: default schedulerName: volcano priorityClassName: high-priority policies: - event: PodEvicted action: RestartJob plugins: ssh: [] env: [] svc: [] volumes: - mountPath: \"/myinput\" - mountPath: \"/myoutput\" volumeClaimName: \"testvolumeclaimname\" volumeClaim: accessModes: [ \"ReadWriteOnce\" ] storageClassName: \"my-storage-class\" resources: requests: storage: 1Gi tasks: - replicas: 6 name: \"default-nginx\" template: metadata: name: web spec: containers: - image: nginx imagePullPolicy: IfNotPresent name: nginx resources: requests: cpu: \"1\" restartPolicy: OnFailure schedulerName: 表示该 job 的 pod 所使用的调度器，默认值为 volcano，也可指定为 default-scheduler。它也是 tasks.template.spec.schedulerName 的默认值。 minAvailable: 表示运行该 job 所要运行的最少 pod 数量。只有当 job 中处于 running 状态的 pod 数量不小于 minAvailable 时，才认为该 job 运行正常。 volumes: 表示该 job 的挂卷配置。volumes 配置遵从 kubernetes volumes 配置要求。 policies: 表示 job 中所有 task 的默认生命周期策略，在 tasks.policies 不配置时使用该策略。 plugins: 表示该 job 在调度过程中使用的插件。 queue: 表示该 job 所属的队列。 priorityClassName: 表示该 job 优先级，在抢占调度和优先级排序中生效。 maxRetry: 表示当该 job 可以进行的最大重启次数。 安装部署 初始化 CRD 资源 kubectl create -f 01volcano-crds.yaml 创建 Namespace kubectl create -f 02volcano-ns.yaml 安装 volcano-controller 组件 kubectl -n volcano-system create -f 03volcano-controller.yaml 安装 volcano-scheduler 组件 kubectl -n volcano-system create -f 04volcano-scheduler.yaml 安装 volcano-webhook 组件 kubectl -n volcano-system create -f 05volcano-webhook.yaml 查看实例状态 [~/Desktop/batch-schedule/volcano]$ kubectl -n volcano-system get po NAME READY STATUS RESTARTS AGE volcano-admission-7448cd567f-8phtb 1/1 Running 0 14d volcano-controllers-f89c46654-s6pls 1/1 Running 0 14d volcano-scheduler-669b797494-jbl8j 1/1 Running 0 14d Volcano 生态 Volcano已经支持几乎所有的主流计算框架： Spark TensorFlow PyTorch Flink Argo MindSpore PaddlePaddle OpenMPI Horovod mxnet Kubeflow KubeGene Cromwell Copyright © Zhenhai Gao 2021 all right reserved发布时间： 2024-06-10 23:03:15 "},"kubernetes/batch-schedule/kueue/":{"url":"kubernetes/batch-schedule/kueue/","title":"Kueue","keywords":"","body":"Kueue架构CRD 资源说明ResourceFlavorClusterQueueLocalQueueWorkloadWorkload Priority Class安装部署生态Kueue Kueue 是一个 Cloud Native Job 调度器，使用默认的 Kubernetes 调度器、Job 控制器和集群自动扩缩器来提供端到端批处理系统。Kueue 会根据配额和层次结构，在团队之间共享资源，从而实现 Job 排队，确定 Job 应等待的时间和应开始的时间。旨在简化和优化 Kubernetes 中的作业管理。 主要具备以下功能： 作业管理：支持基于优先级的作业队列，提供不同的队列策略，如 StrictFIFO 和 BestEffortFIFO。 资源管理：支持资源的公平分享和抢占，以及不同租户之间的资源管理策略。 动态资源回收：一种释放资源配额的机制，随着作业的完成而动态释放资源。 资源灵活性：在 ClusterQueue 和 Cohort 中支持资源的借用或抢占。 内置集成：内置支持常见的作业类型，如 BatchJob、Kubeflow 训练作业、RayJob、RayCluster、JobSet 等。 系统监控：内置 Prometheus 指标，用于监控系统状态。 准入检查：一种机制，用于影响工作负载是否可以被接受。 高级自动缩放支持：与 cluster-autoscaler 的 provisioningRequest 集成，通过准入检查进行管理。 顺序准入：一种简单的全或无调度实现。 部分准入：允许作业以较小的并行度运行，基于可用配额。 架构 ResourceFalvor 提供了节点的抽象，它通过 nodeLabel 的方式与具体的 node 进行绑定。ClusterQueue 是资源池的抽象，定义这个集群总资源量，ClusterQueue 中存在多个 localQueue，它们之间的资源会共享。一个作业会被提交到一个具体的 localQueue 进行调度。不同 clusterQueue 可以通过 Cohort 的机制共享资源。 CRD 资源说明 ResourceFlavor ResourceFlavor 是一种对象，用于表示集群内节点的变体，即将它们与节点标签和污点相关联。例如，您可以使用 ResourceFlavor 表示具有不同预配保证（例如 Spot 与按需）、架构（例如 x86 与 ARM CPU）、品牌和型号（例如 Nvidia A100 与 T4 GPU）的虚拟机。 apiVersion: kueue.x-k8s.io/v1beta1 kind: ResourceFlavor metadata: name: \"spot\" spec: nodeLabels: instance-type: spot nodeTaints: - effect: NoSchedule key: spot value: \"true\" tolerations: - key: \"spot-taint\" operator: \"Exists\" effect: \"NoSchedule\" ClusterQueue ClusterQueue 是集群级对象，用于管理 CPU、内存、GPU 等资源池。它负责管理 ResourceFlavor，并限制其用量并决定工作负载的允许顺序。 apiVersion: kueue.x-k8s.io/v1beta1 kind: ClusterQueue metadata: name: cluster-queue spec: namespaceSelector: {} # Available to all namespaces queueingStrategy: BestEffortFIFO # Default queueing strategy cohort: \"team-ab\" stopPolicy: Hold preemption: reclaimWithinCohort: Any borrowWithinCohort: policy: LowerPriority maxPriorityThreshold: 100 withinClusterQueue: LowerPriority flavorFungibility: whenCanBorrow: TryNextFlavor whenCanPreempt: Preempt resourceGroups: - coveredResources: [\"cpu\", \"memory\", \"nvidia.com/gpu\", \"ephemeral-storage\"] flavors: - name: \"default-flavor\" resources: - name: \"cpu\" nominalQuota: 10 - name: \"memory\" nominalQuota: 10Gi - name: \"nvidia.com/gpu\" nominalQuota: 10 lendingLimit: 1 - name: \"ephemeral-storage\" nominalQuota: 10Gi borrowingLimit: 1Gi .spec.queueingStrategy: 设置使用顺序，其中有两种配置 BestEffortFIFO：默认排队策略配置，工作负载准入遵循先进先出 (FIFO) 规则，但如果配额不足以允许队列头部的工作负载，则将尝试队列中的下一项工作负载。 StrictFIFO：保证 FIFO 语义，队列头部的工作负载可以阻止将更多工作负载加入队列，直到该工作负载获得准入许可。 每个变种都包含表示为 .spec.resourceGroups[].flavors[].resources[].nominalQuota 的使用限制。在这种情况下，当且仅当满足以下条件时，ClusterQueue 才允许工作负载： CPU 请求的总和小于或等于 10 内存请求的总和小于或等于 10Gi GPU 请求的总和小于或等于 10 使用的存储空间总和小于或等于 10Gi LocalQueue LocalQueue 是一个命名空间对象，接受来自命名空间中用户的工作负载。不同命名空间的 LocalQueue 可以指向同一个 ClusterQueue，它们可以在其中共享资源的配额。在这种情况下，命名空间 team-a 和 team-b 中的 LocalQueue 指向 .spec.clusterQueue 下的同一 ClusterQueue cluster-queue。 apiVersion: kueue.x-k8s.io/v1beta1 kind: LocalQueue metadata: namespace: team-a name: team-a-queue spec: clusterQueue: cluster-queue Workload apiVersion: kueue.x-k8s.io/v1beta1 kind: Workload metadata: name: sample-job namespace: team-a spec: active: true queueName: team-a-queue podSets: - count: 3 name: main template: spec: containers: - image: gcr.io/k8s-staging-perf-tests/sleep:latest imagePullPolicy: Always name: container resources: requests: cpu: \"1\" memory: 200Mi restartPolicy: Never Workload Priority Class apiVersion: kueue.x-k8s.io/v1beta1 kind: WorkloadPriorityClass metadata: name: sample-priority value: 10000 description: \"Sample priority\" 安装部署 %accordion% 01kueue-crds.yaml %accordion% apiVersion: apiextensions.k8s.io/v1 kind: CustomResourceDefinition metadata: annotations: controller-gen.kubebuilder.io/version: v0.14.0 name: admissionchecks.kueue.x-k8s.io spec: group: kueue.x-k8s.io names: kind: AdmissionCheck listKind: AdmissionCheckList plural: admissionchecks singular: admissioncheck scope: Cluster versions: - name: v1beta1 schema: openAPIV3Schema: description: AdmissionCheck is the Schema for the admissionchecks API properties: apiVersion: description: |- APIVersion defines the versioned schema of this representation of an object. Servers should convert recognized schemas to the latest internal value, and may reject unrecognized values. More info: https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#resources type: string kind: description: |- Kind is a string value representing the REST resource this object represents. Servers may infer this from the endpoint the client submits requests to. Cannot be updated. In CamelCase. More info: https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#types-kinds type: string metadata: type: object spec: description: AdmissionCheckSpec defines the desired state of AdmissionCheck properties: controllerName: description: |- controllerName is name of the controller which will actually perform the checks. This is the name with which controller identifies with, not necessarily a K8S Pod or Deployment name. Cannot be empty. type: string parameters: description: Parameters identifies the resource providing additional check parameters. properties: apiGroup: description: ApiGroup is the group for the resource being referenced. type: string kind: description: Kind is the type of the resource being referenced. type: string name: description: Name is the name of the resource being referenced. type: string required: - apiGroup - kind - name type: object retryDelayMinutes: default: 15 description: |- RetryDelayMinutes specifies how long to keep the workload suspended after a failed check (after it transitioned to False). After that the check state goes to \"Unknown\". The default is 15 min. format: int64 type: integer required: - controllerName type: object status: description: AdmissionCheckStatus defines the observed state of AdmissionCheck properties: conditions: description: |- conditions hold the latest available observations of the AdmissionCheck current state. items: description: \"Condition contains details for one aspect of the current state of this API Resource.\\n---\\nThis struct is intended for direct use as an array at the field path .status.conditions. For example,\\n\\n\\n\\ttype FooStatus struct{\\n\\t // Represents the observations of a foo's current state.\\n\\t // Known .status.conditions.type are: \\\"Available\\\", \\\"Progressing\\\", and \\\"Degraded\\\"\\n\\t // +patchMergeKey=type\\n\\t // +patchStrategy=merge\\n\\t // +listType=map\\n\\t \\ // +listMapKey=type\\n\\t Conditions []metav1.Condition `json:\\\"conditions,omitempty\\\" patchStrategy:\\\"merge\\\" patchMergeKey:\\\"type\\\" protobuf:\\\"bytes,1,rep,name=conditions\\\"`\\n\\n\\n\\t \\ // other fields\\n\\t}\" properties: lastTransitionTime: description: |- lastTransitionTime is the last time the condition transitioned from one status to another. This should be when the underlying condition changed. If that is not known, then using the time when the API field changed is acceptable. format: date-time type: string message: description: |- message is a human readable message indicating details about the transition. This may be an empty string. maxLength: 32768 type: string observedGeneration: description: |- observedGeneration represents the .metadata.generation that the condition was set based upon. For instance, if .metadata.generation is currently 12, but the .status.conditions[x].observedGeneration is 9, the condition is out of date with respect to the current state of the instance. format: int64 minimum: 0 type: integer reason: description: |- reason contains a programmatic identifier indicating the reason for the condition's last transition. Producers of specific condition types may define expected values and meanings for this field, and whether the values are considered a guaranteed API. The value should be a CamelCase string. This field may not be empty. maxLength: 1024 minLength: 1 pattern: ^[A-Za-z]([A-Za-z0-9_,:]*[A-Za-z0-9_])?$ type: string status: description: status of the condition, one of True, False, Unknown. enum: - \"True\" - \"False\" - Unknown type: string type: description: |- type of condition in CamelCase or in foo.example.com/CamelCase. --- Many .condition.type values are consistent across resources like Available, but because arbitrary conditions can be useful (see .node.status.conditions), the ability to deconflict is important. The regex it matches is (dns1123SubdomainFmt/)?(qualifiedNameFmt) maxLength: 316 pattern: ^([a-z0-9]([-a-z0-9]*[a-z0-9])?(\\.[a-z0-9]([-a-z0-9]*[a-z0-9])?)*/)?(([A-Za-z0-9][-A-Za-z0-9_.]*)?[A-Za-z0-9])$ type: string required: - lastTransitionTime - message - reason - status - type type: object type: array x-kubernetes-list-map-keys: - type x-kubernetes-list-type: map type: object type: object served: true storage: true subresources: status: {} --- apiVersion: apiextensions.k8s.io/v1 kind: CustomResourceDefinition metadata: annotations: controller-gen.kubebuilder.io/version: v0.14.0 name: clusterqueues.kueue.x-k8s.io spec: group: kueue.x-k8s.io names: kind: ClusterQueue listKind: ClusterQueueList plural: clusterqueues singular: clusterqueue scope: Cluster versions: - additionalPrinterColumns: - description: Cohort that this ClusterQueue belongs to jsonPath: .spec.cohort name: Cohort type: string - description: The queueing strategy used to prioritize workloads jsonPath: .spec.queueingStrategy name: Strategy priority: 1 type: string - description: Number of pending workloads jsonPath: .status.pendingWorkloads name: Pending Workloads type: integer - description: Number of admitted workloads that haven't finished yet jsonPath: .status.admittedWorkloads name: Admitted Workloads priority: 1 type: integer name: v1beta1 schema: openAPIV3Schema: description: ClusterQueue is the Schema for the clusterQueue API. properties: apiVersion: description: |- APIVersion defines the versioned schema of this representation of an object. Servers should convert recognized schemas to the latest internal value, and may reject unrecognized values. More info: https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#resources type: string kind: description: |- Kind is a string value representing the REST resource this object represents. Servers may infer this from the endpoint the client submits requests to. Cannot be updated. In CamelCase. More info: https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#types-kinds type: string metadata: type: object spec: description: ClusterQueueSpec defines the desired state of ClusterQueue properties: admissionChecks: description: admissionChecks lists the AdmissionChecks required by this ClusterQueue items: type: string type: array cohort: description: |- cohort that this ClusterQueue belongs to. CQs that belong to the same cohort can borrow unused resources from each other. A CQ can be a member of a single borrowing cohort. A workload submitted to a queue referencing this CQ can borrow quota from any CQ in the cohort. Only quota for the [resource, flavor] pairs listed in the CQ can be borrowed. If empty, this ClusterQueue cannot borrow from any other ClusterQueue and vice versa. A cohort is a name that links CQs together, but it doesn't reference any object. Validation of a cohort name is equivalent to that of object names: subdomain in DNS (RFC 1123). type: string flavorFungibility: description: |- flavorFungibility defines whether a workload should try the next flavor before borrowing or preempting in the flavor being evaluated. properties: whenCanBorrow: default: Borrow description: |- whenCanBorrow determines whether a workload should try the next flavor before borrowing in current flavor. The possible values are: - `Borrow` (default): allocate in current flavor if borrowing is possible. - `TryNextFlavor`: try next flavor even if the current flavor has enough resources to borrow. enum: - Borrow - TryNextFlavor type: string whenCanPreempt: default: TryNextFlavor description: |- whenCanPreempt determines whether a workload should try the next flavor before borrowing in current flavor. The possible values are: - `Preempt`: allocate in current flavor if it's possible to preempt some workloads. - `TryNextFlavor` (default): try next flavor even if there are enough candidates for preemption in the current flavor. enum: - Preempt - TryNextFlavor type: string type: object namespaceSelector: description: |- namespaceSelector defines which namespaces are allowed to submit workloads to this clusterQueue. Beyond this basic support for policy, a policy agent like Gatekeeper should be used to enforce more advanced policies. Defaults to null which is a nothing selector (no namespaces eligible). If set to an empty selector `{}`, then all namespaces are eligible. properties: matchExpressions: description: matchExpressions is a list of label selector requirements. The requirements are ANDed. items: description: |- A label selector requirement is a selector that contains values, a key, and an operator that relates the key and values. properties: key: description: key is the label key that the selector applies to. type: string operator: description: |- operator represents a key's relationship to a set of values. Valid operators are In, NotIn, Exists and DoesNotExist. type: string values: description: |- values is an array of string values. If the operator is In or NotIn, the values array must be non-empty. If the operator is Exists or DoesNotExist, the values array must be empty. This array is replaced during a strategic merge patch. items: type: string type: array required: - key - operator type: object type: array matchLabels: additionalProperties: type: string description: |- matchLabels is a map of {key,value} pairs. A single {key,value} in the matchLabels map is equivalent to an element of matchExpressions, whose key field is \"key\", the operator is \"In\", and the values array contains only \"value\". The requirements are ANDed. type: object type: object x-kubernetes-map-type: atomic preemption: description: |- preemption describes policies to preempt Workloads from this ClusterQueue or the ClusterQueue's cohort. Preemption can happen in two scenarios: - When a Workload fits within the nominal quota of the ClusterQueue, but the quota is currently borrowed by other ClusterQueues in the cohort. Preempting Workloads in other ClusterQueues allows this ClusterQueue to reclaim its nominal quota. - When a Workload doesn't fit within the nominal quota of the ClusterQueue and there are admitted Workloads in the ClusterQueue with lower priority. The preemption algorithm tries to find a minimal set of Workloads to preempt to accomomdate the pending Workload, preempting Workloads with lower priority first. properties: borrowWithinCohort: description: |- borrowWithinCohort provides configuration to allow preemption within cohort while borrowing. properties: maxPriorityThreshold: description: |- maxPriorityThreshold allows to restrict the set of workloads which might be preempted by a borrowing workload, to only workloads with priority less than or equal to the specified threshold priority. When the threshold is not specified, then any workload satisfying the policy can be preempted by the borrowing workload. format: int32 type: integer policy: default: Never description: |- policy determines the policy for preemption to reclaim quota within cohort while borrowing. Possible values are: - `Never` (default): do not allow for preemption, in other ClusterQueues within the cohort, for a borrowing workload. - `LowerPriority`: allow preemption, in other ClusterQueues within the cohort, for a borrowing workload, but only if the preempted workloads are of lower priority. enum: - Never - LowerPriority type: string type: object reclaimWithinCohort: default: Never description: |- reclaimWithinCohort determines whether a pending Workload can preempt Workloads from other ClusterQueues in the cohort that are using more than their nominal quota. The possible values are: - `Never` (default): do not preempt Workloads in the cohort. - `LowerPriority`: if the pending Workload fits within the nominal quota of its ClusterQueue, only preempt Workloads in the cohort that have lower priority than the pending Workload. - `Any`: if the pending Workload fits within the nominal quota of its ClusterQueue, preempt any Workload in the cohort, irrespective of priority. enum: - Never - LowerPriority - Any type: string withinClusterQueue: default: Never description: |- withinClusterQueue determines whether a pending Workload that doesn't fit within the nominal quota for its ClusterQueue, can preempt active Workloads in the ClusterQueue. The possible values are: - `Never` (default): do not preempt Workloads in the ClusterQueue. - `LowerPriority`: only preempt Workloads in the ClusterQueue that have lower priority than the pending Workload. - `LowerOrNewerEqualPriority`: only preempt Workloads in the ClusterQueue that either have a lower priority than the pending workload or equal priority and are newer than the pending workload. enum: - Never - LowerPriority - LowerOrNewerEqualPriority type: string type: object queueingStrategy: default: BestEffortFIFO description: |- QueueingStrategy indicates the queueing strategy of the workloads across the queues in this ClusterQueue. This field is immutable. Current Supported Strategies: - StrictFIFO: workloads are ordered strictly by creation time. Older workloads that can't be admitted will block admitting newer workloads even if they fit available quota. - BestEffortFIFO: workloads are ordered by creation time, however older workloads that can't be admitted will not block admitting newer workloads that fit existing quota. enum: - StrictFIFO - BestEffortFIFO type: string resourceGroups: description: |- resourceGroups describes groups of resources. Each resource group defines the list of resources and a list of flavors that provide quotas for these resources. Each resource and each flavor can only form part of one resource group. resourceGroups can be up to 16. items: properties: coveredResources: description: |- coveredResources is the list of resources covered by the flavors in this group. Examples: cpu, memory, vendor.com/gpu. The list cannot be empty and it can contain up to 16 resources. items: description: ResourceName is the name identifying various resources in a ResourceList. type: string maxItems: 16 minItems: 1 type: array flavors: description: |- flavors is the list of flavors that provide the resources of this group. Typically, different flavors represent different hardware models (e.g., gpu models, cpu architectures) or pricing models (on-demand vs spot cpus). Each flavor MUST list all the resources listed for this group in the same order as the .resources field. The list cannot be empty and it can contain up to 16 flavors. items: properties: name: description: |- name of this flavor. The name should match the .metadata.name of a ResourceFlavor. If a matching ResourceFlavor does not exist, the ClusterQueue will have an Active condition set to False. type: string resources: description: |- resources is the list of quotas for this flavor per resource. There could be up to 16 resources. items: properties: borrowingLimit: anyOf: - type: integer - type: string description: |- borrowingLimit is the maximum amount of quota for the [flavor, resource] combination that this ClusterQueue is allowed to borrow from the unused quota of other ClusterQueues in the same cohort. In total, at a given time, Workloads in a ClusterQueue can consume a quantity of quota equal to nominalQuota+borrowingLimit, assuming the other ClusterQueues in the cohort have enough unused quota. If null, it means that there is no borrowing limit. If not null, it must be non-negative. borrowingLimit must be null if spec.cohort is empty. pattern: ^(\\+|-)?(([0-9]+(\\.[0-9]*)?)|(\\.[0-9]+))(([KMGTPE]i)|[numkMGTPE]|([eE](\\+|-)?(([0-9]+(\\.[0-9]*)?)|(\\.[0-9]+))))?$ x-kubernetes-int-or-string: true lendingLimit: anyOf: - type: integer - type: string description: |- lendingLimit is the maximum amount of unused quota for the [flavor, resource] combination that this ClusterQueue can lend to other ClusterQueues in the same cohort. In total, at a given time, ClusterQueue reserves for its exclusive use a quantity of quota equals to nominalQuota - lendingLimit. If null, it means that there is no lending limit, meaning that all the nominalQuota can be borrowed by other clusterQueues in the cohort. If not null, it must be non-negative. lendingLimit must be null if spec.cohort is empty. This field is in alpha stage. To be able to use this field, enable the feature gate LendingLimit, which is disabled by default. pattern: ^(\\+|-)?(([0-9]+(\\.[0-9]*)?)|(\\.[0-9]+))(([KMGTPE]i)|[numkMGTPE]|([eE](\\+|-)?(([0-9]+(\\.[0-9]*)?)|(\\.[0-9]+))))?$ x-kubernetes-int-or-string: true name: description: name of this resource. type: string nominalQuota: anyOf: - type: integer - type: string description: |- nominalQuota is the quantity of this resource that is available for Workloads admitted by this ClusterQueue at a point in time. The nominalQuota must be non-negative. nominalQuota should represent the resources in the cluster available for running jobs (after discounting resources consumed by system components and pods not managed by kueue). In an autoscaled cluster, nominalQuota should account for resources that can be provided by a component such as Kubernetes cluster-autoscaler. If the ClusterQueue belongs to a cohort, the sum of the quotas for each (flavor, resource) combination defines the maximum quantity that can be allocated by a ClusterQueue in the cohort. pattern: ^(\\+|-)?(([0-9]+(\\.[0-9]*)?)|(\\.[0-9]+))(([KMGTPE]i)|[numkMGTPE]|([eE](\\+|-)?(([0-9]+(\\.[0-9]*)?)|(\\.[0-9]+))))?$ x-kubernetes-int-or-string: true required: - name - nominalQuota type: object maxItems: 16 minItems: 1 type: array x-kubernetes-list-map-keys: - name x-kubernetes-list-type: map required: - name - resources type: object maxItems: 16 minItems: 1 type: array x-kubernetes-list-map-keys: - name x-kubernetes-list-type: map required: - coveredResources - flavors type: object maxItems: 16 type: array x-kubernetes-list-type: atomic stopPolicy: default: None description: |- stopPolicy - if set to a value different from None, the ClusterQueue is considered Inactive, no new reservation being made. Depending on its value, its associated workloads will: - None - Workloads are admitted - HoldAndDrain - Admitted workloads are evicted and Reserving workloads will cancel the reservation. - Hold - Admitted workloads will run to completion and Reserving workloads will cancel the reservation. enum: - None - Hold - HoldAndDrain type: string type: object status: description: ClusterQueueStatus defines the observed state of ClusterQueue properties: admittedWorkloads: description: |- admittedWorkloads is the number of workloads currently admitted to this clusterQueue and haven't finished yet. format: int32 type: integer conditions: description: |- conditions hold the latest available observations of the ClusterQueue current state. items: description: \"Condition contains details for one aspect of the current state of this API Resource.\\n---\\nThis struct is intended for direct use as an array at the field path .status.conditions. For example,\\n\\n\\n\\ttype FooStatus struct{\\n\\t // Represents the observations of a foo's current state.\\n\\t // Known .status.conditions.type are: \\\"Available\\\", \\\"Progressing\\\", and \\\"Degraded\\\"\\n\\t // +patchMergeKey=type\\n\\t // +patchStrategy=merge\\n\\t // +listType=map\\n\\t \\ // +listMapKey=type\\n\\t Conditions []metav1.Condition `json:\\\"conditions,omitempty\\\" patchStrategy:\\\"merge\\\" patchMergeKey:\\\"type\\\" protobuf:\\\"bytes,1,rep,name=conditions\\\"`\\n\\n\\n\\t \\ // other fields\\n\\t}\" properties: lastTransitionTime: description: |- lastTransitionTime is the last time the condition transitioned from one status to another. This should be when the underlying condition changed. If that is not known, then using the time when the API field changed is acceptable. format: date-time type: string message: description: |- message is a human readable message indicating details about the transition. This may be an empty string. maxLength: 32768 type: string observedGeneration: description: |- observedGeneration represents the .metadata.generation that the condition was set based upon. For instance, if .metadata.generation is currently 12, but the .status.conditions[x].observedGeneration is 9, the condition is out of date with respect to the current state of the instance. format: int64 minimum: 0 type: integer reason: description: |- reason contains a programmatic identifier indicating the reason for the condition's last transition. Producers of specific condition types may define expected values and meanings for this field, and whether the values are considered a guaranteed API. The value should be a CamelCase string. This field may not be empty. maxLength: 1024 minLength: 1 pattern: ^[A-Za-z]([A-Za-z0-9_,:]*[A-Za-z0-9_])?$ type: string status: description: status of the condition, one of True, False, Unknown. enum: - \"True\" - \"False\" - Unknown type: string type: description: |- type of condition in CamelCase or in foo.example.com/CamelCase. --- Many .condition.type values are consistent across resources like Available, but because arbitrary conditions can be useful (see .node.status.conditions), the ability to deconflict is important. The regex it matches is (dns1123SubdomainFmt/)?(qualifiedNameFmt) maxLength: 316 pattern: ^([a-z0-9]([-a-z0-9]*[a-z0-9])?(\\.[a-z0-9]([-a-z0-9]*[a-z0-9])?)*/)?(([A-Za-z0-9][-A-Za-z0-9_.]*)?[A-Za-z0-9])$ type: string required: - lastTransitionTime - message - reason - status - type type: object type: array x-kubernetes-list-map-keys: - type x-kubernetes-list-type: map flavorsReservation: description: |- flavorsReservation are the reserved quotas, by flavor, currently in use by the workloads assigned to this ClusterQueue. items: properties: name: description: name of the flavor. type: string resources: description: resources lists the quota usage for the resources in this flavor. items: properties: borrowed: anyOf: - type: integer - type: string description: |- Borrowed is quantity of quota that is borrowed from the cohort. In other words, it's the used quota that is over the nominalQuota. pattern: ^(\\+|-)?(([0-9]+(\\.[0-9]*)?)|(\\.[0-9]+))(([KMGTPE]i)|[numkMGTPE]|([eE](\\+|-)?(([0-9]+(\\.[0-9]*)?)|(\\.[0-9]+))))?$ x-kubernetes-int-or-string: true name: description: name of the resource type: string total: anyOf: - type: integer - type: string description: |- total is the total quantity of used quota, including the amount borrowed from the cohort. pattern: ^(\\+|-)?(([0-9]+(\\.[0-9]*)?)|(\\.[0-9]+))(([KMGTPE]i)|[numkMGTPE]|([eE](\\+|-)?(([0-9]+(\\.[0-9]*)?)|(\\.[0-9]+))))?$ x-kubernetes-int-or-string: true required: - name type: object maxItems: 16 type: array x-kubernetes-list-map-keys: - name x-kubernetes-list-type: map required: - name - resources type: object maxItems: 16 type: array x-kubernetes-list-map-keys: - name x-kubernetes-list-type: map flavorsUsage: description: |- flavorsUsage are the used quotas, by flavor, currently in use by the workloads admitted in this ClusterQueue. items: properties: name: description: name of the flavor. type: string resources: description: resources lists the quota usage for the resources in this flavor. items: properties: borrowed: anyOf: - type: integer - type: string description: |- Borrowed is quantity of quota that is borrowed from the cohort. In other words, it's the used quota that is over the nominalQuota. pattern: ^(\\+|-)?(([0-9]+(\\.[0-9]*)?)|(\\.[0-9]+))(([KMGTPE]i)|[numkMGTPE]|([eE](\\+|-)?(([0-9]+(\\.[0-9]*)?)|(\\.[0-9]+))))?$ x-kubernetes-int-or-string: true name: description: name of the resource type: string total: anyOf: - type: integer - type: string description: |- total is the total quantity of used quota, including the amount borrowed from the cohort. pattern: ^(\\+|-)?(([0-9]+(\\.[0-9]*)?)|(\\.[0-9]+))(([KMGTPE]i)|[numkMGTPE]|([eE](\\+|-)?(([0-9]+(\\.[0-9]*)?)|(\\.[0-9]+))))?$ x-kubernetes-int-or-string: true required: - name type: object maxItems: 16 type: array x-kubernetes-list-map-keys: - name x-kubernetes-list-type: map required: - name - resources type: object maxItems: 16 type: array x-kubernetes-list-map-keys: - name x-kubernetes-list-type: map pendingWorkloads: description: |- pendingWorkloads is the number of workloads currently waiting to be admitted to this clusterQueue. format: int32 type: integer pendingWorkloadsStatus: description: |- PendingWorkloadsStatus contains the information exposed about the current status of the pending workloads in the cluster queue. properties: clusterQueuePendingWorkload: description: Head contains the list of top pending workloads. items: description: |- ClusterQueuePendingWorkload contains the information identifying a pending workload in the cluster queue. properties: name: description: Name indicates the name of the pending workload. type: string namespace: description: Namespace indicates the name of the pending workload. type: string required: - name - namespace type: object type: array x-kubernetes-list-type: atomic lastChangeTime: description: LastChangeTime indicates the time of the last change of the structure. format: date-time type: string required: - lastChangeTime type: object reservingWorkloads: description: |- reservingWorkloads is the number of workloads currently reserving quota in this clusterQueue. format: int32 type: integer type: object type: object served: true storage: true subresources: status: {} --- apiVersion: apiextensions.k8s.io/v1 kind: CustomResourceDefinition metadata: annotations: cert-manager.io/inject-ca-from: $(CERTIFICATE_NAMESPACE)/$(CERTIFICATE_NAME) controller-gen.kubebuilder.io/version: v0.14.0 name: localqueues.kueue.x-k8s.io spec: group: kueue.x-k8s.io names: kind: LocalQueue listKind: LocalQueueList plural: localqueues shortNames: - queue - queues singular: localqueue scope: Namespaced versions: - additionalPrinterColumns: - description: Backing ClusterQueue jsonPath: .spec.clusterQueue name: ClusterQueue type: string - description: Number of pending workloads jsonPath: .status.pendingWorkloads name: Pending Workloads type: integer - description: Number of admitted workloads that haven't finished yet. jsonPath: .status.admittedWorkloads name: Admitted Workloads type: integer name: v1beta1 schema: openAPIV3Schema: description: LocalQueue is the Schema for the localQueues API properties: apiVersion: description: |- APIVersion defines the versioned schema of this representation of an object. Servers should convert recognized schemas to the latest internal value, and may reject unrecognized values. More info: https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#resources type: string kind: description: |- Kind is a string value representing the REST resource this object represents. Servers may infer this from the endpoint the client submits requests to. Cannot be updated. In CamelCase. More info: https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#types-kinds type: string metadata: type: object spec: description: LocalQueueSpec defines the desired state of LocalQueue properties: clusterQueue: description: clusterQueue is a reference to a clusterQueue that backs this localQueue. type: string type: object status: description: LocalQueueStatus defines the observed state of LocalQueue properties: admittedWorkloads: description: |- admittedWorkloads is the number of workloads in this LocalQueue admitted to a ClusterQueue and that haven't finished yet. format: int32 type: integer conditions: description: |- Conditions hold the latest available observations of the LocalQueue current state. items: description: \"Condition contains details for one aspect of the current state of this API Resource.\\n---\\nThis struct is intended for direct use as an array at the field path .status.conditions. For example,\\n\\n\\n\\ttype FooStatus struct{\\n\\t // Represents the observations of a foo's current state.\\n\\t // Known .status.conditions.type are: \\\"Available\\\", \\\"Progressing\\\", and \\\"Degraded\\\"\\n\\t // +patchMergeKey=type\\n\\t // +patchStrategy=merge\\n\\t // +listType=map\\n\\t \\ // +listMapKey=type\\n\\t Conditions []metav1.Condition `json:\\\"conditions,omitempty\\\" patchStrategy:\\\"merge\\\" patchMergeKey:\\\"type\\\" protobuf:\\\"bytes,1,rep,name=conditions\\\"`\\n\\n\\n\\t \\ // other fields\\n\\t}\" properties: lastTransitionTime: description: |- lastTransitionTime is the last time the condition transitioned from one status to another. This should be when the underlying condition changed. If that is not known, then using the time when the API field changed is acceptable. format: date-time type: string message: description: |- message is a human readable message indicating details about the transition. This may be an empty string. maxLength: 32768 type: string observedGeneration: description: |- observedGeneration represents the .metadata.generation that the condition was set based upon. For instance, if .metadata.generation is currently 12, but the .status.conditions[x].observedGeneration is 9, the condition is out of date with respect to the current state of the instance. format: int64 minimum: 0 type: integer reason: description: |- reason contains a programmatic identifier indicating the reason for the condition's last transition. Producers of specific condition types may define expected values and meanings for this field, and whether the values are considered a guaranteed API. The value should be a CamelCase string. This field may not be empty. maxLength: 1024 minLength: 1 pattern: ^[A-Za-z]([A-Za-z0-9_,:]*[A-Za-z0-9_])?$ type: string status: description: status of the condition, one of True, False, Unknown. enum: - \"True\" - \"False\" - Unknown type: string type: description: |- type of condition in CamelCase or in foo.example.com/CamelCase. --- Many .condition.type values are consistent across resources like Available, but because arbitrary conditions can be useful (see .node.status.conditions), the ability to deconflict is important. The regex it matches is (dns1123SubdomainFmt/)?(qualifiedNameFmt) maxLength: 316 pattern: ^([a-z0-9]([-a-z0-9]*[a-z0-9])?(\\.[a-z0-9]([-a-z0-9]*[a-z0-9])?)*/)?(([A-Za-z0-9][-A-Za-z0-9_.]*)?[A-Za-z0-9])$ type: string required: - lastTransitionTime - message - reason - status - type type: object type: array x-kubernetes-list-map-keys: - type x-kubernetes-list-type: map flavorUsage: description: |- flavorsUsage are the used quotas, by flavor currently in use by the workloads assigned to this LocalQueue. items: properties: name: description: name of the flavor. type: string resources: description: resources lists the quota usage for the resources in this flavor. items: properties: name: description: name of the resource. type: string total: anyOf: - type: integer - type: string description: total is the total quantity of used quota. pattern: ^(\\+|-)?(([0-9]+(\\.[0-9]*)?)|(\\.[0-9]+))(([KMGTPE]i)|[numkMGTPE]|([eE](\\+|-)?(([0-9]+(\\.[0-9]*)?)|(\\.[0-9]+))))?$ x-kubernetes-int-or-string: true required: - name type: object maxItems: 16 type: array x-kubernetes-list-map-keys: - name x-kubernetes-list-type: map required: - name - resources type: object maxItems: 16 type: array x-kubernetes-list-map-keys: - name x-kubernetes-list-type: map flavorsReservation: description: |- flavorsReservation are the reserved quotas, by flavor currently in use by the workloads assigned to this LocalQueue. items: properties: name: description: name of the flavor. type: string resources: description: resources lists the quota usage for the resources in this flavor. items: properties: name: description: name of the resource. type: string total: anyOf: - type: integer - type: string description: total is the total quantity of used quota. pattern: ^(\\+|-)?(([0-9]+(\\.[0-9]*)?)|(\\.[0-9]+))(([KMGTPE]i)|[numkMGTPE]|([eE](\\+|-)?(([0-9]+(\\.[0-9]*)?)|(\\.[0-9]+))))?$ x-kubernetes-int-or-string: true required: - name type: object maxItems: 16 type: array x-kubernetes-list-map-keys: - name x-kubernetes-list-type: map required: - name - resources type: object maxItems: 16 type: array x-kubernetes-list-map-keys: - name x-kubernetes-list-type: map pendingWorkloads: description: PendingWorkloads is the number of Workloads in the LocalQueue not yet admitted to a ClusterQueue format: int32 type: integer reservingWorkloads: description: |- reservingWorkloads is the number of workloads in this LocalQueue reserving quota in a ClusterQueue and that haven't finished yet. format: int32 type: integer type: object type: object served: true storage: true subresources: status: {} --- apiVersion: apiextensions.k8s.io/v1 kind: CustomResourceDefinition metadata: annotations: controller-gen.kubebuilder.io/version: v0.14.0 name: multikueueclusters.kueue.x-k8s.io spec: group: kueue.x-k8s.io names: kind: MultiKueueCluster listKind: MultiKueueClusterList plural: multikueueclusters singular: multikueuecluster scope: Cluster versions: - name: v1alpha1 schema: openAPIV3Schema: description: MultiKueueCluster is the Schema for the multikueue API properties: apiVersion: description: |- APIVersion defines the versioned schema of this representation of an object. Servers should convert recognized schemas to the latest internal value, and may reject unrecognized values. More info: https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#resources type: string kind: description: |- Kind is a string value representing the REST resource this object represents. Servers may infer this from the endpoint the client submits requests to. Cannot be updated. In CamelCase. More info: https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#types-kinds type: string metadata: type: object spec: properties: kubeConfig: description: Information how to connect to the cluster. properties: location: description: |- Location of the KubeConfig. If LocationType is Secret then Location is the name of the secret inside the namespace in which the kueue controller manager is running. The config should be stored in the \"kubeconfig\" key. type: string locationType: default: Secret description: Type of the KubeConfig location. enum: - Secret - Path type: string required: - location - locationType type: object required: - kubeConfig type: object status: properties: conditions: items: description: \"Condition contains details for one aspect of the current state of this API Resource.\\n---\\nThis struct is intended for direct use as an array at the field path .status.conditions. For example,\\n\\n\\n\\ttype FooStatus struct{\\n\\t // Represents the observations of a foo's current state.\\n\\t // Known .status.conditions.type are: \\\"Available\\\", \\\"Progressing\\\", and \\\"Degraded\\\"\\n\\t // +patchMergeKey=type\\n\\t // +patchStrategy=merge\\n\\t // +listType=map\\n\\t \\ // +listMapKey=type\\n\\t Conditions []metav1.Condition `json:\\\"conditions,omitempty\\\" patchStrategy:\\\"merge\\\" patchMergeKey:\\\"type\\\" protobuf:\\\"bytes,1,rep,name=conditions\\\"`\\n\\n\\n\\t \\ // other fields\\n\\t}\" properties: lastTransitionTime: description: |- lastTransitionTime is the last time the condition transitioned from one status to another. This should be when the underlying condition changed. If that is not known, then using the time when the API field changed is acceptable. format: date-time type: string message: description: |- message is a human readable message indicating details about the transition. This may be an empty string. maxLength: 32768 type: string observedGeneration: description: |- observedGeneration represents the .metadata.generation that the condition was set based upon. For instance, if .metadata.generation is currently 12, but the .status.conditions[x].observedGeneration is 9, the condition is out of date with respect to the current state of the instance. format: int64 minimum: 0 type: integer reason: description: |- reason contains a programmatic identifier indicating the reason for the condition's last transition. Producers of specific condition types may define expected values and meanings for this field, and whether the values are considered a guaranteed API. The value should be a CamelCase string. This field may not be empty. maxLength: 1024 minLength: 1 pattern: ^[A-Za-z]([A-Za-z0-9_,:]*[A-Za-z0-9_])?$ type: string status: description: status of the condition, one of True, False, Unknown. enum: - \"True\" - \"False\" - Unknown type: string type: description: |- type of condition in CamelCase or in foo.example.com/CamelCase. --- Many .condition.type values are consistent across resources like Available, but because arbitrary conditions can be useful (see .node.status.conditions), the ability to deconflict is important. The regex it matches is (dns1123SubdomainFmt/)?(qualifiedNameFmt) maxLength: 316 pattern: ^([a-z0-9]([-a-z0-9]*[a-z0-9])?(\\.[a-z0-9]([-a-z0-9]*[a-z0-9])?)*/)?(([A-Za-z0-9][-A-Za-z0-9_.]*)?[A-Za-z0-9])$ type: string required: - lastTransitionTime - message - reason - status - type type: object type: array x-kubernetes-list-map-keys: - type x-kubernetes-list-type: map type: object type: object served: true storage: true subresources: status: {} --- apiVersion: apiextensions.k8s.io/v1 kind: CustomResourceDefinition metadata: annotations: controller-gen.kubebuilder.io/version: v0.14.0 name: multikueueconfigs.kueue.x-k8s.io spec: group: kueue.x-k8s.io names: kind: MultiKueueConfig listKind: MultiKueueConfigList plural: multikueueconfigs singular: multikueueconfig scope: Cluster versions: - name: v1alpha1 schema: openAPIV3Schema: description: MultiKueueConfig is the Schema for the multikueue API properties: apiVersion: description: |- APIVersion defines the versioned schema of this representation of an object. Servers should convert recognized schemas to the latest internal value, and may reject unrecognized values. More info: https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#resources type: string kind: description: |- Kind is a string value representing the REST resource this object represents. Servers may infer this from the endpoint the client submits requests to. Cannot be updated. In CamelCase. More info: https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#types-kinds type: string metadata: type: object spec: description: MultiKueueConfigSpec defines the desired state of MultiKueueConfig properties: clusters: description: List of MultiKueueClusters names where the workloads from the ClusterQueue should be distributed. items: type: string maxItems: 10 minItems: 1 type: array x-kubernetes-list-type: set required: - clusters type: object type: object served: true storage: true --- apiVersion: apiextensions.k8s.io/v1 kind: CustomResourceDefinition metadata: annotations: controller-gen.kubebuilder.io/version: v0.14.0 name: provisioningrequestconfigs.kueue.x-k8s.io spec: group: kueue.x-k8s.io names: kind: ProvisioningRequestConfig listKind: ProvisioningRequestConfigList plural: provisioningrequestconfigs singular: provisioningrequestconfig scope: Cluster versions: - name: v1beta1 schema: openAPIV3Schema: description: ProvisioningRequestConfig is the Schema for the provisioningrequestconfig API properties: apiVersion: description: |- APIVersion defines the versioned schema of this representation of an object. Servers should convert recognized schemas to the latest internal value, and may reject unrecognized values. More info: https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#resources type: string kind: description: |- Kind is a string value representing the REST resource this object represents. Servers may infer this from the endpoint the client submits requests to. Cannot be updated. In CamelCase. More info: https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#types-kinds type: string metadata: type: object spec: description: ProvisioningRequestConfigSpec defines the desired state of ProvisioningRequestConfig properties: managedResources: description: |- managedResources contains the list of resources managed by the autoscaling. If empty, all resources are considered managed. If not empty, the ProvisioningRequest will contain only the podsets that are requesting at least one of them. If none of the workloads podsets is requesting at least a managed resource, the workload is considered ready. items: description: ResourceName is the name identifying various resources in a ResourceList. type: string maxItems: 100 type: array x-kubernetes-list-type: set parameters: additionalProperties: description: Parameter is limited to 255 characters. maxLength: 255 type: string description: Parameters contains all other parameters classes may require. maxProperties: 100 type: object provisioningClassName: description: |- ProvisioningClassName describes the different modes of provisioning the resources. Check autoscaling.x-k8s.io ProvisioningRequestSpec.ProvisioningClassName for details. maxLength: 253 pattern: ^[a-z0-9]([-a-z0-9]*[a-z0-9])?(\\.[a-z0-9]([-a-z0-9]*[a-z0-9])?)*$ type: string required: - provisioningClassName type: object type: object served: true storage: true --- apiVersion: apiextensions.k8s.io/v1 kind: CustomResourceDefinition metadata: annotations: controller-gen.kubebuilder.io/version: v0.14.0 name: resourceflavors.kueue.x-k8s.io spec: group: kueue.x-k8s.io names: kind: ResourceFlavor listKind: ResourceFlavorList plural: resourceflavors shortNames: - flavor - flavors singular: resourceflavor scope: Cluster versions: - name: v1beta1 schema: openAPIV3Schema: description: ResourceFlavor is the Schema for the resourceflavors API. properties: apiVersion: description: |- APIVersion defines the versioned schema of this representation of an object. Servers should convert recognized schemas to the latest internal value, and may reject unrecognized values. More info: https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#resources type: string kind: description: |- Kind is a string value representing the REST resource this object represents. Servers may infer this from the endpoint the client submits requests to. Cannot be updated. In CamelCase. More info: https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#types-kinds type: string metadata: type: object spec: description: ResourceFlavorSpec defines the desired state of the ResourceFlavor properties: nodeLabels: additionalProperties: type: string description: |- nodeLabels are labels that associate the ResourceFlavor with Nodes that have the same labels. When a Workload is admitted, its podsets can only get assigned ResourceFlavors whose nodeLabels match the nodeSelector and nodeAffinity fields. Once a ResourceFlavor is assigned to a podSet, the ResourceFlavor's nodeLabels should be injected into the pods of the Workload by the controller that integrates with the Workload object. nodeLabels can be up to 8 elements. maxProperties: 8 type: object x-kubernetes-map-type: atomic nodeTaints: description: |- nodeTaints are taints that the nodes associated with this ResourceFlavor have. Workloads' podsets must have tolerations for these nodeTaints in order to get assigned this ResourceFlavor during admission. An example of a nodeTaint is cloud.provider.com/preemptible=\"true\":NoSchedule nodeTaints can be up to 8 elements. items: description: |- The node this Taint is attached to has the \"effect\" on any pod that does not tolerate the Taint. properties: effect: description: |- Required. The effect of the taint on pods that do not tolerate the taint. Valid effects are NoSchedule, PreferNoSchedule and NoExecute. type: string key: description: Required. The taint key to be applied to a node. type: string timeAdded: description: |- TimeAdded represents the time at which the taint was added. It is only written for NoExecute taints. format: date-time type: string value: description: The taint value corresponding to the taint key. type: string required: - effect - key type: object maxItems: 8 type: array x-kubernetes-list-type: atomic tolerations: description: |- tolerations are extra tolerations that will be added to the pods admitted in the quota associated with this resource flavor. An example of a toleration is cloud.provider.com/preemptible=\"true\":NoSchedule tolerations can be up to 8 elements. items: description: |- The pod this Toleration is attached to tolerates any taint that matches the triple using the matching operator . properties: effect: description: |- Effect indicates the taint effect to match. Empty means match all taint effects. When specified, allowed values are NoSchedule, PreferNoSchedule and NoExecute. type: string key: description: |- Key is the taint key that the toleration applies to. Empty means match all taint keys. If the key is empty, operator must be Exists; this combination means to match all values and all keys. type: string operator: description: |- Operator represents a key's relationship to the value. Valid operators are Exists and Equal. Defaults to Equal. Exists is equivalent to wildcard for value, so that a pod can tolerate all taints of a particular category. type: string tolerationSeconds: description: |- TolerationSeconds represents the period of time the toleration (which must be of effect NoExecute, otherwise this field is ignored) tolerates the taint. By default, it is not set, which means tolerate the taint forever (do not evict). Zero and negative values will be treated as 0 (evict immediately) by the system. format: int64 type: integer value: description: |- Value is the taint value the toleration matches to. If the operator is Exists, the value should be empty, otherwise just a regular string. type: string type: object maxItems: 8 type: array x-kubernetes-list-type: atomic type: object type: object served: true storage: true --- apiVersion: apiextensions.k8s.io/v1 kind: CustomResourceDefinition metadata: annotations: controller-gen.kubebuilder.io/version: v0.14.0 name: workloadpriorityclasses.kueue.x-k8s.io spec: group: kueue.x-k8s.io names: kind: WorkloadPriorityClass listKind: WorkloadPriorityClassList plural: workloadpriorityclasses singular: workloadpriorityclass scope: Cluster versions: - additionalPrinterColumns: - description: Value of workloadPriorityClass's Priority jsonPath: .value name: Value type: integer name: v1beta1 schema: openAPIV3Schema: description: WorkloadPriorityClass is the Schema for the workloadPriorityClass API properties: apiVersion: description: |- APIVersion defines the versioned schema of this representation of an object. Servers should convert recognized schemas to the latest internal value, and may reject unrecognized values. More info: https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#resources type: string description: description: |- description is an arbitrary string that usually provides guidelines on when this workloadPriorityClass should be used. type: string kind: description: |- Kind is a string value representing the REST resource this object represents. Servers may infer this from the endpoint the client submits requests to. Cannot be updated. In CamelCase. More info: https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#types-kinds type: string metadata: type: object value: description: |- value represents the integer value of this workloadPriorityClass. This is the actual priority that workloads receive when jobs have the name of this class in their workloadPriorityClass label. Changing the value of workloadPriorityClass doesn't affect the priority of workloads that were already created. format: int32 type: integer required: - value type: object served: true storage: true subresources: {} --- apiVersion: apiextensions.k8s.io/v1 kind: CustomResourceDefinition metadata: annotations: cert-manager.io/inject-ca-from: $(CERTIFICATE_NAMESPACE)/$(CERTIFICATE_NAME) controller-gen.kubebuilder.io/version: v0.14.0 name: workloads.kueue.x-k8s.io spec: group: kueue.x-k8s.io names: kind: Workload listKind: WorkloadList plural: workloads shortNames: - wl singular: workload scope: Namespaced versions: - additionalPrinterColumns: - description: Name of the queue this workload was submitted to jsonPath: .spec.queueName name: Queue type: string - description: Name of the ClusterQueue that admitted this workload jsonPath: .status.admission.clusterQueue name: Admitted by type: string - description: Time this workload was created jsonPath: .metadata.creationTimestamp name: Age type: date name: v1beta1 schema: openAPIV3Schema: description: Workload is the Schema for the workloads API properties: apiVersion: description: |- APIVersion defines the versioned schema of this representation of an object. Servers should convert recognized schemas to the latest internal value, and may reject unrecognized values. More info: https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#resources type: string kind: description: |- Kind is a string value representing the REST resource this object represents. Servers may infer this from the endpoint the client submits requests to. Cannot be updated. In CamelCase. More info: https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#types-kinds type: string metadata: type: object spec: description: WorkloadSpec defines the desired state of Workload properties: active: default: true description: |- Active determines if a workload can be admitted into a queue. Changing active from true to false will evict any running workloads. Possible values are: - false: indicates that a workload should never be admitted and evicts running workloads - true: indicates that a workload can be evaluated for admission into it's respective queue. Defaults to true type: boolean podSets: description: |- podSets is a list of sets of homogeneous pods, each described by a Pod spec and a count. There must be at least one element and at most 8. podSets cannot be changed. items: properties: count: description: count is the number of pods for the spec. format: int32 minimum: 1 type: integer minCount: description: |- minCount is the minimum number of pods for the spec acceptable if the workload supports partial admission. If not provided, partial admission for the current PodSet is not enabled. Only one podSet within the workload can use this. This is an alpha field and requires enabling PartialAdmission feature gate. format: int32 type: integer name: description: name is the PodSet name. type: string template: description: |- template is the Pod template. The only allowed fields in template.metadata are labels and annotations. If requests are omitted for a container or initContainer, they default to the limits if they are explicitly specified for the container or initContainer. During admission, the rules in nodeSelector and nodeAffinity.requiredDuringSchedulingIgnoredDuringExecution that match the keys in the nodeLabels from the ResourceFlavors considered for this Workload are used to filter the ResourceFlavors that can be assigned to this podSet. properties: metadata: description: |- Standard object's metadata. More info: https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata properties: annotations: additionalProperties: type: string type: object finalizers: items: type: string type: array labels: additionalProperties: type: string type: object name: type: string namespace: type: string type: object spec: description: |- Specification of the desired behavior of the pod. More info: https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#spec-and-status properties: activeDeadlineSeconds: description: |- Optional duration in seconds the pod may be active on the node relative to StartTime before the system will actively try to mark it failed and kill associated containers. Value must be a positive integer. format: int64 type: integer affinity: description: If specified, the pod's scheduling constraints properties: nodeAffinity: description: Describes node affinity scheduling rules for the pod. properties: preferredDuringSchedulingIgnoredDuringExecution: description: |- The scheduler will prefer to schedule pods to nodes that satisfy the affinity expressions specified by this field, but it may choose a node that violates one or more of the expressions. The node that is most preferred is the one with the greatest sum of weights, i.e. for each node that meets all of the scheduling requirements (resource request, requiredDuringScheduling affinity expressions, etc.), compute a sum by iterating through the elements of this field and adding \"weight\" to the sum if the node matches the corresponding matchExpressions; the node(s) with the highest sum are the most preferred. items: description: |- An empty preferred scheduling term matches all objects with implicit weight 0 (i.e. it's a no-op). A null preferred scheduling term matches no objects (i.e. is also a no-op). properties: preference: description: A node selector term, associated with the corresponding weight. properties: matchExpressions: description: A list of node selector requirements by node's labels. items: description: |- A node selector requirement is a selector that contains values, a key, and an operator that relates the key and values. properties: key: description: The label key that the selector applies to. type: string operator: description: |- Represents a key's relationship to a set of values. Valid operators are In, NotIn, Exists, DoesNotExist. Gt, and Lt. type: string values: description: |- An array of string values. If the operator is In or NotIn, the values array must be non-empty. If the operator is Exists or DoesNotExist, the values array must be empty. If the operator is Gt or Lt, the values array must have a single element, which will be interpreted as an integer. This array is replaced during a strategic merge patch. items: type: string type: array required: - key - operator type: object type: array matchFields: description: A list of node selector requirements by node's fields. items: description: |- A node selector requirement is a selector that contains values, a key, and an operator that relates the key and values. properties: key: description: The label key that the selector applies to. type: string operator: description: |- Represents a key's relationship to a set of values. Valid operators are In, NotIn, Exists, DoesNotExist. Gt, and Lt. type: string values: description: |- An array of string values. If the operator is In or NotIn, the values array must be non-empty. If the operator is Exists or DoesNotExist, the values array must be empty. If the operator is Gt or Lt, the values array must have a single element, which will be interpreted as an integer. This array is replaced during a strategic merge patch. items: type: string type: array required: - key - operator type: object type: array type: object x-kubernetes-map-type: atomic weight: description: Weight associated with matching the corresponding nodeSelectorTerm, in the range 1-100. format: int32 type: integer required: - preference - weight type: object type: array requiredDuringSchedulingIgnoredDuringExecution: description: |- If the affinity requirements specified by this field are not met at scheduling time, the pod will not be scheduled onto the node. If the affinity requirements specified by this field cease to be met at some point during pod execution (e.g. due to an update), the system may or may not try to eventually evict the pod from its node. properties: nodeSelectorTerms: description: Required. A list of node selector terms. The terms are ORed. items: description: |- A null or empty node selector term matches no objects. The requirements of them are ANDed. The TopologySelectorTerm type implements a subset of the NodeSelectorTerm. properties: matchExpressions: description: A list of node selector requirements by node's labels. items: description: |- A node selector requirement is a selector that contains values, a key, and an operator that relates the key and values. properties: key: description: The label key that the selector applies to. type: string operator: description: |- Represents a key's relationship to a set of values. Valid operators are In, NotIn, Exists, DoesNotExist. Gt, and Lt. type: string values: description: |- An array of string values. If the operator is In or NotIn, the values array must be non-empty. If the operator is Exists or DoesNotExist, the values array must be empty. If the operator is Gt or Lt, the values array must have a single element, which will be interpreted as an integer. This array is replaced during a strategic merge patch. items: type: string type: array required: - key - operator type: object type: array matchFields: description: A list of node selector requirements by node's fields. items: description: |- A node selector requirement is a selector that contains values, a key, and an operator that relates the key and values. properties: key: description: The label key that the selector applies to. type: string operator: description: |- Represents a key's relationship to a set of values. Valid operators are In, NotIn, Exists, DoesNotExist. Gt, and Lt. type: string values: description: |- An array of string values. If the operator is In or NotIn, the values array must be non-empty. If the operator is Exists or DoesNotExist, the values array must be empty. If the operator is Gt or Lt, the values array must have a single element, which will be interpreted as an integer. This array is replaced during a strategic merge patch. items: type: string type: array required: - key - operator type: object type: array type: object x-kubernetes-map-type: atomic type: array required: - nodeSelectorTerms type: object x-kubernetes-map-type: atomic type: object podAffinity: description: Describes pod affinity scheduling rules (e.g. co-locate this pod in the same node, zone, etc. as some other pod(s)). properties: preferredDuringSchedulingIgnoredDuringExecution: description: |- The scheduler will prefer to schedule pods to nodes that satisfy the affinity expressions specified by this field, but it may choose a node that violates one or more of the expressions. The node that is most preferred is the one with the greatest sum of weights, i.e. for each node that meets all of the scheduling requirements (resource request, requiredDuringScheduling affinity expressions, etc.), compute a sum by iterating through the elements of this field and adding \"weight\" to the sum if the node has pods which matches the corresponding podAffinityTerm; the node(s) with the highest sum are the most preferred. items: description: The weights of all of the matched WeightedPodAffinityTerm fields are added per-node to find the most preferred node(s) properties: podAffinityTerm: description: Required. A pod affinity term, associated with the corresponding weight. properties: labelSelector: description: |- A label query over a set of resources, in this case pods. If it's null, this PodAffinityTerm matches with no Pods. properties: matchExpressions: description: matchExpressions is a list of label selector requirements. The requirements are ANDed. items: description: |- A label selector requirement is a selector that contains values, a key, and an operator that relates the key and values. properties: key: description: key is the label key that the selector applies to. type: string operator: description: |- operator represents a key's relationship to a set of values. Valid operators are In, NotIn, Exists and DoesNotExist. type: string values: description: |- values is an array of string values. If the operator is In or NotIn, the values array must be non-empty. If the operator is Exists or DoesNotExist, the values array must be empty. This array is replaced during a strategic merge patch. items: type: string type: array required: - key - operator type: object type: array matchLabels: additionalProperties: type: string description: |- matchLabels is a map of {key,value} pairs. A single {key,value} in the matchLabels map is equivalent to an element of matchExpressions, whose key field is \"key\", the operator is \"In\", and the values array contains only \"value\". The requirements are ANDed. type: object type: object x-kubernetes-map-type: atomic matchLabelKeys: description: |- MatchLabelKeys is a set of pod label keys to select which pods will be taken into consideration. The keys are used to lookup values from the incoming pod labels, those key-value labels are merged with `LabelSelector` as `key in (value)` to select the group of existing pods which pods will be taken into consideration for the incoming pod's pod (anti) affinity. Keys that don't exist in the incoming pod labels will be ignored. The default value is empty. The same key is forbidden to exist in both MatchLabelKeys and LabelSelector. Also, MatchLabelKeys cannot be set when LabelSelector isn't set. This is an alpha field and requires enabling MatchLabelKeysInPodAffinity feature gate. items: type: string type: array x-kubernetes-list-type: atomic mismatchLabelKeys: description: |- MismatchLabelKeys is a set of pod label keys to select which pods will be taken into consideration. The keys are used to lookup values from the incoming pod labels, those key-value labels are merged with `LabelSelector` as `key notin (value)` to select the group of existing pods which pods will be taken into consideration for the incoming pod's pod (anti) affinity. Keys that don't exist in the incoming pod labels will be ignored. The default value is empty. The same key is forbidden to exist in both MismatchLabelKeys and LabelSelector. Also, MismatchLabelKeys cannot be set when LabelSelector isn't set. This is an alpha field and requires enabling MatchLabelKeysInPodAffinity feature gate. items: type: string type: array x-kubernetes-list-type: atomic namespaceSelector: description: |- A label query over the set of namespaces that the term applies to. The term is applied to the union of the namespaces selected by this field and the ones listed in the namespaces field. null selector and null or empty namespaces list means \"this pod's namespace\". An empty selector ({}) matches all namespaces. properties: matchExpressions: description: matchExpressions is a list of label selector requirements. The requirements are ANDed. items: description: |- A label selector requirement is a selector that contains values, a key, and an operator that relates the key and values. properties: key: description: key is the label key that the selector applies to. type: string operator: description: |- operator represents a key's relationship to a set of values. Valid operators are In, NotIn, Exists and DoesNotExist. type: string values: description: |- values is an array of string values. If the operator is In or NotIn, the values array must be non-empty. If the operator is Exists or DoesNotExist, the values array must be empty. This array is replaced during a strategic merge patch. items: type: string type: array required: - key - operator type: object type: array matchLabels: additionalProperties: type: string description: |- matchLabels is a map of {key,value} pairs. A single {key,value} in the matchLabels map is equivalent to an element of matchExpressions, whose key field is \"key\", the operator is \"In\", and the values array contains only \"value\". The requirements are ANDed. type: object type: object x-kubernetes-map-type: atomic namespaces: description: |- namespaces specifies a static list of namespace names that the term applies to. The term is applied to the union of the namespaces listed in this field and the ones selected by namespaceSelector. null or empty namespaces list and null namespaceSelector means \"this pod's namespace\". items: type: string type: array topologyKey: description: |- This pod should be co-located (affinity) or not co-located (anti-affinity) with the pods matching the labelSelector in the specified namespaces, where co-located is defined as running on a node whose value of the label with key topologyKey matches that of any node on which any of the selected pods is running. Empty topologyKey is not allowed. type: string required: - topologyKey type: object weight: description: |- weight associated with matching the corresponding podAffinityTerm, in the range 1-100. format: int32 type: integer required: - podAffinityTerm - weight type: object type: array requiredDuringSchedulingIgnoredDuringExecution: description: |- If the affinity requirements specified by this field are not met at scheduling time, the pod will not be scheduled onto the node. If the affinity requirements specified by this field cease to be met at some point during pod execution (e.g. due to a pod label update), the system may or may not try to eventually evict the pod from its node. When there are multiple elements, the lists of nodes corresponding to each podAffinityTerm are intersected, i.e. all terms must be satisfied. items: description: |- Defines a set of pods (namely those matching the labelSelector relative to the given namespace(s)) that this pod should be co-located (affinity) or not co-located (anti-affinity) with, where co-located is defined as running on a node whose value of the label with key matches that of any node on which a pod of the set of pods is running properties: labelSelector: description: |- A label query over a set of resources, in this case pods. If it's null, this PodAffinityTerm matches with no Pods. properties: matchExpressions: description: matchExpressions is a list of label selector requirements. The requirements are ANDed. items: description: |- A label selector requirement is a selector that contains values, a key, and an operator that relates the key and values. properties: key: description: key is the label key that the selector applies to. type: string operator: description: |- operator represents a key's relationship to a set of values. Valid operators are In, NotIn, Exists and DoesNotExist. type: string values: description: |- values is an array of string values. If the operator is In or NotIn, the values array must be non-empty. If the operator is Exists or DoesNotExist, the values array must be empty. This array is replaced during a strategic merge patch. items: type: string type: array required: - key - operator type: object type: array matchLabels: additionalProperties: type: string description: |- matchLabels is a map of {key,value} pairs. A single {key,value} in the matchLabels map is equivalent to an element of matchExpressions, whose key field is \"key\", the operator is \"In\", and the values array contains only \"value\". The requirements are ANDed. type: object type: object x-kubernetes-map-type: atomic matchLabelKeys: description: |- MatchLabelKeys is a set of pod label keys to select which pods will be taken into consideration. The keys are used to lookup values from the incoming pod labels, those key-value labels are merged with `LabelSelector` as `key in (value)` to select the group of existing pods which pods will be taken into consideration for the incoming pod's pod (anti) affinity. Keys that don't exist in the incoming pod labels will be ignored. The default value is empty. The same key is forbidden to exist in both MatchLabelKeys and LabelSelector. Also, MatchLabelKeys cannot be set when LabelSelector isn't set. This is an alpha field and requires enabling MatchLabelKeysInPodAffinity feature gate. items: type: string type: array x-kubernetes-list-type: atomic mismatchLabelKeys: description: |- MismatchLabelKeys is a set of pod label keys to select which pods will be taken into consideration. The keys are used to lookup values from the incoming pod labels, those key-value labels are merged with `LabelSelector` as `key notin (value)` to select the group of existing pods which pods will be taken into consideration for the incoming pod's pod (anti) affinity. Keys that don't exist in the incoming pod labels will be ignored. The default value is empty. The same key is forbidden to exist in both MismatchLabelKeys and LabelSelector. Also, MismatchLabelKeys cannot be set when LabelSelector isn't set. This is an alpha field and requires enabling MatchLabelKeysInPodAffinity feature gate. items: type: string type: array x-kubernetes-list-type: atomic namespaceSelector: description: |- A label query over the set of namespaces that the term applies to. The term is applied to the union of the namespaces selected by this field and the ones listed in the namespaces field. null selector and null or empty namespaces list means \"this pod's namespace\". An empty selector ({}) matches all namespaces. properties: matchExpressions: description: matchExpressions is a list of label selector requirements. The requirements are ANDed. items: description: |- A label selector requirement is a selector that contains values, a key, and an operator that relates the key and values. properties: key: description: key is the label key that the selector applies to. type: string operator: description: |- operator represents a key's relationship to a set of values. Valid operators are In, NotIn, Exists and DoesNotExist. type: string values: description: |- values is an array of string values. If the operator is In or NotIn, the values array must be non-empty. If the operator is Exists or DoesNotExist, the values array must be empty. This array is replaced during a strategic merge patch. items: type: string type: array required: - key - operator type: object type: array matchLabels: additionalProperties: type: string description: |- matchLabels is a map of {key,value} pairs. A single {key,value} in the matchLabels map is equivalent to an element of matchExpressions, whose key field is \"key\", the operator is \"In\", and the values array contains only \"value\". The requirements are ANDed. type: object type: object x-kubernetes-map-type: atomic namespaces: description: |- namespaces specifies a static list of namespace names that the term applies to. The term is applied to the union of the namespaces listed in this field and the ones selected by namespaceSelector. null or empty namespaces list and null namespaceSelector means \"this pod's namespace\". items: type: string type: array topologyKey: description: |- This pod should be co-located (affinity) or not co-located (anti-affinity) with the pods matching the labelSelector in the specified namespaces, where co-located is defined as running on a node whose value of the label with key topologyKey matches that of any node on which any of the selected pods is running. Empty topologyKey is not allowed. type: string required: - topologyKey type: object type: array type: object podAntiAffinity: description: Describes pod anti-affinity scheduling rules (e.g. avoid putting this pod in the same node, zone, etc. as some other pod(s)). properties: preferredDuringSchedulingIgnoredDuringExecution: description: |- The scheduler will prefer to schedule pods to nodes that satisfy the anti-affinity expressions specified by this field, but it may choose a node that violates one or more of the expressions. The node that is most preferred is the one with the greatest sum of weights, i.e. for each node that meets all of the scheduling requirements (resource request, requiredDuringScheduling anti-affinity expressions, etc.), compute a sum by iterating through the elements of this field and adding \"weight\" to the sum if the node has pods which matches the corresponding podAffinityTerm; the node(s) with the highest sum are the most preferred. items: description: The weights of all of the matched WeightedPodAffinityTerm fields are added per-node to find the most preferred node(s) properties: podAffinityTerm: description: Required. A pod affinity term, associated with the corresponding weight. properties: labelSelector: description: |- A label query over a set of resources, in this case pods. If it's null, this PodAffinityTerm matches with no Pods. properties: matchExpressions: description: matchExpressions is a list of label selector requirements. The requirements are ANDed. items: description: |- A label selector requirement is a selector that contains values, a key, and an operator that relates the key and values. properties: key: description: key is the label key that the selector applies to. type: string operator: description: |- operator represents a key's relationship to a set of values. Valid operators are In, NotIn, Exists and DoesNotExist. type: string values: description: |- values is an array of string values. If the operator is In or NotIn, the values array must be non-empty. If the operator is Exists or DoesNotExist, the values array must be empty. This array is replaced during a strategic merge patch. items: type: string type: array required: - key - operator type: object type: array matchLabels: additionalProperties: type: string description: |- matchLabels is a map of {key,value} pairs. A single {key,value} in the matchLabels map is equivalent to an element of matchExpressions, whose key field is \"key\", the operator is \"In\", and the values array contains only \"value\". The requirements are ANDed. type: object type: object x-kubernetes-map-type: atomic matchLabelKeys: description: |- MatchLabelKeys is a set of pod label keys to select which pods will be taken into consideration. The keys are used to lookup values from the incoming pod labels, those key-value labels are merged with `LabelSelector` as `key in (value)` to select the group of existing pods which pods will be taken into consideration for the incoming pod's pod (anti) affinity. Keys that don't exist in the incoming pod labels will be ignored. The default value is empty. The same key is forbidden to exist in both MatchLabelKeys and LabelSelector. Also, MatchLabelKeys cannot be set when LabelSelector isn't set. This is an alpha field and requires enabling MatchLabelKeysInPodAffinity feature gate. items: type: string type: array x-kubernetes-list-type: atomic mismatchLabelKeys: description: |- MismatchLabelKeys is a set of pod label keys to select which pods will be taken into consideration. The keys are used to lookup values from the incoming pod labels, those key-value labels are merged with `LabelSelector` as `key notin (value)` to select the group of existing pods which pods will be taken into consideration for the incoming pod's pod (anti) affinity. Keys that don't exist in the incoming pod labels will be ignored. The default value is empty. The same key is forbidden to exist in both MismatchLabelKeys and LabelSelector. Also, MismatchLabelKeys cannot be set when LabelSelector isn't set. This is an alpha field and requires enabling MatchLabelKeysInPodAffinity feature gate. items: type: string type: array x-kubernetes-list-type: atomic namespaceSelector: description: |- A label query over the set of namespaces that the term applies to. The term is applied to the union of the namespaces selected by this field and the ones listed in the namespaces field. null selector and null or empty namespaces list means \"this pod's namespace\". An empty selector ({}) matches all namespaces. properties: matchExpressions: description: matchExpressions is a list of label selector requirements. The requirements are ANDed. items: description: |- A label selector requirement is a selector that contains values, a key, and an operator that relates the key and values. properties: key: description: key is the label key that the selector applies to. type: string operator: description: |- operator represents a key's relationship to a set of values. Valid operators are In, NotIn, Exists and DoesNotExist. type: string values: description: |- values is an array of string values. If the operator is In or NotIn, the values array must be non-empty. If the operator is Exists or DoesNotExist, the values array must be empty. This array is replaced during a strategic merge patch. items: type: string type: array required: - key - operator type: object type: array matchLabels: additionalProperties: type: string description: |- matchLabels is a map of {key,value} pairs. A single {key,value} in the matchLabels map is equivalent to an element of matchExpressions, whose key field is \"key\", the operator is \"In\", and the values array contains only \"value\". The requirements are ANDed. type: object type: object x-kubernetes-map-type: atomic namespaces: description: |- namespaces specifies a static list of namespace names that the term applies to. The term is applied to the union of the namespaces listed in this field and the ones selected by namespaceSelector. null or empty namespaces list and null namespaceSelector means \"this pod's namespace\". items: type: string type: array topologyKey: description: |- This pod should be co-located (affinity) or not co-located (anti-affinity) with the pods matching the labelSelector in the specified namespaces, where co-located is defined as running on a node whose value of the label with key topologyKey matches that of any node on which any of the selected pods is running. Empty topologyKey is not allowed. type: string required: - topologyKey type: object weight: description: |- weight associated with matching the corresponding podAffinityTerm, in the range 1-100. format: int32 type: integer required: - podAffinityTerm - weight type: object type: array requiredDuringSchedulingIgnoredDuringExecution: description: |- If the anti-affinity requirements specified by this field are not met at scheduling time, the pod will not be scheduled onto the node. If the anti-affinity requirements specified by this field cease to be met at some point during pod execution (e.g. due to a pod label update), the system may or may not try to eventually evict the pod from its node. When there are multiple elements, the lists of nodes corresponding to each podAffinityTerm are intersected, i.e. all terms must be satisfied. items: description: |- Defines a set of pods (namely those matching the labelSelector relative to the given namespace(s)) that this pod should be co-located (affinity) or not co-located (anti-affinity) with, where co-located is defined as running on a node whose value of the label with key matches that of any node on which a pod of the set of pods is running properties: labelSelector: description: |- A label query over a set of resources, in this case pods. If it's null, this PodAffinityTerm matches with no Pods. properties: matchExpressions: description: matchExpressions is a list of label selector requirements. The requirements are ANDed. items: description: |- A label selector requirement is a selector that contains values, a key, and an operator that relates the key and values. properties: key: description: key is the label key that the selector applies to. type: string operator: description: |- operator represents a key's relationship to a set of values. Valid operators are In, NotIn, Exists and DoesNotExist. type: string values: description: |- values is an array of string values. If the operator is In or NotIn, the values array must be non-empty. If the operator is Exists or DoesNotExist, the values array must be empty. This array is replaced during a strategic merge patch. items: type: string type: array required: - key - operator type: object type: array matchLabels: additionalProperties: type: string description: |- matchLabels is a map of {key,value} pairs. A single {key,value} in the matchLabels map is equivalent to an element of matchExpressions, whose key field is \"key\", the operator is \"In\", and the values array contains only \"value\". The requirements are ANDed. type: object type: object x-kubernetes-map-type: atomic matchLabelKeys: description: |- MatchLabelKeys is a set of pod label keys to select which pods will be taken into consideration. The keys are used to lookup values from the incoming pod labels, those key-value labels are merged with `LabelSelector` as `key in (value)` to select the group of existing pods which pods will be taken into consideration for the incoming pod's pod (anti) affinity. Keys that don't exist in the incoming pod labels will be ignored. The default value is empty. The same key is forbidden to exist in both MatchLabelKeys and LabelSelector. Also, MatchLabelKeys cannot be set when LabelSelector isn't set. This is an alpha field and requires enabling MatchLabelKeysInPodAffinity feature gate. items: type: string type: array x-kubernetes-list-type: atomic mismatchLabelKeys: description: |- MismatchLabelKeys is a set of pod label keys to select which pods will be taken into consideration. The keys are used to lookup values from the incoming pod labels, those key-value labels are merged with `LabelSelector` as `key notin (value)` to select the group of existing pods which pods will be taken into consideration for the incoming pod's pod (anti) affinity. Keys that don't exist in the incoming pod labels will be ignored. The default value is empty. The same key is forbidden to exist in both MismatchLabelKeys and LabelSelector. Also, MismatchLabelKeys cannot be set when LabelSelector isn't set. This is an alpha field and requires enabling MatchLabelKeysInPodAffinity feature gate. items: type: string type: array x-kubernetes-list-type: atomic namespaceSelector: description: |- A label query over the set of namespaces that the term applies to. The term is applied to the union of the namespaces selected by this field and the ones listed in the namespaces field. null selector and null or empty namespaces list means \"this pod's namespace\". An empty selector ({}) matches all namespaces. properties: matchExpressions: description: matchExpressions is a list of label selector requirements. The requirements are ANDed. items: description: |- A label selector requirement is a selector that contains values, a key, and an operator that relates the key and values. properties: key: description: key is the label key that the selector applies to. type: string operator: description: |- operator represents a key's relationship to a set of values. Valid operators are In, NotIn, Exists and DoesNotExist. type: string values: description: |- values is an array of string values. If the operator is In or NotIn, the values array must be non-empty. If the operator is Exists or DoesNotExist, the values array must be empty. This array is replaced during a strategic merge patch. items: type: string type: array required: - key - operator type: object type: array matchLabels: additionalProperties: type: string description: |- matchLabels is a map of {key,value} pairs. A single {key,value} in the matchLabels map is equivalent to an element of matchExpressions, whose key field is \"key\", the operator is \"In\", and the values array contains only \"value\". The requirements are ANDed. type: object type: object x-kubernetes-map-type: atomic namespaces: description: |- namespaces specifies a static list of namespace names that the term applies to. The term is applied to the union of the namespaces listed in this field and the ones selected by namespaceSelector. null or empty namespaces list and null namespaceSelector means \"this pod's namespace\". items: type: string type: array topologyKey: description: |- This pod should be co-located (affinity) or not co-located (anti-affinity) with the pods matching the labelSelector in the specified namespaces, where co-located is defined as running on a node whose value of the label with key topologyKey matches that of any node on which any of the selected pods is running. Empty topologyKey is not allowed. type: string required: - topologyKey type: object type: array type: object type: object automountServiceAccountToken: description: AutomountServiceAccountToken indicates whether a service account token should be automatically mounted. type: boolean containers: description: |- List of containers belonging to the pod. Containers cannot currently be added or removed. There must be at least one container in a Pod. Cannot be updated. items: description: A single application container that you want to run within a pod. properties: args: description: |- Arguments to the entrypoint. The container image's CMD is used if this is not provided. Variable references $(VAR_NAME) are expanded using the container's environment. If a variable cannot be resolved, the reference in the input string will be unchanged. Double $ are reduced to a single $, which allows for escaping the $(VAR_NAME) syntax: i.e. \"$(VAR_NAME)\" will produce the string literal \"$(VAR_NAME)\". Escaped references will never be expanded, regardless of whether the variable exists or not. Cannot be updated. More info: https://kubernetes.io/docs/tasks/inject-data-application/define-command-argument-container/#running-a-command-in-a-shell items: type: string type: array command: description: |- Entrypoint array. Not executed within a shell. The container image's ENTRYPOINT is used if this is not provided. Variable references $(VAR_NAME) are expanded using the container's environment. If a variable cannot be resolved, the reference in the input string will be unchanged. Double $ are reduced to a single $, which allows for escaping the $(VAR_NAME) syntax: i.e. \"$(VAR_NAME)\" will produce the string literal \"$(VAR_NAME)\". Escaped references will never be expanded, regardless of whether the variable exists or not. Cannot be updated. More info: https://kubernetes.io/docs/tasks/inject-data-application/define-command-argument-container/#running-a-command-in-a-shell items: type: string type: array env: description: |- List of environment variables to set in the container. Cannot be updated. items: description: EnvVar represents an environment variable present in a Container. properties: name: description: Name of the environment variable. Must be a C_IDENTIFIER. type: string value: description: |- Variable references $(VAR_NAME) are expanded using the previously defined environment variables in the container and any service environment variables. If a variable cannot be resolved, the reference in the input string will be unchanged. Double $ are reduced to a single $, which allows for escaping the $(VAR_NAME) syntax: i.e. \"$(VAR_NAME)\" will produce the string literal \"$(VAR_NAME)\". Escaped references will never be expanded, regardless of whether the variable exists or not. Defaults to \"\". type: string valueFrom: description: Source for the environment variable's value. Cannot be used if value is not empty. properties: configMapKeyRef: description: Selects a key of a ConfigMap. properties: key: description: The key to select. type: string name: description: |- Name of the referent. More info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names TODO: Add other useful fields. apiVersion, kind, uid? type: string optional: description: Specify whether the ConfigMap or its key must be defined type: boolean required: - key type: object x-kubernetes-map-type: atomic fieldRef: description: |- Selects a field of the pod: supports metadata.name, metadata.namespace, `metadata.labels['']`, `metadata.annotations['']`, spec.nodeName, spec.serviceAccountName, status.hostIP, status.podIP, status.podIPs. properties: apiVersion: description: Version of the schema the FieldPath is written in terms of, defaults to \"v1\". type: string fieldPath: description: Path of the field to select in the specified API version. type: string required: - fieldPath type: object x-kubernetes-map-type: atomic resourceFieldRef: description: |- Selects a resource of the container: only resources limits and requests (limits.cpu, limits.memory, limits.ephemeral-storage, requests.cpu, requests.memory and requests.ephemeral-storage) are currently supported. properties: containerName: description: 'Container name: required for volumes, optional for env vars' type: string divisor: anyOf: - type: integer - type: string description: Specifies the output format of the exposed resources, defaults to \"1\" pattern: ^(\\+|-)?(([0-9]+(\\.[0-9]*)?)|(\\.[0-9]+))(([KMGTPE]i)|[numkMGTPE]|([eE](\\+|-)?(([0-9]+(\\.[0-9]*)?)|(\\.[0-9]+))))?$ x-kubernetes-int-or-string: true resource: description: 'Required: resource to select' type: string required: - resource type: object x-kubernetes-map-type: atomic secretKeyRef: description: Selects a key of a secret in the pod's namespace properties: key: description: The key of the secret to select from. Must be a valid secret key. type: string name: description: |- Name of the referent. More info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names TODO: Add other useful fields. apiVersion, kind, uid? type: string optional: description: Specify whether the Secret or its key must be defined type: boolean required: - key type: object x-kubernetes-map-type: atomic type: object required: - name type: object type: array envFrom: description: |- List of sources to populate environment variables in the container. The keys defined within a source must be a C_IDENTIFIER. All invalid keys will be reported as an event when the container is starting. When a key exists in multiple sources, the value associated with the last source will take precedence. Values defined by an Env with a duplicate key will take precedence. Cannot be updated. items: description: EnvFromSource represents the source of a set of ConfigMaps properties: configMapRef: description: The ConfigMap to select from properties: name: description: |- Name of the referent. More info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names TODO: Add other useful fields. apiVersion, kind, uid? type: string optional: description: Specify whether the ConfigMap must be defined type: boolean type: object x-kubernetes-map-type: atomic prefix: description: An optional identifier to prepend to each key in the ConfigMap. Must be a C_IDENTIFIER. type: string secretRef: description: The Secret to select from properties: name: description: |- Name of the referent. More info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names TODO: Add other useful fields. apiVersion, kind, uid? type: string optional: description: Specify whether the Secret must be defined type: boolean type: object x-kubernetes-map-type: atomic type: object type: array image: description: |- Container image name. More info: https://kubernetes.io/docs/concepts/containers/images This field is optional to allow higher level config management to default or override container images in workload controllers like Deployments and StatefulSets. type: string imagePullPolicy: description: |- Image pull policy. One of Always, Never, IfNotPresent. Defaults to Always if :latest tag is specified, or IfNotPresent otherwise. Cannot be updated. More info: https://kubernetes.io/docs/concepts/containers/images#updating-images type: string lifecycle: description: |- Actions that the management system should take in response to container lifecycle events. Cannot be updated. properties: postStart: description: |- PostStart is called immediately after a container is created. If the handler fails, the container is terminated and restarted according to its restart policy. Other management of the container blocks until the hook completes. More info: https://kubernetes.io/docs/concepts/containers/container-lifecycle-hooks/#container-hooks properties: exec: description: Exec specifies the action to take. properties: command: description: |- Command is the command line to execute inside the container, the working directory for the command is root ('/') in the container's filesystem. The command is simply exec'd, it is not run inside a shell, so traditional shell instructions ('|', etc) won't work. To use a shell, you need to explicitly call out to that shell. Exit status of 0 is treated as live/healthy and non-zero is unhealthy. items: type: string type: array type: object httpGet: description: HTTPGet specifies the http request to perform. properties: host: description: |- Host name to connect to, defaults to the pod IP. You probably want to set \"Host\" in httpHeaders instead. type: string httpHeaders: description: Custom headers to set in the request. HTTP allows repeated headers. items: description: HTTPHeader describes a custom header to be used in HTTP probes properties: name: description: |- The header field name. This will be canonicalized upon output, so case-variant names will be understood as the same header. type: string value: description: The header field value type: string required: - name - value type: object type: array path: description: Path to access on the HTTP server. type: string port: anyOf: - type: integer - type: string description: |- Name or number of the port to access on the container. Number must be in the range 1 to 65535. Name must be an IANA_SVC_NAME. x-kubernetes-int-or-string: true scheme: description: |- Scheme to use for connecting to the host. Defaults to HTTP. type: string required: - port type: object sleep: description: Sleep represents the duration that the container should sleep before being terminated. properties: seconds: description: Seconds is the number of seconds to sleep. format: int64 type: integer required: - seconds type: object tcpSocket: description: |- Deprecated. TCPSocket is NOT supported as a LifecycleHandler and kept for the backward compatibility. There are no validation of this field and lifecycle hooks will fail in runtime when tcp handler is specified. properties: host: description: 'Optional: Host name to connect to, defaults to the pod IP.' type: string port: anyOf: - type: integer - type: string description: |- Number or name of the port to access on the container. Number must be in the range 1 to 65535. Name must be an IANA_SVC_NAME. x-kubernetes-int-or-string: true required: - port type: object type: object preStop: description: |- PreStop is called immediately before a container is terminated due to an API request or management event such as liveness/startup probe failure, preemption, resource contention, etc. The handler is not called if the container crashes or exits. The Pod's termination grace period countdown begins before the PreStop hook is executed. Regardless of the outcome of the handler, the container will eventually terminate within the Pod's termination grace period (unless delayed by finalizers). Other management of the container blocks until the hook completes or until the termination grace period is reached. More info: https://kubernetes.io/docs/concepts/containers/container-lifecycle-hooks/#container-hooks properties: exec: description: Exec specifies the action to take. properties: command: description: |- Command is the command line to execute inside the container, the working directory for the command is root ('/') in the container's filesystem. The command is simply exec'd, it is not run inside a shell, so traditional shell instructions ('|', etc) won't work. To use a shell, you need to explicitly call out to that shell. Exit status of 0 is treated as live/healthy and non-zero is unhealthy. items: type: string type: array type: object httpGet: description: HTTPGet specifies the http request to perform. properties: host: description: |- Host name to connect to, defaults to the pod IP. You probably want to set \"Host\" in httpHeaders instead. type: string httpHeaders: description: Custom headers to set in the request. HTTP allows repeated headers. items: description: HTTPHeader describes a custom header to be used in HTTP probes properties: name: description: |- The header field name. This will be canonicalized upon output, so case-variant names will be understood as the same header. type: string value: description: The header field value type: string required: - name - value type: object type: array path: description: Path to access on the HTTP server. type: string port: anyOf: - type: integer - type: string description: |- Name or number of the port to access on the container. Number must be in the range 1 to 65535. Name must be an IANA_SVC_NAME. x-kubernetes-int-or-string: true scheme: description: |- Scheme to use for connecting to the host. Defaults to HTTP. type: string required: - port type: object sleep: description: Sleep represents the duration that the container should sleep before being terminated. properties: seconds: description: Seconds is the number of seconds to sleep. format: int64 type: integer required: - seconds type: object tcpSocket: description: |- Deprecated. TCPSocket is NOT supported as a LifecycleHandler and kept for the backward compatibility. There are no validation of this field and lifecycle hooks will fail in runtime when tcp handler is specified. properties: host: description: 'Optional: Host name to connect to, defaults to the pod IP.' type: string port: anyOf: - type: integer - type: string description: |- Number or name of the port to access on the container. Number must be in the range 1 to 65535. Name must be an IANA_SVC_NAME. x-kubernetes-int-or-string: true required: - port type: object type: object type: object livenessProbe: description: |- Periodic probe of container liveness. Container will be restarted if the probe fails. Cannot be updated. More info: https://kubernetes.io/docs/concepts/workloads/pods/pod-lifecycle#container-probes properties: exec: description: Exec specifies the action to take. properties: command: description: |- Command is the command line to execute inside the container, the working directory for the command is root ('/') in the container's filesystem. The command is simply exec'd, it is not run inside a shell, so traditional shell instructions ('|', etc) won't work. To use a shell, you need to explicitly call out to that shell. Exit status of 0 is treated as live/healthy and non-zero is unhealthy. items: type: string type: array type: object failureThreshold: description: |- Minimum consecutive failures for the probe to be considered failed after having succeeded. Defaults to 3. Minimum value is 1. format: int32 type: integer grpc: description: GRPC specifies an action involving a GRPC port. properties: port: description: Port number of the gRPC service. Number must be in the range 1 to 65535. format: int32 type: integer service: description: |- Service is the name of the service to place in the gRPC HealthCheckRequest (see https://github.com/grpc/grpc/blob/master/doc/health-checking.md). If this is not specified, the default behavior is defined by gRPC. type: string required: - port type: object httpGet: description: HTTPGet specifies the http request to perform. properties: host: description: |- Host name to connect to, defaults to the pod IP. You probably want to set \"Host\" in httpHeaders instead. type: string httpHeaders: description: Custom headers to set in the request. HTTP allows repeated headers. items: description: HTTPHeader describes a custom header to be used in HTTP probes properties: name: description: |- The header field name. This will be canonicalized upon output, so case-variant names will be understood as the same header. type: string value: description: The header field value type: string required: - name - value type: object type: array path: description: Path to access on the HTTP server. type: string port: anyOf: - type: integer - type: string description: |- Name or number of the port to access on the container. Number must be in the range 1 to 65535. Name must be an IANA_SVC_NAME. x-kubernetes-int-or-string: true scheme: description: |- Scheme to use for connecting to the host. Defaults to HTTP. type: string required: - port type: object initialDelaySeconds: description: |- Number of seconds after the container has started before liveness probes are initiated. More info: https://kubernetes.io/docs/concepts/workloads/pods/pod-lifecycle#container-probes format: int32 type: integer periodSeconds: description: |- How often (in seconds) to perform the probe. Default to 10 seconds. Minimum value is 1. format: int32 type: integer successThreshold: description: |- Minimum consecutive successes for the probe to be considered successful after having failed. Defaults to 1. Must be 1 for liveness and startup. Minimum value is 1. format: int32 type: integer tcpSocket: description: TCPSocket specifies an action involving a TCP port. properties: host: description: 'Optional: Host name to connect to, defaults to the pod IP.' type: string port: anyOf: - type: integer - type: string description: |- Number or name of the port to access on the container. Number must be in the range 1 to 65535. Name must be an IANA_SVC_NAME. x-kubernetes-int-or-string: true required: - port type: object terminationGracePeriodSeconds: description: |- Optional duration in seconds the pod needs to terminate gracefully upon probe failure. The grace period is the duration in seconds after the processes running in the pod are sent a termination signal and the time when the processes are forcibly halted with a kill signal. Set this value longer than the expected cleanup time for your process. If this value is nil, the pod's terminationGracePeriodSeconds will be used. Otherwise, this value overrides the value provided by the pod spec. Value must be non-negative integer. The value zero indicates stop immediately via the kill signal (no opportunity to shut down). This is a beta field and requires enabling ProbeTerminationGracePeriod feature gate. Minimum value is 1. spec.terminationGracePeriodSeconds is used if unset. format: int64 type: integer timeoutSeconds: description: |- Number of seconds after which the probe times out. Defaults to 1 second. Minimum value is 1. More info: https://kubernetes.io/docs/concepts/workloads/pods/pod-lifecycle#container-probes format: int32 type: integer type: object name: description: |- Name of the container specified as a DNS_LABEL. Each container in a pod must have a unique name (DNS_LABEL). Cannot be updated. type: string ports: description: |- List of ports to expose from the container. Not specifying a port here DOES NOT prevent that port from being exposed. Any port which is listening on the default \"0.0.0.0\" address inside a container will be accessible from the network. Modifying this array with strategic merge patch may corrupt the data. For more information See https://github.com/kubernetes/kubernetes/issues/108255. Cannot be updated. items: description: ContainerPort represents a network port in a single container. properties: containerPort: description: |- Number of port to expose on the pod's IP address. This must be a valid port number, 0 ']`, `metadata.annotations['']`, spec.nodeName, spec.serviceAccountName, status.hostIP, status.podIP, status.podIPs. properties: apiVersion: description: Version of the schema the FieldPath is written in terms of, defaults to \"v1\". type: string fieldPath: description: Path of the field to select in the specified API version. type: string required: - fieldPath type: object x-kubernetes-map-type: atomic resourceFieldRef: description: |- Selects a resource of the container: only resources limits and requests (limits.cpu, limits.memory, limits.ephemeral-storage, requests.cpu, requests.memory and requests.ephemeral-storage) are currently supported. properties: containerName: description: 'Container name: required for volumes, optional for env vars' type: string divisor: anyOf: - type: integer - type: string description: Specifies the output format of the exposed resources, defaults to \"1\" pattern: ^(\\+|-)?(([0-9]+(\\.[0-9]*)?)|(\\.[0-9]+))(([KMGTPE]i)|[numkMGTPE]|([eE](\\+|-)?(([0-9]+(\\.[0-9]*)?)|(\\.[0-9]+))))?$ x-kubernetes-int-or-string: true resource: description: 'Required: resource to select' type: string required: - resource type: object x-kubernetes-map-type: atomic secretKeyRef: description: Selects a key of a secret in the pod's namespace properties: key: description: The key of the secret to select from. Must be a valid secret key. type: string name: description: |- Name of the referent. More info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names TODO: Add other useful fields. apiVersion, kind, uid? type: string optional: description: Specify whether the Secret or its key must be defined type: boolean required: - key type: object x-kubernetes-map-type: atomic type: object required: - name type: object type: array envFrom: description: |- List of sources to populate environment variables in the container. The keys defined within a source must be a C_IDENTIFIER. All invalid keys will be reported as an event when the container is starting. When a key exists in multiple sources, the value associated with the last source will take precedence. Values defined by an Env with a duplicate key will take precedence. Cannot be updated. items: description: EnvFromSource represents the source of a set of ConfigMaps properties: configMapRef: description: The ConfigMap to select from properties: name: description: |- Name of the referent. More info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names TODO: Add other useful fields. apiVersion, kind, uid? type: string optional: description: Specify whether the ConfigMap must be defined type: boolean type: object x-kubernetes-map-type: atomic prefix: description: An optional identifier to prepend to each key in the ConfigMap. Must be a C_IDENTIFIER. type: string secretRef: description: The Secret to select from properties: name: description: |- Name of the referent. More info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names TODO: Add other useful fields. apiVersion, kind, uid? type: string optional: description: Specify whether the Secret must be defined type: boolean type: object x-kubernetes-map-type: atomic type: object type: array image: description: |- Container image name. More info: https://kubernetes.io/docs/concepts/containers/images type: string imagePullPolicy: description: |- Image pull policy. One of Always, Never, IfNotPresent. Defaults to Always if :latest tag is specified, or IfNotPresent otherwise. Cannot be updated. More info: https://kubernetes.io/docs/concepts/containers/images#updating-images type: string lifecycle: description: Lifecycle is not allowed for ephemeral containers. properties: postStart: description: |- PostStart is called immediately after a container is created. If the handler fails, the container is terminated and restarted according to its restart policy. Other management of the container blocks until the hook completes. More info: https://kubernetes.io/docs/concepts/containers/container-lifecycle-hooks/#container-hooks properties: exec: description: Exec specifies the action to take. properties: command: description: |- Command is the command line to execute inside the container, the working directory for the command is root ('/') in the container's filesystem. The command is simply exec'd, it is not run inside a shell, so traditional shell instructions ('|', etc) won't work. To use a shell, you need to explicitly call out to that shell. Exit status of 0 is treated as live/healthy and non-zero is unhealthy. items: type: string type: array type: object httpGet: description: HTTPGet specifies the http request to perform. properties: host: description: |- Host name to connect to, defaults to the pod IP. You probably want to set \"Host\" in httpHeaders instead. type: string httpHeaders: description: Custom headers to set in the request. HTTP allows repeated headers. items: description: HTTPHeader describes a custom header to be used in HTTP probes properties: name: description: |- The header field name. This will be canonicalized upon output, so case-variant names will be understood as the same header. type: string value: description: The header field value type: string required: - name - value type: object type: array path: description: Path to access on the HTTP server. type: string port: anyOf: - type: integer - type: string description: |- Name or number of the port to access on the container. Number must be in the range 1 to 65535. Name must be an IANA_SVC_NAME. x-kubernetes-int-or-string: true scheme: description: |- Scheme to use for connecting to the host. Defaults to HTTP. type: string required: - port type: object sleep: description: Sleep represents the duration that the container should sleep before being terminated. properties: seconds: description: Seconds is the number of seconds to sleep. format: int64 type: integer required: - seconds type: object tcpSocket: description: |- Deprecated. TCPSocket is NOT supported as a LifecycleHandler and kept for the backward compatibility. There are no validation of this field and lifecycle hooks will fail in runtime when tcp handler is specified. properties: host: description: 'Optional: Host name to connect to, defaults to the pod IP.' type: string port: anyOf: - type: integer - type: string description: |- Number or name of the port to access on the container. Number must be in the range 1 to 65535. Name must be an IANA_SVC_NAME. x-kubernetes-int-or-string: true required: - port type: object type: object preStop: description: |- PreStop is called immediately before a container is terminated due to an API request or management event such as liveness/startup probe failure, preemption, resource contention, etc. The handler is not called if the container crashes or exits. The Pod's termination grace period countdown begins before the PreStop hook is executed. Regardless of the outcome of the handler, the container will eventually terminate within the Pod's termination grace period (unless delayed by finalizers). Other management of the container blocks until the hook completes or until the termination grace period is reached. More info: https://kubernetes.io/docs/concepts/containers/container-lifecycle-hooks/#container-hooks properties: exec: description: Exec specifies the action to take. properties: command: description: |- Command is the command line to execute inside the container, the working directory for the command is root ('/') in the container's filesystem. The command is simply exec'd, it is not run inside a shell, so traditional shell instructions ('|', etc) won't work. To use a shell, you need to explicitly call out to that shell. Exit status of 0 is treated as live/healthy and non-zero is unhealthy. items: type: string type: array type: object httpGet: description: HTTPGet specifies the http request to perform. properties: host: description: |- Host name to connect to, defaults to the pod IP. You probably want to set \"Host\" in httpHeaders instead. type: string httpHeaders: description: Custom headers to set in the request. HTTP allows repeated headers. items: description: HTTPHeader describes a custom header to be used in HTTP probes properties: name: description: |- The header field name. This will be canonicalized upon output, so case-variant names will be understood as the same header. type: string value: description: The header field value type: string required: - name - value type: object type: array path: description: Path to access on the HTTP server. type: string port: anyOf: - type: integer - type: string description: |- Name or number of the port to access on the container. Number must be in the range 1 to 65535. Name must be an IANA_SVC_NAME. x-kubernetes-int-or-string: true scheme: description: |- Scheme to use for connecting to the host. Defaults to HTTP. type: string required: - port type: object sleep: description: Sleep represents the duration that the container should sleep before being terminated. properties: seconds: description: Seconds is the number of seconds to sleep. format: int64 type: integer required: - seconds type: object tcpSocket: description: |- Deprecated. TCPSocket is NOT supported as a LifecycleHandler and kept for the backward compatibility. There are no validation of this field and lifecycle hooks will fail in runtime when tcp handler is specified. properties: host: description: 'Optional: Host name to connect to, defaults to the pod IP.' type: string port: anyOf: - type: integer - type: string description: |- Number or name of the port to access on the container. Number must be in the range 1 to 65535. Name must be an IANA_SVC_NAME. x-kubernetes-int-or-string: true required: - port type: object type: object type: object livenessProbe: description: Probes are not allowed for ephemeral containers. properties: exec: description: Exec specifies the action to take. properties: command: description: |- Command is the command line to execute inside the container, the working directory for the command is root ('/') in the container's filesystem. The command is simply exec'd, it is not run inside a shell, so traditional shell instructions ('|', etc) won't work. To use a shell, you need to explicitly call out to that shell. Exit status of 0 is treated as live/healthy and non-zero is unhealthy. items: type: string type: array type: object failureThreshold: description: |- Minimum consecutive failures for the probe to be considered failed after having succeeded. Defaults to 3. Minimum value is 1. format: int32 type: integer grpc: description: GRPC specifies an action involving a GRPC port. properties: port: description: Port number of the gRPC service. Number must be in the range 1 to 65535. format: int32 type: integer service: description: |- Service is the name of the service to place in the gRPC HealthCheckRequest (see https://github.com/grpc/grpc/blob/master/doc/health-checking.md). If this is not specified, the default behavior is defined by gRPC. type: string required: - port type: object httpGet: description: HTTPGet specifies the http request to perform. properties: host: description: |- Host name to connect to, defaults to the pod IP. You probably want to set \"Host\" in httpHeaders instead. type: string httpHeaders: description: Custom headers to set in the request. HTTP allows repeated headers. items: description: HTTPHeader describes a custom header to be used in HTTP probes properties: name: description: |- The header field name. This will be canonicalized upon output, so case-variant names will be understood as the same header. type: string value: description: The header field value type: string required: - name - value type: object type: array path: description: Path to access on the HTTP server. type: string port: anyOf: - type: integer - type: string description: |- Name or number of the port to access on the container. Number must be in the range 1 to 65535. Name must be an IANA_SVC_NAME. x-kubernetes-int-or-string: true scheme: description: |- Scheme to use for connecting to the host. Defaults to HTTP. type: string required: - port type: object initialDelaySeconds: description: |- Number of seconds after the container has started before liveness probes are initiated. More info: https://kubernetes.io/docs/concepts/workloads/pods/pod-lifecycle#container-probes format: int32 type: integer periodSeconds: description: |- How often (in seconds) to perform the probe. Default to 10 seconds. Minimum value is 1. format: int32 type: integer successThreshold: description: |- Minimum consecutive successes for the probe to be considered successful after having failed. Defaults to 1. Must be 1 for liveness and startup. Minimum value is 1. format: int32 type: integer tcpSocket: description: TCPSocket specifies an action involving a TCP port. properties: host: description: 'Optional: Host name to connect to, defaults to the pod IP.' type: string port: anyOf: - type: integer - type: string description: |- Number or name of the port to access on the container. Number must be in the range 1 to 65535. Name must be an IANA_SVC_NAME. x-kubernetes-int-or-string: true required: - port type: object terminationGracePeriodSeconds: description: |- Optional duration in seconds the pod needs to terminate gracefully upon probe failure. The grace period is the duration in seconds after the processes running in the pod are sent a termination signal and the time when the processes are forcibly halted with a kill signal. Set this value longer than the expected cleanup time for your process. If this value is nil, the pod's terminationGracePeriodSeconds will be used. Otherwise, this value overrides the value provided by the pod spec. Value must be non-negative integer. The value zero indicates stop immediately via the kill signal (no opportunity to shut down). This is a beta field and requires enabling ProbeTerminationGracePeriod feature gate. Minimum value is 1. spec.terminationGracePeriodSeconds is used if unset. format: int64 type: integer timeoutSeconds: description: |- Number of seconds after which the probe times out. Defaults to 1 second. Minimum value is 1. More info: https://kubernetes.io/docs/concepts/workloads/pods/pod-lifecycle#container-probes format: int32 type: integer type: object name: description: |- Name of the ephemeral container specified as a DNS_LABEL. This name must be unique among all containers, init containers and ephemeral containers. type: string ports: description: Ports are not allowed for ephemeral containers. items: description: ContainerPort represents a network port in a single container. properties: containerPort: description: |- Number of port to expose on the pod's IP address. This must be a valid port number, 0 ']`, `metadata.annotations['']`, spec.nodeName, spec.serviceAccountName, status.hostIP, status.podIP, status.podIPs. properties: apiVersion: description: Version of the schema the FieldPath is written in terms of, defaults to \"v1\". type: string fieldPath: description: Path of the field to select in the specified API version. type: string required: - fieldPath type: object x-kubernetes-map-type: atomic resourceFieldRef: description: |- Selects a resource of the container: only resources limits and requests (limits.cpu, limits.memory, limits.ephemeral-storage, requests.cpu, requests.memory and requests.ephemeral-storage) are currently supported. properties: containerName: description: 'Container name: required for volumes, optional for env vars' type: string divisor: anyOf: - type: integer - type: string description: Specifies the output format of the exposed resources, defaults to \"1\" pattern: ^(\\+|-)?(([0-9]+(\\.[0-9]*)?)|(\\.[0-9]+))(([KMGTPE]i)|[numkMGTPE]|([eE](\\+|-)?(([0-9]+(\\.[0-9]*)?)|(\\.[0-9]+))))?$ x-kubernetes-int-or-string: true resource: description: 'Required: resource to select' type: string required: - resource type: object x-kubernetes-map-type: atomic secretKeyRef: description: Selects a key of a secret in the pod's namespace properties: key: description: The key of the secret to select from. Must be a valid secret key. type: string name: description: |- Name of the referent. More info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names TODO: Add other useful fields. apiVersion, kind, uid? type: string optional: description: Specify whether the Secret or its key must be defined type: boolean required: - key type: object x-kubernetes-map-type: atomic type: object required: - name type: object type: array envFrom: description: |- List of sources to populate environment variables in the container. The keys defined within a source must be a C_IDENTIFIER. All invalid keys will be reported as an event when the container is starting. When a key exists in multiple sources, the value associated with the last source will take precedence. Values defined by an Env with a duplicate key will take precedence. Cannot be updated. items: description: EnvFromSource represents the source of a set of ConfigMaps properties: configMapRef: description: The ConfigMap to select from properties: name: description: |- Name of the referent. More info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names TODO: Add other useful fields. apiVersion, kind, uid? type: string optional: description: Specify whether the ConfigMap must be defined type: boolean type: object x-kubernetes-map-type: atomic prefix: description: An optional identifier to prepend to each key in the ConfigMap. Must be a C_IDENTIFIER. type: string secretRef: description: The Secret to select from properties: name: description: |- Name of the referent. More info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names TODO: Add other useful fields. apiVersion, kind, uid? type: string optional: description: Specify whether the Secret must be defined type: boolean type: object x-kubernetes-map-type: atomic type: object type: array image: description: |- Container image name. More info: https://kubernetes.io/docs/concepts/containers/images This field is optional to allow higher level config management to default or override container images in workload controllers like Deployments and StatefulSets. type: string imagePullPolicy: description: |- Image pull policy. One of Always, Never, IfNotPresent. Defaults to Always if :latest tag is specified, or IfNotPresent otherwise. Cannot be updated. More info: https://kubernetes.io/docs/concepts/containers/images#updating-images type: string lifecycle: description: |- Actions that the management system should take in response to container lifecycle events. Cannot be updated. properties: postStart: description: |- PostStart is called immediately after a container is created. If the handler fails, the container is terminated and restarted according to its restart policy. Other management of the container blocks until the hook completes. More info: https://kubernetes.io/docs/concepts/containers/container-lifecycle-hooks/#container-hooks properties: exec: description: Exec specifies the action to take. properties: command: description: |- Command is the command line to execute inside the container, the working directory for the command is root ('/') in the container's filesystem. The command is simply exec'd, it is not run inside a shell, so traditional shell instructions ('|', etc) won't work. To use a shell, you need to explicitly call out to that shell. Exit status of 0 is treated as live/healthy and non-zero is unhealthy. items: type: string type: array type: object httpGet: description: HTTPGet specifies the http request to perform. properties: host: description: |- Host name to connect to, defaults to the pod IP. You probably want to set \"Host\" in httpHeaders instead. type: string httpHeaders: description: Custom headers to set in the request. HTTP allows repeated headers. items: description: HTTPHeader describes a custom header to be used in HTTP probes properties: name: description: |- The header field name. This will be canonicalized upon output, so case-variant names will be understood as the same header. type: string value: description: The header field value type: string required: - name - value type: object type: array path: description: Path to access on the HTTP server. type: string port: anyOf: - type: integer - type: string description: |- Name or number of the port to access on the container. Number must be in the range 1 to 65535. Name must be an IANA_SVC_NAME. x-kubernetes-int-or-string: true scheme: description: |- Scheme to use for connecting to the host. Defaults to HTTP. type: string required: - port type: object sleep: description: Sleep represents the duration that the container should sleep before being terminated. properties: seconds: description: Seconds is the number of seconds to sleep. format: int64 type: integer required: - seconds type: object tcpSocket: description: |- Deprecated. TCPSocket is NOT supported as a LifecycleHandler and kept for the backward compatibility. There are no validation of this field and lifecycle hooks will fail in runtime when tcp handler is specified. properties: host: description: 'Optional: Host name to connect to, defaults to the pod IP.' type: string port: anyOf: - type: integer - type: string description: |- Number or name of the port to access on the container. Number must be in the range 1 to 65535. Name must be an IANA_SVC_NAME. x-kubernetes-int-or-string: true required: - port type: object type: object preStop: description: |- PreStop is called immediately before a container is terminated due to an API request or management event such as liveness/startup probe failure, preemption, resource contention, etc. The handler is not called if the container crashes or exits. The Pod's termination grace period countdown begins before the PreStop hook is executed. Regardless of the outcome of the handler, the container will eventually terminate within the Pod's termination grace period (unless delayed by finalizers). Other management of the container blocks until the hook completes or until the termination grace period is reached. More info: https://kubernetes.io/docs/concepts/containers/container-lifecycle-hooks/#container-hooks properties: exec: description: Exec specifies the action to take. properties: command: description: |- Command is the command line to execute inside the container, the working directory for the command is root ('/') in the container's filesystem. The command is simply exec'd, it is not run inside a shell, so traditional shell instructions ('|', etc) won't work. To use a shell, you need to explicitly call out to that shell. Exit status of 0 is treated as live/healthy and non-zero is unhealthy. items: type: string type: array type: object httpGet: description: HTTPGet specifies the http request to perform. properties: host: description: |- Host name to connect to, defaults to the pod IP. You probably want to set \"Host\" in httpHeaders instead. type: string httpHeaders: description: Custom headers to set in the request. HTTP allows repeated headers. items: description: HTTPHeader describes a custom header to be used in HTTP probes properties: name: description: |- The header field name. This will be canonicalized upon output, so case-variant names will be understood as the same header. type: string value: description: The header field value type: string required: - name - value type: object type: array path: description: Path to access on the HTTP server. type: string port: anyOf: - type: integer - type: string description: |- Name or number of the port to access on the container. Number must be in the range 1 to 65535. Name must be an IANA_SVC_NAME. x-kubernetes-int-or-string: true scheme: description: |- Scheme to use for connecting to the host. Defaults to HTTP. type: string required: - port type: object sleep: description: Sleep represents the duration that the container should sleep before being terminated. properties: seconds: description: Seconds is the number of seconds to sleep. format: int64 type: integer required: - seconds type: object tcpSocket: description: |- Deprecated. TCPSocket is NOT supported as a LifecycleHandler and kept for the backward compatibility. There are no validation of this field and lifecycle hooks will fail in runtime when tcp handler is specified. properties: host: description: 'Optional: Host name to connect to, defaults to the pod IP.' type: string port: anyOf: - type: integer - type: string description: |- Number or name of the port to access on the container. Number must be in the range 1 to 65535. Name must be an IANA_SVC_NAME. x-kubernetes-int-or-string: true required: - port type: object type: object type: object livenessProbe: description: |- Periodic probe of container liveness. Container will be restarted if the probe fails. Cannot be updated. More info: https://kubernetes.io/docs/concepts/workloads/pods/pod-lifecycle#container-probes properties: exec: description: Exec specifies the action to take. properties: command: description: |- Command is the command line to execute inside the container, the working directory for the command is root ('/') in the container's filesystem. The command is simply exec'd, it is not run inside a shell, so traditional shell instructions ('|', etc) won't work. To use a shell, you need to explicitly call out to that shell. Exit status of 0 is treated as live/healthy and non-zero is unhealthy. items: type: string type: array type: object failureThreshold: description: |- Minimum consecutive failures for the probe to be considered failed after having succeeded. Defaults to 3. Minimum value is 1. format: int32 type: integer grpc: description: GRPC specifies an action involving a GRPC port. properties: port: description: Port number of the gRPC service. Number must be in the range 1 to 65535. format: int32 type: integer service: description: |- Service is the name of the service to place in the gRPC HealthCheckRequest (see https://github.com/grpc/grpc/blob/master/doc/health-checking.md). If this is not specified, the default behavior is defined by gRPC. type: string required: - port type: object httpGet: description: HTTPGet specifies the http request to perform. properties: host: description: |- Host name to connect to, defaults to the pod IP. You probably want to set \"Host\" in httpHeaders instead. type: string httpHeaders: description: Custom headers to set in the request. HTTP allows repeated headers. items: description: HTTPHeader describes a custom header to be used in HTTP probes properties: name: description: |- The header field name. This will be canonicalized upon output, so case-variant names will be understood as the same header. type: string value: description: The header field value type: string required: - name - value type: object type: array path: description: Path to access on the HTTP server. type: string port: anyOf: - type: integer - type: string description: |- Name or number of the port to access on the container. Number must be in the range 1 to 65535. Name must be an IANA_SVC_NAME. x-kubernetes-int-or-string: true scheme: description: |- Scheme to use for connecting to the host. Defaults to HTTP. type: string required: - port type: object initialDelaySeconds: description: |- Number of seconds after the container has started before liveness probes are initiated. More info: https://kubernetes.io/docs/concepts/workloads/pods/pod-lifecycle#container-probes format: int32 type: integer periodSeconds: description: |- How often (in seconds) to perform the probe. Default to 10 seconds. Minimum value is 1. format: int32 type: integer successThreshold: description: |- Minimum consecutive successes for the probe to be considered successful after having failed. Defaults to 1. Must be 1 for liveness and startup. Minimum value is 1. format: int32 type: integer tcpSocket: description: TCPSocket specifies an action involving a TCP port. properties: host: description: 'Optional: Host name to connect to, defaults to the pod IP.' type: string port: anyOf: - type: integer - type: string description: |- Number or name of the port to access on the container. Number must be in the range 1 to 65535. Name must be an IANA_SVC_NAME. x-kubernetes-int-or-string: true required: - port type: object terminationGracePeriodSeconds: description: |- Optional duration in seconds the pod needs to terminate gracefully upon probe failure. The grace period is the duration in seconds after the processes running in the pod are sent a termination signal and the time when the processes are forcibly halted with a kill signal. Set this value longer than the expected cleanup time for your process. If this value is nil, the pod's terminationGracePeriodSeconds will be used. Otherwise, this value overrides the value provided by the pod spec. Value must be non-negative integer. The value zero indicates stop immediately via the kill signal (no opportunity to shut down). This is a beta field and requires enabling ProbeTerminationGracePeriod feature gate. Minimum value is 1. spec.terminationGracePeriodSeconds is used if unset. format: int64 type: integer timeoutSeconds: description: |- Number of seconds after which the probe times out. Defaults to 1 second. Minimum value is 1. More info: https://kubernetes.io/docs/concepts/workloads/pods/pod-lifecycle#container-probes format: int32 type: integer type: object name: description: |- Name of the container specified as a DNS_LABEL. Each container in a pod must have a unique name (DNS_LABEL). Cannot be updated. type: string ports: description: |- List of ports to expose from the container. Not specifying a port here DOES NOT prevent that port from being exposed. Any port which is listening on the default \"0.0.0.0\" address inside a container will be accessible from the network. Modifying this array with strategic merge patch may corrupt the data. For more information See https://github.com/kubernetes/kubernetes/issues/108255. Cannot be updated. items: description: ContainerPort represents a network port in a single container. properties: containerPort: description: |- Number of port to expose on the pod's IP address. This must be a valid port number, 0 ...svc.\". If not specified, the pod will not have a domainname at all. type: string terminationGracePeriodSeconds: description: |- Optional duration in seconds the pod needs to terminate gracefully. May be decreased in delete request. Value must be non-negative integer. The value zero indicates stop immediately via the kill signal (no opportunity to shut down). If this value is nil, the default grace period will be used instead. The grace period is the duration in seconds after the processes running in the pod are sent a termination signal and the time when the processes are forcibly halted with a kill signal. Set this value longer than the expected cleanup time for your process. Defaults to 30 seconds. format: int64 type: integer tolerations: description: If specified, the pod's tolerations. items: description: |- The pod this Toleration is attached to tolerates any taint that matches the triple using the matching operator . properties: effect: description: |- Effect indicates the taint effect to match. Empty means match all taint effects. When specified, allowed values are NoSchedule, PreferNoSchedule and NoExecute. type: string key: description: |- Key is the taint key that the toleration applies to. Empty means match all taint keys. If the key is empty, operator must be Exists; this combination means to match all values and all keys. type: string operator: description: |- Operator represents a key's relationship to the value. Valid operators are Exists and Equal. Defaults to Equal. Exists is equivalent to wildcard for value, so that a pod can tolerate all taints of a particular category. type: string tolerationSeconds: description: |- TolerationSeconds represents the period of time the toleration (which must be of effect NoExecute, otherwise this field is ignored) tolerates the taint. By default, it is not set, which means tolerate the taint forever (do not evict). Zero and negative values will be treated as 0 (evict immediately) by the system. format: int64 type: integer value: description: |- Value is the taint value the toleration matches to. If the operator is Exists, the value should be empty, otherwise just a regular string. type: string type: object type: array topologySpreadConstraints: description: |- TopologySpreadConstraints describes how a group of pods ought to spread across topology domains. Scheduler will schedule pods in a way which abides by the constraints. All topologySpreadConstraints are ANDed. items: description: TopologySpreadConstraint specifies how to spread matching pods among the given topology. properties: labelSelector: description: |- LabelSelector is used to find matching pods. Pods that match this label selector are counted to determine the number of pods in their corresponding topology domain. properties: matchExpressions: description: matchExpressions is a list of label selector requirements. The requirements are ANDed. items: description: |- A label selector requirement is a selector that contains values, a key, and an operator that relates the key and values. properties: key: description: key is the label key that the selector applies to. type: string operator: description: |- operator represents a key's relationship to a set of values. Valid operators are In, NotIn, Exists and DoesNotExist. type: string values: description: |- values is an array of string values. If the operator is In or NotIn, the values array must be non-empty. If the operator is Exists or DoesNotExist, the values array must be empty. This array is replaced during a strategic merge patch. items: type: string type: array required: - key - operator type: object type: array matchLabels: additionalProperties: type: string description: |- matchLabels is a map of {key,value} pairs. A single {key,value} in the matchLabels map is equivalent to an element of matchExpressions, whose key field is \"key\", the operator is \"In\", and the values array contains only \"value\". The requirements are ANDed. type: object type: object x-kubernetes-map-type: atomic matchLabelKeys: description: |- MatchLabelKeys is a set of pod label keys to select the pods over which spreading will be calculated. The keys are used to lookup values from the incoming pod labels, those key-value labels are ANDed with labelSelector to select the group of existing pods over which spreading will be calculated for the incoming pod. The same key is forbidden to exist in both MatchLabelKeys and LabelSelector. MatchLabelKeys cannot be set when LabelSelector isn't set. Keys that don't exist in the incoming pod labels will be ignored. A null or empty list means only match against labelSelector. This is a beta field and requires the MatchLabelKeysInPodTopologySpread feature gate to be enabled (enabled by default). items: type: string type: array x-kubernetes-list-type: atomic maxSkew: description: |- MaxSkew describes the degree to which pods may be unevenly distributed. When `whenUnsatisfiable=DoNotSchedule`, it is the maximum permitted difference between the number of matching pods in the target topology and the global minimum. The global minimum is the minimum number of matching pods in an eligible domain or zero if the number of eligible domains is less than MinDomains. For example, in a 3-zone cluster, MaxSkew is set to 1, and pods with the same labelSelector spread as 2/2/1: In this case, the global minimum is 1. | zone1 | zone2 | zone3 | | P P | P P | P | - if MaxSkew is 1, incoming pod can only be scheduled to zone3 to become 2/2/2; scheduling it onto zone1(zone2) would make the ActualSkew(3-1) on zone1(zone2) violate MaxSkew(1). - if MaxSkew is 2, incoming pod can be scheduled onto any zone. When `whenUnsatisfiable=ScheduleAnyway`, it is used to give higher precedence to topologies that satisfy it. It's a required field. Default value is 1 and 0 is not allowed. format: int32 type: integer minDomains: description: |- MinDomains indicates a minimum number of eligible domains. When the number of eligible domains with matching topology keys is less than minDomains, Pod Topology Spread treats \"global minimum\" as 0, and then the calculation of Skew is performed. And when the number of eligible domains with matching topology keys equals or greater than minDomains, this value has no effect on scheduling. As a result, when the number of eligible domains is less than minDomains, scheduler won't schedule more than maxSkew Pods to those domains. If value is nil, the constraint behaves as if MinDomains is equal to 1. Valid values are integers greater than 0. When value is not nil, WhenUnsatisfiable must be DoNotSchedule. For example, in a 3-zone cluster, MaxSkew is set to 2, MinDomains is set to 5 and pods with the same labelSelector spread as 2/2/2: | zone1 | zone2 | zone3 | | P P | P P | P P | The number of domains is less than 5(MinDomains), so \"global minimum\" is treated as 0. In this situation, new pod with the same labelSelector cannot be scheduled, because computed skew will be 3(3 - 0) if new Pod is scheduled to any of the three zones, it will violate MaxSkew. This is a beta field and requires the MinDomainsInPodTopologySpread feature gate to be enabled (enabled by default). format: int32 type: integer nodeAffinityPolicy: description: |- NodeAffinityPolicy indicates how we will treat Pod's nodeAffinity/nodeSelector when calculating pod topology spread skew. Options are: - Honor: only nodes matching nodeAffinity/nodeSelector are included in the calculations. - Ignore: nodeAffinity/nodeSelector are ignored. All nodes are included in the calculations. If this value is nil, the behavior is equivalent to the Honor policy. This is a beta-level feature default enabled by the NodeInclusionPolicyInPodTopologySpread feature flag. type: string nodeTaintsPolicy: description: |- NodeTaintsPolicy indicates how we will treat node taints when calculating pod topology spread skew. Options are: - Honor: nodes without taints, along with tainted nodes for which the incoming pod has a toleration, are included. - Ignore: node taints are ignored. All nodes are included. If this value is nil, the behavior is equivalent to the Ignore policy. This is a beta-level feature default enabled by the NodeInclusionPolicyInPodTopologySpread feature flag. type: string topologyKey: description: |- TopologyKey is the key of node labels. Nodes that have a label with this key and identical values are considered to be in the same topology. We consider each as a \"bucket\", and try to put balanced number of pods into each bucket. We define a domain as a particular instance of a topology. Also, we define an eligible domain as a domain whose nodes meet the requirements of nodeAffinityPolicy and nodeTaintsPolicy. e.g. If TopologyKey is \"kubernetes.io/hostname\", each Node is a domain of that topology. And, if TopologyKey is \"topology.kubernetes.io/zone\", each zone is a domain of that topology. It's a required field. type: string whenUnsatisfiable: description: |- WhenUnsatisfiable indicates how to deal with a pod if it doesn't satisfy the spread constraint. - DoNotSchedule (default) tells the scheduler not to schedule it. - ScheduleAnyway tells the scheduler to schedule the pod in any location, but giving higher precedence to topologies that would help reduce the skew. A constraint is considered \"Unsatisfiable\" for an incoming pod if and only if every possible node assignment for that pod would violate \"MaxSkew\" on some topology. For example, in a 3-zone cluster, MaxSkew is set to 1, and pods with the same labelSelector spread as 3/1/1: | zone1 | zone2 | zone3 | | P P P | P | P | If WhenUnsatisfiable is set to DoNotSchedule, incoming pod can only be scheduled to zone2(zone3) to become 3/2/1(3/1/2) as ActualSkew(2-1) on zone2(zone3) satisfies MaxSkew(1). In other words, the cluster can still be imbalanced, but scheduler won't make it *more* imbalanced. It's a required field. type: string required: - maxSkew - topologyKey - whenUnsatisfiable type: object type: array x-kubernetes-list-map-keys: - topologyKey - whenUnsatisfiable x-kubernetes-list-type: map volumes: description: |- List of volumes that can be mounted by containers belonging to the pod. More info: https://kubernetes.io/docs/concepts/storage/volumes items: description: Volume represents a named volume in a pod that may be accessed by any container in the pod. properties: awsElasticBlockStore: description: |- awsElasticBlockStore represents an AWS Disk resource that is attached to a kubelet's host machine and then exposed to the pod. More info: https://kubernetes.io/docs/concepts/storage/volumes#awselasticblockstore properties: fsType: description: |- fsType is the filesystem type of the volume that you want to mount. Tip: Ensure that the filesystem type is supported by the host operating system. Examples: \"ext4\", \"xfs\", \"ntfs\". Implicitly inferred to be \"ext4\" if unspecified. More info: https://kubernetes.io/docs/concepts/storage/volumes#awselasticblockstore TODO: how do we prevent errors in the filesystem from compromising the machine type: string partition: description: |- partition is the partition in the volume that you want to mount. If omitted, the default is to mount by volume name. Examples: For volume /dev/sda1, you specify the partition as \"1\". Similarly, the volume partition for /dev/sda is \"0\" (or you can leave the property empty). format: int32 type: integer readOnly: description: |- readOnly value true will force the readOnly setting in VolumeMounts. More info: https://kubernetes.io/docs/concepts/storage/volumes#awselasticblockstore type: boolean volumeID: description: |- volumeID is unique ID of the persistent disk resource in AWS (Amazon EBS volume). More info: https://kubernetes.io/docs/concepts/storage/volumes#awselasticblockstore type: string required: - volumeID type: object azureDisk: description: azureDisk represents an Azure Data Disk mount on the host and bind mount to the pod. properties: cachingMode: description: 'cachingMode is the Host Caching mode: None, Read Only, Read Write.' type: string diskName: description: diskName is the Name of the data disk in the blob storage type: string diskURI: description: diskURI is the URI of data disk in the blob storage type: string fsType: description: |- fsType is Filesystem type to mount. Must be a filesystem type supported by the host operating system. Ex. \"ext4\", \"xfs\", \"ntfs\". Implicitly inferred to be \"ext4\" if unspecified. type: string kind: description: 'kind expected values are Shared: multiple blob disks per storage account Dedicated: single blob disk per storage account Managed: azure managed data disk (only in managed availability set). defaults to shared' type: string readOnly: description: |- readOnly Defaults to false (read/write). ReadOnly here will force the ReadOnly setting in VolumeMounts. type: boolean required: - diskName - diskURI type: object azureFile: description: azureFile represents an Azure File Service mount on the host and bind mount to the pod. properties: readOnly: description: |- readOnly defaults to false (read/write). ReadOnly here will force the ReadOnly setting in VolumeMounts. type: boolean secretName: description: secretName is the name of secret that contains Azure Storage Account Name and Key type: string shareName: description: shareName is the azure share Name type: string required: - secretName - shareName type: object cephfs: description: cephFS represents a Ceph FS mount on the host that shares a pod's lifetime properties: monitors: description: |- monitors is Required: Monitors is a collection of Ceph monitors More info: https://examples.k8s.io/volumes/cephfs/README.md#how-to-use-it items: type: string type: array path: description: 'path is Optional: Used as the mounted root, rather than the full Ceph tree, default is /' type: string readOnly: description: |- readOnly is Optional: Defaults to false (read/write). ReadOnly here will force the ReadOnly setting in VolumeMounts. More info: https://examples.k8s.io/volumes/cephfs/README.md#how-to-use-it type: boolean secretFile: description: |- secretFile is Optional: SecretFile is the path to key ring for User, default is /etc/ceph/user.secret More info: https://examples.k8s.io/volumes/cephfs/README.md#how-to-use-it type: string secretRef: description: |- secretRef is Optional: SecretRef is reference to the authentication secret for User, default is empty. More info: https://examples.k8s.io/volumes/cephfs/README.md#how-to-use-it properties: name: description: |- Name of the referent. More info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names TODO: Add other useful fields. apiVersion, kind, uid? type: string type: object x-kubernetes-map-type: atomic user: description: |- user is optional: User is the rados user name, default is admin More info: https://examples.k8s.io/volumes/cephfs/README.md#how-to-use-it type: string required: - monitors type: object cinder: description: |- cinder represents a cinder volume attached and mounted on kubelets host machine. More info: https://examples.k8s.io/mysql-cinder-pd/README.md properties: fsType: description: |- fsType is the filesystem type to mount. Must be a filesystem type supported by the host operating system. Examples: \"ext4\", \"xfs\", \"ntfs\". Implicitly inferred to be \"ext4\" if unspecified. More info: https://examples.k8s.io/mysql-cinder-pd/README.md type: string readOnly: description: |- readOnly defaults to false (read/write). ReadOnly here will force the ReadOnly setting in VolumeMounts. More info: https://examples.k8s.io/mysql-cinder-pd/README.md type: boolean secretRef: description: |- secretRef is optional: points to a secret object containing parameters used to connect to OpenStack. properties: name: description: |- Name of the referent. More info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names TODO: Add other useful fields. apiVersion, kind, uid? type: string type: object x-kubernetes-map-type: atomic volumeID: description: |- volumeID used to identify the volume in cinder. More info: https://examples.k8s.io/mysql-cinder-pd/README.md type: string required: - volumeID type: object configMap: description: configMap represents a configMap that should populate this volume properties: defaultMode: description: |- defaultMode is optional: mode bits used to set permissions on created files by default. Must be an octal value between 0000 and 0777 or a decimal value between 0 and 511. YAML accepts both octal and decimal values, JSON requires decimal values for mode bits. Defaults to 0644. Directories within the path are not affected by this setting. This might be in conflict with other options that affect the file mode, like fsGroup, and the result can be other mode bits set. format: int32 type: integer items: description: |- items if unspecified, each key-value pair in the Data field of the referenced ConfigMap will be projected into the volume as a file whose name is the key and content is the value. If specified, the listed keys will be projected into the specified paths, and unlisted keys will not be present. If a key is specified which is not present in the ConfigMap, the volume setup will error unless it is marked optional. Paths must be relative and may not contain the '..' path or start with '..'. items: description: Maps a string key to a path within a volume. properties: key: description: key is the key to project. type: string mode: description: |- mode is Optional: mode bits used to set permissions on this file. Must be an octal value between 0000 and 0777 or a decimal value between 0 and 511. YAML accepts both octal and decimal values, JSON requires decimal values for mode bits. If not specified, the volume defaultMode will be used. This might be in conflict with other options that affect the file mode, like fsGroup, and the result can be other mode bits set. format: int32 type: integer path: description: |- path is the relative path of the file to map the key to. May not be an absolute path. May not contain the path element '..'. May not start with the string '..'. type: string required: - key - path type: object type: array name: description: |- Name of the referent. More info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names TODO: Add other useful fields. apiVersion, kind, uid? type: string optional: description: optional specify whether the ConfigMap or its keys must be defined type: boolean type: object x-kubernetes-map-type: atomic csi: description: csi (Container Storage Interface) represents ephemeral storage that is handled by certain external CSI drivers (Beta feature). properties: driver: description: |- driver is the name of the CSI driver that handles this volume. Consult with your admin for the correct name as registered in the cluster. type: string fsType: description: |- fsType to mount. Ex. \"ext4\", \"xfs\", \"ntfs\". If not provided, the empty value is passed to the associated CSI driver which will determine the default filesystem to apply. type: string nodePublishSecretRef: description: |- nodePublishSecretRef is a reference to the secret object containing sensitive information to pass to the CSI driver to complete the CSI NodePublishVolume and NodeUnpublishVolume calls. This field is optional, and may be empty if no secret is required. If the secret object contains more than one secret, all secret references are passed. properties: name: description: |- Name of the referent. More info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names TODO: Add other useful fields. apiVersion, kind, uid? type: string type: object x-kubernetes-map-type: atomic readOnly: description: |- readOnly specifies a read-only configuration for the volume. Defaults to false (read/write). type: boolean volumeAttributes: additionalProperties: type: string description: |- volumeAttributes stores driver-specific properties that are passed to the CSI driver. Consult your driver's documentation for supported values. type: object required: - driver type: object downwardAPI: description: downwardAPI represents downward API about the pod that should populate this volume properties: defaultMode: description: |- Optional: mode bits to use on created files by default. Must be a Optional: mode bits used to set permissions on created files by default. Must be an octal value between 0000 and 0777 or a decimal value between 0 and 511. YAML accepts both octal and decimal values, JSON requires decimal values for mode bits. Defaults to 0644. Directories within the path are not affected by this setting. This might be in conflict with other options that affect the file mode, like fsGroup, and the result can be other mode bits set. format: int32 type: integer items: description: Items is a list of downward API volume file items: description: DownwardAPIVolumeFile represents information to create the file containing the pod field properties: fieldRef: description: 'Required: Selects a field of the pod: only annotations, labels, name and namespace are supported.' properties: apiVersion: description: Version of the schema the FieldPath is written in terms of, defaults to \"v1\". type: string fieldPath: description: Path of the field to select in the specified API version. type: string required: - fieldPath type: object x-kubernetes-map-type: atomic mode: description: |- Optional: mode bits used to set permissions on this file, must be an octal value between 0000 and 0777 or a decimal value between 0 and 511. YAML accepts both octal and decimal values, JSON requires decimal values for mode bits. If not specified, the volume defaultMode will be used. This might be in conflict with other options that affect the file mode, like fsGroup, and the result can be other mode bits set. format: int32 type: integer path: description: 'Required: Path is the relative path name of the file to be created. Must not be absolute or contain the ''..'' path. Must be utf-8 encoded. The first item of the relative path must not start with ''..''' type: string resourceFieldRef: description: |- Selects a resource of the container: only resources limits and requests (limits.cpu, limits.memory, requests.cpu and requests.memory) are currently supported. properties: containerName: description: 'Container name: required for volumes, optional for env vars' type: string divisor: anyOf: - type: integer - type: string description: Specifies the output format of the exposed resources, defaults to \"1\" pattern: ^(\\+|-)?(([0-9]+(\\.[0-9]*)?)|(\\.[0-9]+))(([KMGTPE]i)|[numkMGTPE]|([eE](\\+|-)?(([0-9]+(\\.[0-9]*)?)|(\\.[0-9]+))))?$ x-kubernetes-int-or-string: true resource: description: 'Required: resource to select' type: string required: - resource type: object x-kubernetes-map-type: atomic required: - path type: object type: array type: object emptyDir: description: |- emptyDir represents a temporary directory that shares a pod's lifetime. More info: https://kubernetes.io/docs/concepts/storage/volumes#emptydir properties: medium: description: |- medium represents what type of storage medium should back this directory. The default is \"\" which means to use the node's default medium. Must be an empty string (default) or Memory. More info: https://kubernetes.io/docs/concepts/storage/volumes#emptydir type: string sizeLimit: anyOf: - type: integer - type: string description: |- sizeLimit is the total amount of local storage required for this EmptyDir volume. The size limit is also applicable for memory medium. The maximum usage on memory medium EmptyDir would be the minimum value between the SizeLimit specified here and the sum of memory limits of all containers in a pod. The default is nil which means that the limit is undefined. More info: https://kubernetes.io/docs/concepts/storage/volumes#emptydir pattern: ^(\\+|-)?(([0-9]+(\\.[0-9]*)?)|(\\.[0-9]+))(([KMGTPE]i)|[numkMGTPE]|([eE](\\+|-)?(([0-9]+(\\.[0-9]*)?)|(\\.[0-9]+))))?$ x-kubernetes-int-or-string: true type: object ephemeral: description: |- ephemeral represents a volume that is handled by a cluster storage driver. The volume's lifecycle is tied to the pod that defines it - it will be created before the pod starts, and deleted when the pod is removed. Use this if: a) the volume is only needed while the pod runs, b) features of normal volumes like restoring from snapshot or capacity tracking are needed, c) the storage driver is specified through a storage class, and d) the storage driver supports dynamic volume provisioning through a PersistentVolumeClaim (see EphemeralVolumeSource for more information on the connection between this volume type and PersistentVolumeClaim). Use PersistentVolumeClaim or one of the vendor-specific APIs for volumes that persist for longer than the lifecycle of an individual pod. Use CSI for light-weight local ephemeral volumes if the CSI driver is meant to be used that way - see the documentation of the driver for more information. A pod can use both types of ephemeral volumes and persistent volumes at the same time. properties: volumeClaimTemplate: description: |- Will be used to create a stand-alone PVC to provision the volume. The pod in which this EphemeralVolumeSource is embedded will be the owner of the PVC, i.e. the PVC will be deleted together with the pod. The name of the PVC will be `-` where `` is the name from the `PodSpec.Volumes` array entry. Pod validation will reject the pod if the concatenated name is not valid for a PVC (for example, too long). An existing PVC with that name that is not owned by the pod will *not* be used for the pod to avoid using an unrelated volume by mistake. Starting the pod is then blocked until the unrelated PVC is removed. If such a pre-created PVC is meant to be used by the pod, the PVC has to updated with an owner reference to the pod once the pod exists. Normally this should not be necessary, but it may be useful when manually reconstructing a broken cluster. This field is read-only and no changes will be made by Kubernetes to the PVC after it has been created. Required, must not be nil. properties: metadata: description: |- May contain labels and annotations that will be copied into the PVC when creating it. No other fields are allowed and will be rejected during validation. properties: annotations: additionalProperties: type: string type: object finalizers: items: type: string type: array labels: additionalProperties: type: string type: object name: type: string namespace: type: string type: object spec: description: |- The specification for the PersistentVolumeClaim. The entire content is copied unchanged into the PVC that gets created from this template. The same fields as in a PersistentVolumeClaim are also valid here. properties: accessModes: description: |- accessModes contains the desired access modes the volume should have. More info: https://kubernetes.io/docs/concepts/storage/persistent-volumes#access-modes-1 items: type: string type: array dataSource: description: |- dataSource field can be used to specify either: * An existing VolumeSnapshot object (snapshot.storage.k8s.io/VolumeSnapshot) * An existing PVC (PersistentVolumeClaim) If the provisioner or an external controller can support the specified data source, it will create a new volume based on the contents of the specified data source. When the AnyVolumeDataSource feature gate is enabled, dataSource contents will be copied to dataSourceRef, and dataSourceRef contents will be copied to dataSource when dataSourceRef.namespace is not specified. If the namespace is specified, then dataSourceRef will not be copied to dataSource. properties: apiGroup: description: |- APIGroup is the group for the resource being referenced. If APIGroup is not specified, the specified Kind must be in the core API group. For any other third-party types, APIGroup is required. type: string kind: description: Kind is the type of resource being referenced type: string name: description: Name is the name of resource being referenced type: string required: - kind - name type: object x-kubernetes-map-type: atomic dataSourceRef: description: |- dataSourceRef specifies the object from which to populate the volume with data, if a non-empty volume is desired. This may be any object from a non-empty API group (non core object) or a PersistentVolumeClaim object. When this field is specified, volume binding will only succeed if the type of the specified object matches some installed volume populator or dynamic provisioner. This field will replace the functionality of the dataSource field and as such if both fields are non-empty, they must have the same value. For backwards compatibility, when namespace isn't specified in dataSourceRef, both fields (dataSource and dataSourceRef) will be set to the same value automatically if one of them is empty and the other is non-empty. When namespace is specified in dataSourceRef, dataSource isn't set to the same value and must be empty. There are three important differences between dataSource and dataSourceRef: * While dataSource only allows two specific types of objects, dataSourceRef allows any non-core object, as well as PersistentVolumeClaim objects. * While dataSource ignores disallowed values (dropping them), dataSourceRef preserves all values, and generates an error if a disallowed value is specified. * While dataSource only allows local objects, dataSourceRef allows objects in any namespaces. (Beta) Using this field requires the AnyVolumeDataSource feature gate to be enabled. (Alpha) Using the namespace field of dataSourceRef requires the CrossNamespaceVolumeDataSource feature gate to be enabled. properties: apiGroup: description: |- APIGroup is the group for the resource being referenced. If APIGroup is not specified, the specified Kind must be in the core API group. For any other third-party types, APIGroup is required. type: string kind: description: Kind is the type of resource being referenced type: string name: description: Name is the name of resource being referenced type: string namespace: description: |- Namespace is the namespace of resource being referenced Note that when a namespace is specified, a gateway.networking.k8s.io/ReferenceGrant object is required in the referent namespace to allow that namespace's owner to accept the reference. See the ReferenceGrant documentation for details. (Alpha) This field requires the CrossNamespaceVolumeDataSource feature gate to be enabled. type: string required: - kind - name type: object resources: description: |- resources represents the minimum resources the volume should have. If RecoverVolumeExpansionFailure feature is enabled users are allowed to specify resource requirements that are lower than previous value but must still be higher than capacity recorded in the status field of the claim. More info: https://kubernetes.io/docs/concepts/storage/persistent-volumes#resources properties: limits: additionalProperties: anyOf: - type: integer - type: string pattern: ^(\\+|-)?(([0-9]+(\\.[0-9]*)?)|(\\.[0-9]+))(([KMGTPE]i)|[numkMGTPE]|([eE](\\+|-)?(([0-9]+(\\.[0-9]*)?)|(\\.[0-9]+))))?$ x-kubernetes-int-or-string: true description: |- Limits describes the maximum amount of compute resources allowed. More info: https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/ type: object requests: additionalProperties: anyOf: - type: integer - type: string pattern: ^(\\+|-)?(([0-9]+(\\.[0-9]*)?)|(\\.[0-9]+))(([KMGTPE]i)|[numkMGTPE]|([eE](\\+|-)?(([0-9]+(\\.[0-9]*)?)|(\\.[0-9]+))))?$ x-kubernetes-int-or-string: true description: |- Requests describes the minimum amount of compute resources required. If Requests is omitted for a container, it defaults to Limits if that is explicitly specified, otherwise to an implementation-defined value. Requests cannot exceed Limits. More info: https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/ type: object type: object selector: description: selector is a label query over volumes to consider for binding. properties: matchExpressions: description: matchExpressions is a list of label selector requirements. The requirements are ANDed. items: description: |- A label selector requirement is a selector that contains values, a key, and an operator that relates the key and values. properties: key: description: key is the label key that the selector applies to. type: string operator: description: |- operator represents a key's relationship to a set of values. Valid operators are In, NotIn, Exists and DoesNotExist. type: string values: description: |- values is an array of string values. If the operator is In or NotIn, the values array must be non-empty. If the operator is Exists or DoesNotExist, the values array must be empty. This array is replaced during a strategic merge patch. items: type: string type: array required: - key - operator type: object type: array matchLabels: additionalProperties: type: string description: |- matchLabels is a map of {key,value} pairs. A single {key,value} in the matchLabels map is equivalent to an element of matchExpressions, whose key field is \"key\", the operator is \"In\", and the values array contains only \"value\". The requirements are ANDed. type: object type: object x-kubernetes-map-type: atomic storageClassName: description: |- storageClassName is the name of the StorageClass required by the claim. More info: https://kubernetes.io/docs/concepts/storage/persistent-volumes#class-1 type: string volumeAttributesClassName: description: |- volumeAttributesClassName may be used to set the VolumeAttributesClass used by this claim. If specified, the CSI driver will create or update the volume with the attributes defined in the corresponding VolumeAttributesClass. This has a different purpose than storageClassName, it can be changed after the claim is created. An empty string value means that no VolumeAttributesClass will be applied to the claim but it's not allowed to reset this field to empty string once it is set. If unspecified and the PersistentVolumeClaim is unbound, the default VolumeAttributesClass will be set by the persistentvolume controller if it exists. If the resource referred to by volumeAttributesClass does not exist, this PersistentVolumeClaim will be set to a Pending state, as reflected by the modifyVolumeStatus field, until such as a resource exists. More info: https://kubernetes.io/docs/concepts/storage/persistent-volumes#volumeattributesclass (Alpha) Using this field requires the VolumeAttributesClass feature gate to be enabled. type: string volumeMode: description: |- volumeMode defines what type of volume is required by the claim. Value of Filesystem is implied when not included in claim spec. type: string volumeName: description: volumeName is the binding reference to the PersistentVolume backing this claim. type: string type: object required: - spec type: object type: object fc: description: fc represents a Fibre Channel resource that is attached to a kubelet's host machine and then exposed to the pod. properties: fsType: description: |- fsType is the filesystem type to mount. Must be a filesystem type supported by the host operating system. Ex. \"ext4\", \"xfs\", \"ntfs\". Implicitly inferred to be \"ext4\" if unspecified. TODO: how do we prevent errors in the filesystem from compromising the machine type: string lun: description: 'lun is Optional: FC target lun number' format: int32 type: integer readOnly: description: |- readOnly is Optional: Defaults to false (read/write). ReadOnly here will force the ReadOnly setting in VolumeMounts. type: boolean targetWWNs: description: 'targetWWNs is Optional: FC target worldwide names (WWNs)' items: type: string type: array wwids: description: |- wwids Optional: FC volume world wide identifiers (wwids) Either wwids or combination of targetWWNs and lun must be set, but not both simultaneously. items: type: string type: array type: object flexVolume: description: |- flexVolume represents a generic volume resource that is provisioned/attached using an exec based plugin. properties: driver: description: driver is the name of the driver to use for this volume. type: string fsType: description: |- fsType is the filesystem type to mount. Must be a filesystem type supported by the host operating system. Ex. \"ext4\", \"xfs\", \"ntfs\". The default filesystem depends on FlexVolume script. type: string options: additionalProperties: type: string description: 'options is Optional: this field holds extra command options if any.' type: object readOnly: description: |- readOnly is Optional: defaults to false (read/write). ReadOnly here will force the ReadOnly setting in VolumeMounts. type: boolean secretRef: description: |- secretRef is Optional: secretRef is reference to the secret object containing sensitive information to pass to the plugin scripts. This may be empty if no secret object is specified. If the secret object contains more than one secret, all secrets are passed to the plugin scripts. properties: name: description: |- Name of the referent. More info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names TODO: Add other useful fields. apiVersion, kind, uid? type: string type: object x-kubernetes-map-type: atomic required: - driver type: object flocker: description: flocker represents a Flocker volume attached to a kubelet's host machine. This depends on the Flocker control service being running properties: datasetName: description: |- datasetName is Name of the dataset stored as metadata -> name on the dataset for Flocker should be considered as deprecated type: string datasetUUID: description: datasetUUID is the UUID of the dataset. This is unique identifier of a Flocker dataset type: string type: object gcePersistentDisk: description: |- gcePersistentDisk represents a GCE Disk resource that is attached to a kubelet's host machine and then exposed to the pod. More info: https://kubernetes.io/docs/concepts/storage/volumes#gcepersistentdisk properties: fsType: description: |- fsType is filesystem type of the volume that you want to mount. Tip: Ensure that the filesystem type is supported by the host operating system. Examples: \"ext4\", \"xfs\", \"ntfs\". Implicitly inferred to be \"ext4\" if unspecified. More info: https://kubernetes.io/docs/concepts/storage/volumes#gcepersistentdisk TODO: how do we prevent errors in the filesystem from compromising the machine type: string partition: description: |- partition is the partition in the volume that you want to mount. If omitted, the default is to mount by volume name. Examples: For volume /dev/sda1, you specify the partition as \"1\". Similarly, the volume partition for /dev/sda is \"0\" (or you can leave the property empty). More info: https://kubernetes.io/docs/concepts/storage/volumes#gcepersistentdisk format: int32 type: integer pdName: description: |- pdName is unique name of the PD resource in GCE. Used to identify the disk in GCE. More info: https://kubernetes.io/docs/concepts/storage/volumes#gcepersistentdisk type: string readOnly: description: |- readOnly here will force the ReadOnly setting in VolumeMounts. Defaults to false. More info: https://kubernetes.io/docs/concepts/storage/volumes#gcepersistentdisk type: boolean required: - pdName type: object gitRepo: description: |- gitRepo represents a git repository at a particular revision. DEPRECATED: GitRepo is deprecated. To provision a container with a git repo, mount an EmptyDir into an InitContainer that clones the repo using git, then mount the EmptyDir into the Pod's container. properties: directory: description: |- directory is the target directory name. Must not contain or start with '..'. If '.' is supplied, the volume directory will be the git repository. Otherwise, if specified, the volume will contain the git repository in the subdirectory with the given name. type: string repository: description: repository is the URL type: string revision: description: revision is the commit hash for the specified revision. type: string required: - repository type: object glusterfs: description: |- glusterfs represents a Glusterfs mount on the host that shares a pod's lifetime. More info: https://examples.k8s.io/volumes/glusterfs/README.md properties: endpoints: description: |- endpoints is the endpoint name that details Glusterfs topology. More info: https://examples.k8s.io/volumes/glusterfs/README.md#create-a-pod type: string path: description: |- path is the Glusterfs volume path. More info: https://examples.k8s.io/volumes/glusterfs/README.md#create-a-pod type: string readOnly: description: |- readOnly here will force the Glusterfs volume to be mounted with read-only permissions. Defaults to false. More info: https://examples.k8s.io/volumes/glusterfs/README.md#create-a-pod type: boolean required: - endpoints - path type: object hostPath: description: |- hostPath represents a pre-existing file or directory on the host machine that is directly exposed to the container. This is generally used for system agents or other privileged things that are allowed to see the host machine. Most containers will NOT need this. More info: https://kubernetes.io/docs/concepts/storage/volumes#hostpath --- TODO(jonesdl) We need to restrict who can use host directory mounts and who can/can not mount host directories as read/write. properties: path: description: |- path of the directory on the host. If the path is a symlink, it will follow the link to the real path. More info: https://kubernetes.io/docs/concepts/storage/volumes#hostpath type: string type: description: |- type for HostPath Volume Defaults to \"\" More info: https://kubernetes.io/docs/concepts/storage/volumes#hostpath type: string required: - path type: object iscsi: description: |- iscsi represents an ISCSI Disk resource that is attached to a kubelet's host machine and then exposed to the pod. More info: https://examples.k8s.io/volumes/iscsi/README.md properties: chapAuthDiscovery: description: chapAuthDiscovery defines whether support iSCSI Discovery CHAP authentication type: boolean chapAuthSession: description: chapAuthSession defines whether support iSCSI Session CHAP authentication type: boolean fsType: description: |- fsType is the filesystem type of the volume that you want to mount. Tip: Ensure that the filesystem type is supported by the host operating system. Examples: \"ext4\", \"xfs\", \"ntfs\". Implicitly inferred to be \"ext4\" if unspecified. More info: https://kubernetes.io/docs/concepts/storage/volumes#iscsi TODO: how do we prevent errors in the filesystem from compromising the machine type: string initiatorName: description: |- initiatorName is the custom iSCSI Initiator Name. If initiatorName is specified with iscsiInterface simultaneously, new iSCSI interface : will be created for the connection. type: string iqn: description: iqn is the target iSCSI Qualified Name. type: string iscsiInterface: description: |- iscsiInterface is the interface Name that uses an iSCSI transport. Defaults to 'default' (tcp). type: string lun: description: lun represents iSCSI Target Lun number. format: int32 type: integer portals: description: |- portals is the iSCSI Target Portal List. The portal is either an IP or ip_addr:port if the port is other than default (typically TCP ports 860 and 3260). items: type: string type: array readOnly: description: |- readOnly here will force the ReadOnly setting in VolumeMounts. Defaults to false. type: boolean secretRef: description: secretRef is the CHAP Secret for iSCSI target and initiator authentication properties: name: description: |- Name of the referent. More info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names TODO: Add other useful fields. apiVersion, kind, uid? type: string type: object x-kubernetes-map-type: atomic targetPortal: description: |- targetPortal is iSCSI Target Portal. The Portal is either an IP or ip_addr:port if the port is other than default (typically TCP ports 860 and 3260). type: string required: - iqn - lun - targetPortal type: object name: description: |- name of the volume. Must be a DNS_LABEL and unique within the pod. More info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names type: string nfs: description: |- nfs represents an NFS mount on the host that shares a pod's lifetime More info: https://kubernetes.io/docs/concepts/storage/volumes#nfs properties: path: description: |- path that is exported by the NFS server. More info: https://kubernetes.io/docs/concepts/storage/volumes#nfs type: string readOnly: description: |- readOnly here will force the NFS export to be mounted with read-only permissions. Defaults to false. More info: https://kubernetes.io/docs/concepts/storage/volumes#nfs type: boolean server: description: |- server is the hostname or IP address of the NFS server. More info: https://kubernetes.io/docs/concepts/storage/volumes#nfs type: string required: - path - server type: object persistentVolumeClaim: description: |- persistentVolumeClaimVolumeSource represents a reference to a PersistentVolumeClaim in the same namespace. More info: https://kubernetes.io/docs/concepts/storage/persistent-volumes#persistentvolumeclaims properties: claimName: description: |- claimName is the name of a PersistentVolumeClaim in the same namespace as the pod using this volume. More info: https://kubernetes.io/docs/concepts/storage/persistent-volumes#persistentvolumeclaims type: string readOnly: description: |- readOnly Will force the ReadOnly setting in VolumeMounts. Default false. type: boolean required: - claimName type: object photonPersistentDisk: description: photonPersistentDisk represents a PhotonController persistent disk attached and mounted on kubelets host machine properties: fsType: description: |- fsType is the filesystem type to mount. Must be a filesystem type supported by the host operating system. Ex. \"ext4\", \"xfs\", \"ntfs\". Implicitly inferred to be \"ext4\" if unspecified. type: string pdID: description: pdID is the ID that identifies Photon Controller persistent disk type: string required: - pdID type: object portworxVolume: description: portworxVolume represents a portworx volume attached and mounted on kubelets host machine properties: fsType: description: |- fSType represents the filesystem type to mount Must be a filesystem type supported by the host operating system. Ex. \"ext4\", \"xfs\". Implicitly inferred to be \"ext4\" if unspecified. type: string readOnly: description: |- readOnly defaults to false (read/write). ReadOnly here will force the ReadOnly setting in VolumeMounts. type: boolean volumeID: description: volumeID uniquely identifies a Portworx volume type: string required: - volumeID type: object projected: description: projected items for all in one resources secrets, configmaps, and downward API properties: defaultMode: description: |- defaultMode are the mode bits used to set permissions on created files by default. Must be an octal value between 0000 and 0777 or a decimal value between 0 and 511. YAML accepts both octal and decimal values, JSON requires decimal values for mode bits. Directories within the path are not affected by this setting. This might be in conflict with other options that affect the file mode, like fsGroup, and the result can be other mode bits set. format: int32 type: integer sources: description: sources is the list of volume projections items: description: Projection that may be projected along with other supported volume types properties: clusterTrustBundle: description: |- ClusterTrustBundle allows a pod to access the `.spec.trustBundle` field of ClusterTrustBundle objects in an auto-updating file. Alpha, gated by the ClusterTrustBundleProjection feature gate. ClusterTrustBundle objects can either be selected by name, or by the combination of signer name and a label selector. Kubelet performs aggressive normalization of the PEM contents written into the pod filesystem. Esoteric PEM features such as inter-block comments and block headers are stripped. Certificates are deduplicated. The ordering of certificates within the file is arbitrary, and Kubelet may change the order over time. properties: labelSelector: description: |- Select all ClusterTrustBundles that match this label selector. Only has effect if signerName is set. Mutually-exclusive with name. If unset, interpreted as \"match nothing\". If set but empty, interpreted as \"match everything\". properties: matchExpressions: description: matchExpressions is a list of label selector requirements. The requirements are ANDed. items: description: |- A label selector requirement is a selector that contains values, a key, and an operator that relates the key and values. properties: key: description: key is the label key that the selector applies to. type: string operator: description: |- operator represents a key's relationship to a set of values. Valid operators are In, NotIn, Exists and DoesNotExist. type: string values: description: |- values is an array of string values. If the operator is In or NotIn, the values array must be non-empty. If the operator is Exists or DoesNotExist, the values array must be empty. This array is replaced during a strategic merge patch. items: type: string type: array required: - key - operator type: object type: array matchLabels: additionalProperties: type: string description: |- matchLabels is a map of {key,value} pairs. A single {key,value} in the matchLabels map is equivalent to an element of matchExpressions, whose key field is \"key\", the operator is \"In\", and the values array contains only \"value\". The requirements are ANDed. type: object type: object x-kubernetes-map-type: atomic name: description: |- Select a single ClusterTrustBundle by object name. Mutually-exclusive with signerName and labelSelector. type: string optional: description: |- If true, don't block pod startup if the referenced ClusterTrustBundle(s) aren't available. If using name, then the named ClusterTrustBundle is allowed not to exist. If using signerName, then the combination of signerName and labelSelector is allowed to match zero ClusterTrustBundles. type: boolean path: description: Relative path from the volume root to write the bundle. type: string signerName: description: |- Select all ClusterTrustBundles that match this signer name. Mutually-exclusive with name. The contents of all selected ClusterTrustBundles will be unified and deduplicated. type: string required: - path type: object configMap: description: configMap information about the configMap data to project properties: items: description: |- items if unspecified, each key-value pair in the Data field of the referenced ConfigMap will be projected into the volume as a file whose name is the key and content is the value. If specified, the listed keys will be projected into the specified paths, and unlisted keys will not be present. If a key is specified which is not present in the ConfigMap, the volume setup will error unless it is marked optional. Paths must be relative and may not contain the '..' path or start with '..'. items: description: Maps a string key to a path within a volume. properties: key: description: key is the key to project. type: string mode: description: |- mode is Optional: mode bits used to set permissions on this file. Must be an octal value between 0000 and 0777 or a decimal value between 0 and 511. YAML accepts both octal and decimal values, JSON requires decimal values for mode bits. If not specified, the volume defaultMode will be used. This might be in conflict with other options that affect the file mode, like fsGroup, and the result can be other mode bits set. format: int32 type: integer path: description: |- path is the relative path of the file to map the key to. May not be an absolute path. May not contain the path element '..'. May not start with the string '..'. type: string required: - key - path type: object type: array name: description: |- Name of the referent. More info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names TODO: Add other useful fields. apiVersion, kind, uid? type: string optional: description: optional specify whether the ConfigMap or its keys must be defined type: boolean type: object x-kubernetes-map-type: atomic downwardAPI: description: downwardAPI information about the downwardAPI data to project properties: items: description: Items is a list of DownwardAPIVolume file items: description: DownwardAPIVolumeFile represents information to create the file containing the pod field properties: fieldRef: description: 'Required: Selects a field of the pod: only annotations, labels, name and namespace are supported.' properties: apiVersion: description: Version of the schema the FieldPath is written in terms of, defaults to \"v1\". type: string fieldPath: description: Path of the field to select in the specified API version. type: string required: - fieldPath type: object x-kubernetes-map-type: atomic mode: description: |- Optional: mode bits used to set permissions on this file, must be an octal value between 0000 and 0777 or a decimal value between 0 and 511. YAML accepts both octal and decimal values, JSON requires decimal values for mode bits. If not specified, the volume defaultMode will be used. This might be in conflict with other options that affect the file mode, like fsGroup, and the result can be other mode bits set. format: int32 type: integer path: description: 'Required: Path is the relative path name of the file to be created. Must not be absolute or contain the ''..'' path. Must be utf-8 encoded. The first item of the relative path must not start with ''..''' type: string resourceFieldRef: description: |- Selects a resource of the container: only resources limits and requests (limits.cpu, limits.memory, requests.cpu and requests.memory) are currently supported. properties: containerName: description: 'Container name: required for volumes, optional for env vars' type: string divisor: anyOf: - type: integer - type: string description: Specifies the output format of the exposed resources, defaults to \"1\" pattern: ^(\\+|-)?(([0-9]+(\\.[0-9]*)?)|(\\.[0-9]+))(([KMGTPE]i)|[numkMGTPE]|([eE](\\+|-)?(([0-9]+(\\.[0-9]*)?)|(\\.[0-9]+))))?$ x-kubernetes-int-or-string: true resource: description: 'Required: resource to select' type: string required: - resource type: object x-kubernetes-map-type: atomic required: - path type: object type: array type: object secret: description: secret information about the secret data to project properties: items: description: |- items if unspecified, each key-value pair in the Data field of the referenced Secret will be projected into the volume as a file whose name is the key and content is the value. If specified, the listed keys will be projected into the specified paths, and unlisted keys will not be present. If a key is specified which is not present in the Secret, the volume setup will error unless it is marked optional. Paths must be relative and may not contain the '..' path or start with '..'. items: description: Maps a string key to a path within a volume. properties: key: description: key is the key to project. type: string mode: description: |- mode is Optional: mode bits used to set permissions on this file. Must be an octal value between 0000 and 0777 or a decimal value between 0 and 511. YAML accepts both octal and decimal values, JSON requires decimal values for mode bits. If not specified, the volume defaultMode will be used. This might be in conflict with other options that affect the file mode, like fsGroup, and the result can be other mode bits set. format: int32 type: integer path: description: |- path is the relative path of the file to map the key to. May not be an absolute path. May not contain the path element '..'. May not start with the string '..'. type: string required: - key - path type: object type: array name: description: |- Name of the referent. More info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names TODO: Add other useful fields. apiVersion, kind, uid? type: string optional: description: optional field specify whether the Secret or its key must be defined type: boolean type: object x-kubernetes-map-type: atomic serviceAccountToken: description: serviceAccountToken is information about the serviceAccountToken data to project properties: audience: description: |- audience is the intended audience of the token. A recipient of a token must identify itself with an identifier specified in the audience of the token, and otherwise should reject the token. The audience defaults to the identifier of the apiserver. type: string expirationSeconds: description: |- expirationSeconds is the requested duration of validity of the service account token. As the token approaches expiration, the kubelet volume plugin will proactively rotate the service account token. The kubelet will start trying to rotate the token if the token is older than 80 percent of its time to live or if the token is older than 24 hours.Defaults to 1 hour and must be at least 10 minutes. format: int64 type: integer path: description: |- path is the path relative to the mount point of the file to project the token into. type: string required: - path type: object type: object type: array type: object quobyte: description: quobyte represents a Quobyte mount on the host that shares a pod's lifetime properties: group: description: |- group to map volume access to Default is no group type: string readOnly: description: |- readOnly here will force the Quobyte volume to be mounted with read-only permissions. Defaults to false. type: boolean registry: description: |- registry represents a single or multiple Quobyte Registry services specified as a string as host:port pair (multiple entries are separated with commas) which acts as the central registry for volumes type: string tenant: description: |- tenant owning the given Quobyte volume in the Backend Used with dynamically provisioned Quobyte volumes, value is set by the plugin type: string user: description: |- user to map volume access to Defaults to serivceaccount user type: string volume: description: volume is a string that references an already created Quobyte volume by name. type: string required: - registry - volume type: object rbd: description: |- rbd represents a Rados Block Device mount on the host that shares a pod's lifetime. More info: https://examples.k8s.io/volumes/rbd/README.md properties: fsType: description: |- fsType is the filesystem type of the volume that you want to mount. Tip: Ensure that the filesystem type is supported by the host operating system. Examples: \"ext4\", \"xfs\", \"ntfs\". Implicitly inferred to be \"ext4\" if unspecified. More info: https://kubernetes.io/docs/concepts/storage/volumes#rbd TODO: how do we prevent errors in the filesystem from compromising the machine type: string image: description: |- image is the rados image name. More info: https://examples.k8s.io/volumes/rbd/README.md#how-to-use-it type: string keyring: description: |- keyring is the path to key ring for RBDUser. Default is /etc/ceph/keyring. More info: https://examples.k8s.io/volumes/rbd/README.md#how-to-use-it type: string monitors: description: |- monitors is a collection of Ceph monitors. More info: https://examples.k8s.io/volumes/rbd/README.md#how-to-use-it items: type: string type: array pool: description: |- pool is the rados pool name. Default is rbd. More info: https://examples.k8s.io/volumes/rbd/README.md#how-to-use-it type: string readOnly: description: |- readOnly here will force the ReadOnly setting in VolumeMounts. Defaults to false. More info: https://examples.k8s.io/volumes/rbd/README.md#how-to-use-it type: boolean secretRef: description: |- secretRef is name of the authentication secret for RBDUser. If provided overrides keyring. Default is nil. More info: https://examples.k8s.io/volumes/rbd/README.md#how-to-use-it properties: name: description: |- Name of the referent. More info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names TODO: Add other useful fields. apiVersion, kind, uid? type: string type: object x-kubernetes-map-type: atomic user: description: |- user is the rados user name. Default is admin. More info: https://examples.k8s.io/volumes/rbd/README.md#how-to-use-it type: string required: - image - monitors type: object scaleIO: description: scaleIO represents a ScaleIO persistent volume attached and mounted on Kubernetes nodes. properties: fsType: description: |- fsType is the filesystem type to mount. Must be a filesystem type supported by the host operating system. Ex. \"ext4\", \"xfs\", \"ntfs\". Default is \"xfs\". type: string gateway: description: gateway is the host address of the ScaleIO API Gateway. type: string protectionDomain: description: protectionDomain is the name of the ScaleIO Protection Domain for the configured storage. type: string readOnly: description: |- readOnly Defaults to false (read/write). ReadOnly here will force the ReadOnly setting in VolumeMounts. type: boolean secretRef: description: |- secretRef references to the secret for ScaleIO user and other sensitive information. If this is not provided, Login operation will fail. properties: name: description: |- Name of the referent. More info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names TODO: Add other useful fields. apiVersion, kind, uid? type: string type: object x-kubernetes-map-type: atomic sslEnabled: description: sslEnabled Flag enable/disable SSL communication with Gateway, default false type: boolean storageMode: description: |- storageMode indicates whether the storage for a volume should be ThickProvisioned or ThinProvisioned. Default is ThinProvisioned. type: string storagePool: description: storagePool is the ScaleIO Storage Pool associated with the protection domain. type: string system: description: system is the name of the storage system as configured in ScaleIO. type: string volumeName: description: |- volumeName is the name of a volume already created in the ScaleIO system that is associated with this volume source. type: string required: - gateway - secretRef - system type: object secret: description: |- secret represents a secret that should populate this volume. More info: https://kubernetes.io/docs/concepts/storage/volumes#secret properties: defaultMode: description: |- defaultMode is Optional: mode bits used to set permissions on created files by default. Must be an octal value between 0000 and 0777 or a decimal value between 0 and 511. YAML accepts both octal and decimal values, JSON requires decimal values for mode bits. Defaults to 0644. Directories within the path are not affected by this setting. This might be in conflict with other options that affect the file mode, like fsGroup, and the result can be other mode bits set. format: int32 type: integer items: description: |- items If unspecified, each key-value pair in the Data field of the referenced Secret will be projected into the volume as a file whose name is the key and content is the value. If specified, the listed keys will be projected into the specified paths, and unlisted keys will not be present. If a key is specified which is not present in the Secret, the volume setup will error unless it is marked optional. Paths must be relative and may not contain the '..' path or start with '..'. items: description: Maps a string key to a path within a volume. properties: key: description: key is the key to project. type: string mode: description: |- mode is Optional: mode bits used to set permissions on this file. Must be an octal value between 0000 and 0777 or a decimal value between 0 and 511. YAML accepts both octal and decimal values, JSON requires decimal values for mode bits. If not specified, the volume defaultMode will be used. This might be in conflict with other options that affect the file mode, like fsGroup, and the result can be other mode bits set. format: int32 type: integer path: description: |- path is the relative path of the file to map the key to. May not be an absolute path. May not contain the path element '..'. May not start with the string '..'. type: string required: - key - path type: object type: array optional: description: optional field specify whether the Secret or its keys must be defined type: boolean secretName: description: |- secretName is the name of the secret in the pod's namespace to use. More info: https://kubernetes.io/docs/concepts/storage/volumes#secret type: string type: object storageos: description: storageOS represents a StorageOS volume attached and mounted on Kubernetes nodes. properties: fsType: description: |- fsType is the filesystem type to mount. Must be a filesystem type supported by the host operating system. Ex. \"ext4\", \"xfs\", \"ntfs\". Implicitly inferred to be \"ext4\" if unspecified. type: string readOnly: description: |- readOnly defaults to false (read/write). ReadOnly here will force the ReadOnly setting in VolumeMounts. type: boolean secretRef: description: |- secretRef specifies the secret to use for obtaining the StorageOS API credentials. If not specified, default values will be attempted. properties: name: description: |- Name of the referent. More info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names TODO: Add other useful fields. apiVersion, kind, uid? type: string type: object x-kubernetes-map-type: atomic volumeName: description: |- volumeName is the human-readable name of the StorageOS volume. Volume names are only unique within a namespace. type: string volumeNamespace: description: |- volumeNamespace specifies the scope of the volume within StorageOS. If no namespace is specified then the Pod's namespace will be used. This allows the Kubernetes name scoping to be mirrored within StorageOS for tighter integration. Set VolumeName to any name to override the default behaviour. Set to \"default\" if you are not using namespaces within StorageOS. Namespaces that do not pre-exist within StorageOS will be created. type: string type: object vsphereVolume: description: vsphereVolume represents a vSphere volume attached and mounted on kubelets host machine properties: fsType: description: |- fsType is filesystem type to mount. Must be a filesystem type supported by the host operating system. Ex. \"ext4\", \"xfs\", \"ntfs\". Implicitly inferred to be \"ext4\" if unspecified. type: string storagePolicyID: description: storagePolicyID is the storage Policy Based Management (SPBM) profile ID associated with the StoragePolicyName. type: string storagePolicyName: description: storagePolicyName is the storage Policy Based Management (SPBM) profile name. type: string volumePath: description: volumePath is the path that identifies vSphere volume vmdk type: string required: - volumePath type: object required: - name type: object type: array required: - containers type: object type: object required: - count - name - template type: object maxItems: 8 minItems: 1 type: array x-kubernetes-list-map-keys: - name x-kubernetes-list-type: map priority: description: |- Priority determines the order of access to the resources managed by the ClusterQueue where the workload is queued. The priority value is populated from PriorityClassName. The higher the value, the higher the priority. If priorityClassName is specified, priority must not be null. format: int32 type: integer priorityClassName: description: |- If specified, indicates the workload's priority. \"system-node-critical\" and \"system-cluster-critical\" are two special keywords which indicate the highest priorities with the former being the highest priority. Any other name must be defined by creating a PriorityClass object with that name. If not specified, the workload priority will be default or zero if there is no default. type: string priorityClassSource: default: \"\" description: |- priorityClassSource determines whether the priorityClass field refers to a pod PriorityClass or kueue.x-k8s.io/workloadpriorityclass. Workload's PriorityClass can accept the name of a pod priorityClass or a workloadPriorityClass. When using pod PriorityClass, a priorityClassSource field has the scheduling.k8s.io/priorityclass value. enum: - kueue.x-k8s.io/workloadpriorityclass - scheduling.k8s.io/priorityclass - \"\" type: string queueName: description: |- queueName is the name of the LocalQueue the Workload is associated with. queueName cannot be changed while .status.admission is not null. type: string required: - podSets type: object status: description: WorkloadStatus defines the observed state of Workload properties: admission: description: |- admission holds the parameters of the admission of the workload by a ClusterQueue. admission can be set back to null, but its fields cannot be changed once set. properties: clusterQueue: description: clusterQueue is the name of the ClusterQueue that admitted this workload. type: string podSetAssignments: description: PodSetAssignments hold the admission results for each of the .spec.podSets entries. items: properties: count: description: |- count is the number of pods taken into account at admission time. This field will not change in case of quota reclaim. Value could be missing for Workloads created before this field was added, in that case spec.podSets[*].count value will be used. format: int32 minimum: 0 type: integer flavors: additionalProperties: description: ResourceFlavorReference is the name of the ResourceFlavor. type: string description: Flavors are the flavors assigned to the workload for each resource. type: object name: default: main description: Name is the name of the podSet. It should match one of the names in .spec.podSets. type: string resourceUsage: additionalProperties: anyOf: - type: integer - type: string pattern: ^(\\+|-)?(([0-9]+(\\.[0-9]*)?)|(\\.[0-9]+))(([KMGTPE]i)|[numkMGTPE]|([eE](\\+|-)?(([0-9]+(\\.[0-9]*)?)|(\\.[0-9]+))))?$ x-kubernetes-int-or-string: true description: |- resourceUsage keeps track of the total resources all the pods in the podset need to run. Beside what is provided in podSet's specs, this calculation takes into account the LimitRange defaults and RuntimeClass overheads at the moment of admission. This field will not change in case of quota reclaim. type: object required: - name type: object type: array x-kubernetes-list-map-keys: - name x-kubernetes-list-type: map required: - clusterQueue - podSetAssignments type: object admissionChecks: description: admissionChecks list all the admission checks required by the workload and the current status items: properties: lastTransitionTime: description: |- lastTransitionTime is the last time the condition transitioned from one status to another. This should be when the underlying condition changed. If that is not known, then using the time when the API field changed is acceptable. format: date-time type: string message: description: |- message is a human readable message indicating details about the transition. This may be an empty string. maxLength: 32768 type: string name: description: name identifies the admission check. maxLength: 316 type: string podSetUpdates: items: description: |- PodSetUpdate contains a list of pod set modifications suggested by AdmissionChecks. The modifications should be additive only - modifications of already existing keys or having the same key provided by multiple AdmissionChecks is not allowed and will result in failure during workload admission. properties: annotations: additionalProperties: type: string type: object labels: additionalProperties: type: string type: object name: description: Name of the PodSet to modify. Should match to one of the Workload's PodSets. type: string nodeSelector: additionalProperties: type: string type: object tolerations: items: description: |- The pod this Toleration is attached to tolerates any taint that matches the triple using the matching operator . properties: effect: description: |- Effect indicates the taint effect to match. Empty means match all taint effects. When specified, allowed values are NoSchedule, PreferNoSchedule and NoExecute. type: string key: description: |- Key is the taint key that the toleration applies to. Empty means match all taint keys. If the key is empty, operator must be Exists; this combination means to match all values and all keys. type: string operator: description: |- Operator represents a key's relationship to the value. Valid operators are Exists and Equal. Defaults to Equal. Exists is equivalent to wildcard for value, so that a pod can tolerate all taints of a particular category. type: string tolerationSeconds: description: |- TolerationSeconds represents the period of time the toleration (which must be of effect NoExecute, otherwise this field is ignored) tolerates the taint. By default, it is not set, which means tolerate the taint forever (do not evict). Zero and negative values will be treated as 0 (evict immediately) by the system. format: int64 type: integer value: description: |- Value is the taint value the toleration matches to. If the operator is Exists, the value should be empty, otherwise just a regular string. type: string type: object type: array required: - name type: object type: array x-kubernetes-list-type: atomic state: description: state of the admissionCheck, one of Pending, Ready, Retry, Rejected enum: - Pending - Ready - Retry - Rejected type: string required: - lastTransitionTime - message - name - state type: object type: array x-kubernetes-list-map-keys: - name x-kubernetes-list-type: map conditions: description: |- conditions hold the latest available observations of the Workload current state. The type of the condition could be: - Admitted: the Workload was admitted through a ClusterQueue. - Finished: the associated workload finished running (failed or succeeded). - PodsReady: at least `.spec.podSets[*].count` Pods are ready or have succeeded. items: description: \"Condition contains details for one aspect of the current state of this API Resource.\\n---\\nThis struct is intended for direct use as an array at the field path .status.conditions. For example,\\n\\n\\n\\ttype FooStatus struct{\\n\\t // Represents the observations of a foo's current state.\\n\\t // Known .status.conditions.type are: \\\"Available\\\", \\\"Progressing\\\", and \\\"Degraded\\\"\\n\\t // +patchMergeKey=type\\n\\t // +patchStrategy=merge\\n\\t // +listType=map\\n\\t \\ // +listMapKey=type\\n\\t Conditions []metav1.Condition `json:\\\"conditions,omitempty\\\" patchStrategy:\\\"merge\\\" patchMergeKey:\\\"type\\\" protobuf:\\\"bytes,1,rep,name=conditions\\\"`\\n\\n\\n\\t \\ // other fields\\n\\t}\" properties: lastTransitionTime: description: |- lastTransitionTime is the last time the condition transitioned from one status to another. This should be when the underlying condition changed. If that is not known, then using the time when the API field changed is acceptable. format: date-time type: string message: description: |- message is a human readable message indicating details about the transition. This may be an empty string. maxLength: 32768 type: string observedGeneration: description: |- observedGeneration represents the .metadata.generation that the condition was set based upon. For instance, if .metadata.generation is currently 12, but the .status.conditions[x].observedGeneration is 9, the condition is out of date with respect to the current state of the instance. format: int64 minimum: 0 type: integer reason: description: |- reason contains a programmatic identifier indicating the reason for the condition's last transition. Producers of specific condition types may define expected values and meanings for this field, and whether the values are considered a guaranteed API. The value should be a CamelCase string. This field may not be empty. maxLength: 1024 minLength: 1 pattern: ^[A-Za-z]([A-Za-z0-9_,:]*[A-Za-z0-9_])?$ type: string status: description: status of the condition, one of True, False, Unknown. enum: - \"True\" - \"False\" - Unknown type: string type: description: |- type of condition in CamelCase or in foo.example.com/CamelCase. --- Many .condition.type values are consistent across resources like Available, but because arbitrary conditions can be useful (see .node.status.conditions), the ability to deconflict is important. The regex it matches is (dns1123SubdomainFmt/)?(qualifiedNameFmt) maxLength: 316 pattern: ^([a-z0-9]([-a-z0-9]*[a-z0-9])?(\\.[a-z0-9]([-a-z0-9]*[a-z0-9])?)*/)?(([A-Za-z0-9][-A-Za-z0-9_.]*)?[A-Za-z0-9])$ type: string required: - lastTransitionTime - message - reason - status - type type: object type: array x-kubernetes-list-map-keys: - type x-kubernetes-list-type: map reclaimablePods: description: |- reclaimablePods keeps track of the number pods within a podset for which the resource reservation is no longer needed. items: properties: count: description: count is the number of pods for which the requested resources are no longer needed. format: int32 minimum: 0 type: integer name: description: name is the PodSet name. type: string required: - count - name type: object type: array x-kubernetes-list-map-keys: - name x-kubernetes-list-type: map requeueState: description: |- requeueState holds the re-queue state when a workload meets Eviction with PodsReadyTimeout reason. properties: count: description: |- count records the number of times a workload has been re-queued When a deactivated (`.spec.activate`=`false`) workload is reactivated (`.spec.activate`=`true`), this count would be reset to null. format: int32 minimum: 0 type: integer requeueAt: description: |- requeueAt records the time when a workload will be re-queued. When a deactivated (`.spec.activate`=`false`) workload is reactivated (`.spec.activate`=`true`), this time would be reset to null. format: date-time type: string type: object type: object type: object served: true storage: true subresources: status: {} %/accordion% %accordion% 02kueue-ns.yaml %accordion% apiVersion: v1 kind: Namespace metadata: labels: control-plane: controller-manager name: kueue-system --- apiVersion: rbac.authorization.k8s.io/v1 kind: Role metadata: name: podsecuritypolicy namespace: kueue-system rules: - apiGroups: - policy - extensions resourceNames: - system resources: - podsecuritypolicies verbs: - use --- apiVersion: rbac.authorization.k8s.io/v1 kind: RoleBinding metadata: name: podsecuritypolicy namespace: kueue-system roleRef: apiGroup: rbac.authorization.k8s.io kind: Role name: podsecuritypolicy subjects: - kind: ServiceAccount name: default - kind: ServiceAccount name: kueue-controller-manager %/accordion% %accordion% 03kueue-rbac.yaml %accordion% apiVersion: v1 kind: ServiceAccount metadata: name: kueue-controller-manager namespace: kueue-system --- apiVersion: rbac.authorization.k8s.io/v1 kind: Role metadata: name: kueue-leader-election-role namespace: kueue-system rules: - apiGroups: - \"\" resources: - configmaps verbs: - get - list - watch - create - update - patch - delete - apiGroups: - coordination.k8s.io resources: - leases verbs: - get - list - watch - create - update - patch - delete - apiGroups: - \"\" resources: - events verbs: - create - patch --- apiVersion: rbac.authorization.k8s.io/v1 kind: RoleBinding metadata: name: kueue-leader-election-rolebinding namespace: kueue-system roleRef: apiGroup: rbac.authorization.k8s.io kind: Role name: kueue-leader-election-role subjects: - kind: ServiceAccount name: kueue-controller-manager namespace: kueue-system --- apiVersion: rbac.authorization.k8s.io/v1 kind: ClusterRole metadata: name: kueue-batch-admin-role aggregationRule: clusterRoleSelectors: - matchLabels: rbac.kueue.x-k8s.io/batch-admin: \"true\" --- apiVersion: rbac.authorization.k8s.io/v1 kind: ClusterRole metadata: name: kueue-batch-user-role aggregationRule: clusterRoleSelectors: - matchLabels: rbac.kueue.x-k8s.io/batch-user: \"true\" --- apiVersion: rbac.authorization.k8s.io/v1 kind: ClusterRole metadata: labels: rbac.kueue.x-k8s.io/batch-admin: \"true\" name: kueue-clusterqueue-editor-role rules: - apiGroups: - kueue.x-k8s.io resources: - clusterqueues verbs: - create - delete - get - list - patch - update - watch - apiGroups: - kueue.x-k8s.io resources: - clusterqueues/status verbs: - get --- apiVersion: rbac.authorization.k8s.io/v1 kind: ClusterRole metadata: labels: rbac.kueue.x-k8s.io/batch-admin: \"true\" name: kueue-clusterqueue-viewer-role rules: - apiGroups: - kueue.x-k8s.io resources: - clusterqueues verbs: - get - list - watch - apiGroups: - kueue.x-k8s.io resources: - clusterqueues/status verbs: - get --- apiVersion: rbac.authorization.k8s.io/v1 kind: ClusterRole metadata: labels: rbac.kueue.x-k8s.io/batch-admin: \"true\" rbac.kueue.x-k8s.io/batch-user: \"true\" name: kueue-job-editor-role rules: - apiGroups: - batch resources: - jobs verbs: - create - delete - get - list - patch - update - watch - apiGroups: - batch resources: - jobs/status verbs: - get --- apiVersion: rbac.authorization.k8s.io/v1 kind: ClusterRole metadata: labels: rbac.kueue.x-k8s.io/batch-admin: \"true\" rbac.kueue.x-k8s.io/batch-user: \"true\" name: kueue-job-viewer-role rules: - apiGroups: - batch resources: - jobs verbs: - get - list - watch - apiGroups: - batch resources: - jobs/status verbs: - get --- apiVersion: rbac.authorization.k8s.io/v1 kind: ClusterRole metadata: labels: rbac.kueue.x-k8s.io/batch-admin: \"true\" rbac.kueue.x-k8s.io/batch-user: \"true\" name: kueue-jobset-editor-role rules: - apiGroups: - jobset.x-k8s.io resources: - jobsets verbs: - create - delete - get - list - patch - update - watch - apiGroups: - jobset.x-k8s.io resources: - jobsets/status verbs: - get --- apiVersion: rbac.authorization.k8s.io/v1 kind: ClusterRole metadata: labels: rbac.kueue.x-k8s.io/batch-admin: \"true\" rbac.kueue.x-k8s.io/batch-user: \"true\" name: kueue-jobset-viewer-role rules: - apiGroups: - jobset.x-k8s.io resources: - jobsets verbs: - get - list - watch - apiGroups: - jobset.x-k8s.io resources: - jobsets/status verbs: - get --- apiVersion: rbac.authorization.k8s.io/v1 kind: ClusterRole metadata: labels: rbac.kueue.x-k8s.io/batch-admin: \"true\" name: kueue-localqueue-editor-role rules: - apiGroups: - kueue.x-k8s.io resources: - localqueues verbs: - create - delete - get - list - patch - update - watch - apiGroups: - kueue.x-k8s.io resources: - localqueues/status verbs: - get --- apiVersion: rbac.authorization.k8s.io/v1 kind: ClusterRole metadata: labels: rbac.kueue.x-k8s.io/batch-admin: \"true\" rbac.kueue.x-k8s.io/batch-user: \"true\" name: kueue-localqueue-viewer-role rules: - apiGroups: - kueue.x-k8s.io resources: - localqueues verbs: - get - list - watch - apiGroups: - kueue.x-k8s.io resources: - localqueues/status verbs: - get --- apiVersion: rbac.authorization.k8s.io/v1 kind: ClusterRole metadata: name: kueue-manager-role rules: - apiGroups: - \"\" resources: - events verbs: - create - patch - update - watch - apiGroups: - \"\" resources: - limitranges verbs: - get - list - watch - apiGroups: - \"\" resources: - namespaces verbs: - get - list - watch - apiGroups: - \"\" resources: - pods verbs: - delete - get - list - patch - update - watch - apiGroups: - \"\" resources: - pods/finalizers verbs: - get - update - apiGroups: - \"\" resources: - pods/status verbs: - get - patch - apiGroups: - \"\" resources: - podtemplates verbs: - create - delete - get - list - update - watch - apiGroups: - \"\" resources: - secrets verbs: - get - list - update - watch - apiGroups: - admissionregistration.k8s.io resources: - mutatingwebhookconfigurations verbs: - get - list - update - watch - apiGroups: - admissionregistration.k8s.io resources: - validatingwebhookconfigurations verbs: - get - list - update - watch - apiGroups: - autoscaling.x-k8s.io resources: - provisioningrequests verbs: - create - delete - get - list - patch - update - watch - apiGroups: - autoscaling.x-k8s.io resources: - provisioningrequests/status verbs: - get - apiGroups: - batch resources: - jobs verbs: - get - list - patch - update - watch - apiGroups: - batch resources: - jobs/finalizers verbs: - get - patch - update - apiGroups: - batch resources: - jobs/status verbs: - get - update - apiGroups: - flowcontrol.apiserver.k8s.io resources: - flowschemas verbs: - list - watch - apiGroups: - flowcontrol.apiserver.k8s.io resources: - flowschemas/status verbs: - patch - apiGroups: - flowcontrol.apiserver.k8s.io resources: - prioritylevelconfigurations verbs: - list - watch - apiGroups: - jobset.x-k8s.io resources: - jobsets verbs: - get - list - patch - update - watch - apiGroups: - jobset.x-k8s.io resources: - jobsets/finalizers verbs: - get - update - apiGroups: - jobset.x-k8s.io resources: - jobsets/status verbs: - get - update - apiGroups: - kubeflow.org resources: - mpijobs verbs: - get - list - patch - update - watch - apiGroups: - kubeflow.org resources: - mpijobs/finalizers verbs: - get - update - apiGroups: - kubeflow.org resources: - mpijobs/status verbs: - get - update - apiGroups: - kubeflow.org resources: - mxjobs verbs: - get - list - patch - update - watch - apiGroups: - kubeflow.org resources: - mxjobs/finalizers verbs: - get - update - apiGroups: - kubeflow.org resources: - mxjobs/status verbs: - get - update - apiGroups: - kubeflow.org resources: - paddlejobs verbs: - get - list - patch - update - watch - apiGroups: - kubeflow.org resources: - paddlejobs/finalizers verbs: - get - update - apiGroups: - kubeflow.org resources: - paddlejobs/status verbs: - get - update - apiGroups: - kubeflow.org resources: - pytorchjobs verbs: - get - list - patch - update - watch - apiGroups: - kubeflow.org resources: - pytorchjobs/finalizers verbs: - get - update - apiGroups: - kubeflow.org resources: - pytorchjobs/status verbs: - get - update - apiGroups: - kubeflow.org resources: - tfjobs verbs: - get - list - patch - update - watch - apiGroups: - kubeflow.org resources: - tfjobs/finalizers verbs: - get - update - apiGroups: - kubeflow.org resources: - tfjobs/status verbs: - get - update - apiGroups: - kubeflow.org resources: - xgboostjobs verbs: - get - list - patch - update - watch - apiGroups: - kubeflow.org resources: - xgboostjobs/finalizers verbs: - get - update - apiGroups: - kubeflow.org resources: - xgboostjobs/status verbs: - get - update - apiGroups: - kueue.x-k8s.io resources: - admissionchecks verbs: - create - delete - get - list - patch - update - watch - apiGroups: - kueue.x-k8s.io resources: - admissionchecks/finalizers verbs: - update - apiGroups: - kueue.x-k8s.io resources: - admissionchecks/status verbs: - get - patch - update - apiGroups: - kueue.x-k8s.io resources: - clusterqueues verbs: - create - delete - get - list - patch - update - watch - apiGroups: - kueue.x-k8s.io resources: - clusterqueues/finalizers verbs: - update - apiGroups: - kueue.x-k8s.io resources: - clusterqueues/status verbs: - get - patch - update - apiGroups: - kueue.x-k8s.io resources: - localqueues verbs: - create - delete - get - list - patch - update - watch - apiGroups: - kueue.x-k8s.io resources: - localqueues/finalizers verbs: - update - apiGroups: - kueue.x-k8s.io resources: - localqueues/status verbs: - get - patch - update - apiGroups: - kueue.x-k8s.io resources: - multikueueclusters verbs: - get - list - watch - apiGroups: - kueue.x-k8s.io resources: - multikueueclusters/status verbs: - get - patch - update - apiGroups: - kueue.x-k8s.io resources: - multikueueconfigs verbs: - get - list - watch - apiGroups: - kueue.x-k8s.io resources: - provisioningrequestconfigs verbs: - get - list - watch - apiGroups: - kueue.x-k8s.io resources: - resourceflavors verbs: - delete - get - list - update - watch - apiGroups: - kueue.x-k8s.io resources: - resourceflavors/finalizers verbs: - update - apiGroups: - kueue.x-k8s.io resources: - workloadpriorityclasses verbs: - get - list - watch - apiGroups: - kueue.x-k8s.io resources: - workloads verbs: - create - delete - get - list - patch - update - watch - apiGroups: - kueue.x-k8s.io resources: - workloads/finalizers verbs: - update - apiGroups: - kueue.x-k8s.io resources: - workloads/status verbs: - get - patch - update - apiGroups: - node.k8s.io resources: - runtimeclasses verbs: - get - list - watch - apiGroups: - ray.io resources: - rayclusters verbs: - get - list - patch - update - watch - apiGroups: - ray.io resources: - rayclusters/finalizers verbs: - get - update - apiGroups: - ray.io resources: - rayclusters/status verbs: - get - update - apiGroups: - ray.io resources: - rayjobs verbs: - get - list - patch - update - watch - apiGroups: - ray.io resources: - rayjobs/finalizers verbs: - get - update - apiGroups: - ray.io resources: - rayjobs/status verbs: - get - update - apiGroups: - scheduling.k8s.io resources: - priorityclasses verbs: - get - list - watch --- apiVersion: rbac.authorization.k8s.io/v1 kind: ClusterRoleBinding metadata: name: kueue-manager-rolebinding roleRef: apiGroup: rbac.authorization.k8s.io kind: ClusterRole name: kueue-manager-role subjects: - kind: ServiceAccount name: kueue-controller-manager namespace: kueue-system --- apiVersion: rbac.authorization.k8s.io/v1 kind: ClusterRole metadata: name: kueue-metrics-reader rules: - nonResourceURLs: - /metrics verbs: - get --- apiVersion: rbac.authorization.k8s.io/v1 kind: ClusterRole metadata: labels: rbac.kueue.x-k8s.io/batch-admin: \"true\" rbac.kueue.x-k8s.io/batch-user: \"true\" name: kueue-mpijob-editor-role rules: - apiGroups: - kubeflow.org resources: - mpijobs verbs: - create - delete - get - list - patch - update - watch - apiGroups: - kubeflow.org resources: - mpijobs/status verbs: - get --- apiVersion: rbac.authorization.k8s.io/v1 kind: ClusterRole metadata: labels: rbac.kueue.x-k8s.io/batch-admin: \"true\" rbac.kueue.x-k8s.io/batch-user: \"true\" name: kueue-mpijob-viewer-role rules: - apiGroups: - kubeflow.org resources: - mpijobs verbs: - get - list - watch - apiGroups: - kubeflow.org resources: - mpijobs/status verbs: - get --- apiVersion: rbac.authorization.k8s.io/v1 kind: ClusterRole metadata: labels: rbac.kueue.x-k8s.io/batch-admin: \"true\" rbac.kueue.x-k8s.io/batch-user: \"true\" name: kueue-mxjob-editor-role rules: - apiGroups: - kubeflow.org resources: - mxjobs verbs: - create - delete - get - list - patch - update - watch - apiGroups: - kubeflow.org resources: - mxjobs/status verbs: - get --- apiVersion: rbac.authorization.k8s.io/v1 kind: ClusterRole metadata: labels: rbac.kueue.x-k8s.io/batch-admin: \"true\" rbac.kueue.x-k8s.io/batch-user: \"true\" name: kueue-mxjob-viewer-role rules: - apiGroups: - kubeflow.org resources: - mxjobs verbs: - get - list - watch - apiGroups: - kubeflow.org resources: - mxjobs/status verbs: - get --- apiVersion: rbac.authorization.k8s.io/v1 kind: ClusterRole metadata: labels: rbac.kueue.x-k8s.io/batch-admin: \"true\" rbac.kueue.x-k8s.io/batch-user: \"true\" name: kueue-paddlejob-editor-role rules: - apiGroups: - kubeflow.org resources: - paddlejobs verbs: - create - delete - get - list - patch - update - watch - apiGroups: - kubeflow.org resources: - paddlejobs/status verbs: - get --- apiVersion: rbac.authorization.k8s.io/v1 kind: ClusterRole metadata: labels: rbac.kueue.x-k8s.io/batch-admin: \"true\" rbac.kueue.x-k8s.io/batch-user: \"true\" name: kueue-paddlejob-viewer-role rules: - apiGroups: - kubeflow.org resources: - paddlejobs verbs: - get - list - watch - apiGroups: - kubeflow.org resources: - paddlejobs/status verbs: - get --- apiVersion: rbac.authorization.k8s.io/v1 kind: ClusterRole metadata: labels: rbac.kueue.x-k8s.io/batch-admin: \"true\" name: kueue-pending-workloads-cq-viewer-role rules: - apiGroups: - visibility.kueue.x-k8s.io resources: - clusterqueues/pendingworkloads verbs: - get - list - watch --- apiVersion: rbac.authorization.k8s.io/v1 kind: ClusterRole metadata: labels: rbac.kueue.x-k8s.io/batch-admin: \"true\" rbac.kueue.x-k8s.io/batch-user: \"true\" name: kueue-pending-workloads-lq-viewer-role rules: - apiGroups: - visibility.kueue.x-k8s.io resources: - localqueues/pendingworkloads verbs: - get - list - watch --- apiVersion: rbac.authorization.k8s.io/v1 kind: ClusterRole metadata: labels: rbac.kueue.x-k8s.io/batch-admin: \"true\" rbac.kueue.x-k8s.io/batch-user: \"true\" name: kueue-pytorchjob-editor-role rules: - apiGroups: - kubeflow.org resources: - pytorchjobs verbs: - create - delete - get - list - patch - update - watch - apiGroups: - kubeflow.org resources: - pytorchjobs/status verbs: - get --- apiVersion: rbac.authorization.k8s.io/v1 kind: ClusterRole metadata: labels: rbac.kueue.x-k8s.io/batch-admin: \"true\" rbac.kueue.x-k8s.io/batch-user: \"true\" name: kueue-pytorchjob-viewer-role rules: - apiGroups: - kubeflow.org resources: - pytorchjobs verbs: - get - list - watch - apiGroups: - kubeflow.org resources: - pytorchjobs/status verbs: - get --- apiVersion: rbac.authorization.k8s.io/v1 kind: ClusterRole metadata: labels: rbac.kueue.x-k8s.io/batch-admin: \"true\" rbac.kueue.x-k8s.io/batch-user: \"true\" name: kueue-rayjob-editor-role rules: - apiGroups: - ray.io resources: - rayjobs verbs: - create - delete - get - list - patch - update - watch - apiGroups: - ray.io resources: - rayjobs/status verbs: - get --- apiVersion: rbac.authorization.k8s.io/v1 kind: ClusterRole metadata: labels: rbac.kueue.x-k8s.io/batch-admin: \"true\" rbac.kueue.x-k8s.io/batch-user: \"true\" name: kueue-rayjob-viewer-role rules: - apiGroups: - ray.io resources: - rayjobs verbs: - get - list - watch - apiGroups: - ray.io resources: - rayjobs/status verbs: - get --- apiVersion: rbac.authorization.k8s.io/v1 kind: ClusterRole metadata: labels: rbac.kueue.x-k8s.io/batch-admin: \"true\" name: kueue-resourceflavor-editor-role rules: - apiGroups: - kueue.x-k8s.io resources: - resourceflavors verbs: - create - delete - get - list - patch - update - watch --- apiVersion: rbac.authorization.k8s.io/v1 kind: ClusterRole metadata: labels: rbac.kueue.x-k8s.io/batch-admin: \"true\" name: kueue-resourceflavor-viewer-role rules: - apiGroups: - kueue.x-k8s.io resources: - resourceflavors verbs: - get - list - watch --- apiVersion: rbac.authorization.k8s.io/v1 kind: ClusterRole metadata: labels: rbac.kueue.x-k8s.io/batch-admin: \"true\" rbac.kueue.x-k8s.io/batch-user: \"true\" name: kueue-tfjob-editor-role rules: - apiGroups: - kubeflow.org resources: - tfjobs verbs: - create - delete - get - list - patch - update - watch - apiGroups: - kubeflow.org resources: - tfjobs/status verbs: - get --- apiVersion: rbac.authorization.k8s.io/v1 kind: ClusterRole metadata: labels: rbac.kueue.x-k8s.io/batch-admin: \"true\" rbac.kueue.x-k8s.io/batch-user: \"true\" name: kueue-tfjob-viewer-role rules: - apiGroups: - kubeflow.org resources: - tfjobs verbs: - get - list - watch - apiGroups: - kubeflow.org resources: - tfjobs/status verbs: - get --- apiVersion: rbac.authorization.k8s.io/v1 kind: ClusterRole metadata: labels: rbac.kueue.x-k8s.io/batch-admin: \"true\" name: kueue-workload-editor-role rules: - apiGroups: - kueue.x-k8s.io resources: - workloads verbs: - create - delete - get - list - patch - update - watch - apiGroups: - kueue.x-k8s.io resources: - workloads/status verbs: - get --- apiVersion: rbac.authorization.k8s.io/v1 kind: ClusterRole metadata: labels: rbac.kueue.x-k8s.io/batch-admin: \"true\" rbac.kueue.x-k8s.io/batch-user: \"true\" name: kueue-workload-viewer-role rules: - apiGroups: - kueue.x-k8s.io resources: - workloads verbs: - get - list - watch - apiGroups: - kueue.x-k8s.io resources: - workloads/status verbs: - get --- apiVersion: rbac.authorization.k8s.io/v1 kind: ClusterRole metadata: labels: rbac.kueue.x-k8s.io/batch-admin: \"true\" rbac.kueue.x-k8s.io/batch-user: \"true\" name: kueue-xgboostjob-editor-role rules: - apiGroups: - kubeflow.org resources: - xgboostjobs verbs: - create - delete - get - list - patch - update - watch - apiGroups: - kubeflow.org resources: - xgboostjobs/status verbs: - get --- apiVersion: rbac.authorization.k8s.io/v1 kind: ClusterRole metadata: labels: rbac.kueue.x-k8s.io/batch-admin: \"true\" rbac.kueue.x-k8s.io/batch-user: \"true\" name: kueue-xgboostjob-viewer-role rules: - apiGroups: - kubeflow.org resources: - xgboostjobs verbs: - get - list - watch - apiGroups: - kubeflow.org resources: - xgboostjobs/status verbs: - get --- apiVersion: rbac.authorization.k8s.io/v1 kind: ClusterRole metadata: name: kueue-proxy-role rules: - apiGroups: - authentication.k8s.io resources: - tokenreviews verbs: - create - apiGroups: - authorization.k8s.io resources: - subjectaccessreviews verbs: - create --- apiVersion: rbac.authorization.k8s.io/v1 kind: ClusterRoleBinding metadata: name: kueue-proxy-rolebinding roleRef: apiGroup: rbac.authorization.k8s.io kind: ClusterRole name: kueue-proxy-role subjects: - kind: ServiceAccount name: kueue-controller-manager namespace: kueue-system %/accordion% %accordion% 04deploy.yaml %accordion% apiVersion: v1 kind: ConfigMap metadata: name: kueue-manager-config namespace: kueue-system data: controller_manager_config.yaml: | apiVersion: config.kueue.x-k8s.io/v1beta1 kind: Configuration health: healthProbeBindAddress: :8081 metrics: bindAddress: :8080 # enableClusterQueueResources: true webhook: port: 9443 leaderElection: leaderElect: true resourceName: c1f6bfd2.kueue.x-k8s.io controller: groupKindConcurrency: Job.batch: 5 Pod: 5 Workload.kueue.x-k8s.io: 5 LocalQueue.kueue.x-k8s.io: 1 ClusterQueue.kueue.x-k8s.io: 1 ResourceFlavor.kueue.x-k8s.io: 1 clientConnection: qps: 50 burst: 100 #pprofBindAddress: :8082 #waitForPodsReady: # enable: true #manageJobsWithoutQueueName: true #internalCertManagement: # enable: false # webhookServiceName: \"\" # webhookSecretName: \"\" integrations: frameworks: - \"batch/job\" - \"kubeflow.org/mpijob\" - \"ray.io/rayjob\" - \"ray.io/raycluster\" - \"jobset.x-k8s.io/jobset\" - \"kubeflow.org/mxjob\" - \"kubeflow.org/paddlejob\" - \"kubeflow.org/pytorchjob\" - \"kubeflow.org/tfjob\" - \"kubeflow.org/xgboostjob\" # - \"pod\" # podOptions: # namespaceSelector: # matchExpressions: # - key: kubernetes.io/metadata.name # operator: NotIn # values: [ kube-system, kueue-system ] --- apiVersion: v1 kind: Secret metadata: name: kueue-webhook-server-cert namespace: kueue-system --- apiVersion: v1 kind: Service metadata: labels: control-plane: controller-manager name: kueue-controller-manager-metrics-service namespace: kueue-system spec: ports: - name: https port: 8443 protocol: TCP targetPort: https selector: control-plane: controller-manager --- apiVersion: v1 kind: Service metadata: name: kueue-webhook-service namespace: kueue-system spec: ports: - port: 443 protocol: TCP targetPort: 9443 selector: control-plane: controller-manager --- apiVersion: apps/v1 kind: Deployment metadata: labels: control-plane: controller-manager name: kueue-controller-manager namespace: kueue-system spec: replicas: 1 selector: matchLabels: control-plane: controller-manager template: metadata: annotations: kubectl.kubernetes.io/default-container: manager labels: control-plane: controller-manager spec: containers: - args: - --config=/controller_manager_config.yaml - --zap-log-level=2 command: - /manager image: 172.22.96.158/system_containers/kueue:v0.6.2 imagePullPolicy: Always livenessProbe: httpGet: path: /healthz port: 8081 initialDelaySeconds: 15 periodSeconds: 20 name: manager ports: - containerPort: 8082 name: visibility protocol: TCP - containerPort: 9443 name: webhook-server protocol: TCP readinessProbe: httpGet: path: /readyz port: 8081 initialDelaySeconds: 5 periodSeconds: 10 resources: limits: cpu: 500m memory: 512Mi requests: cpu: 100m memory: 256Mi securityContext: allowPrivilegeEscalation: false volumeMounts: - mountPath: /tmp/k8s-webhook-server/serving-certs name: cert readOnly: true - mountPath: /controller_manager_config.yaml name: manager-config subPath: controller_manager_config.yaml - args: - --secure-listen-address=0.0.0.0:8443 - --upstream=http://127.0.0.1:8080/ - --logtostderr=true - --v=10 image: 172.22.96.158/system_containers/kube-rbac-proxy:v0.8.0 name: kube-rbac-proxy ports: - containerPort: 8443 name: https protocol: TCP securityContext: runAsNonRoot: true serviceAccountName: kueue-controller-manager terminationGracePeriodSeconds: 10 volumes: - name: cert secret: defaultMode: 420 secretName: kueue-webhook-server-cert - configMap: name: kueue-manager-config name: manager-config %/accordion% %accordion% 05webhook.yaml %accordion% apiVersion: admissionregistration.k8s.io/v1 kind: MutatingWebhookConfiguration metadata: name: kueue-mutating-webhook-configuration webhooks: - admissionReviewVersions: - v1 clientConfig: service: name: kueue-webhook-service namespace: kueue-system path: /mutate--v1-pod failurePolicy: Fail name: mpod.kb.io namespaceSelector: matchExpressions: - key: kubernetes.io/metadata.name operator: NotIn values: - kube-system - kueue-system rules: - apiGroups: - \"\" apiVersions: - v1 operations: - CREATE resources: - pods sideEffects: None - admissionReviewVersions: - v1 clientConfig: service: name: kueue-webhook-service namespace: kueue-system path: /mutate-batch-v1-job failurePolicy: Fail name: mjob.kb.io rules: - apiGroups: - batch apiVersions: - v1 operations: - CREATE resources: - jobs sideEffects: None - admissionReviewVersions: - v1 clientConfig: service: name: kueue-webhook-service namespace: kueue-system path: /mutate-jobset-x-k8s-io-v1alpha2-jobset failurePolicy: Fail name: mjobset.kb.io rules: - apiGroups: - jobset.x-k8s.io apiVersions: - v1alpha2 operations: - CREATE resources: - jobsets sideEffects: None - admissionReviewVersions: - v1 clientConfig: service: name: kueue-webhook-service namespace: kueue-system path: /mutate-kubeflow-org-v1-mxjob failurePolicy: Fail name: mmxjob.kb.io rules: - apiGroups: - kubeflow.org apiVersions: - v1 operations: - CREATE resources: - mxjobs sideEffects: None - admissionReviewVersions: - v1 clientConfig: service: name: kueue-webhook-service namespace: kueue-system path: /mutate-kubeflow-org-v1-paddlejob failurePolicy: Fail name: mpaddlejob.kb.io rules: - apiGroups: - kubeflow.org apiVersions: - v1 operations: - CREATE resources: - paddlejobs sideEffects: None - admissionReviewVersions: - v1 clientConfig: service: name: kueue-webhook-service namespace: kueue-system path: /mutate-kubeflow-org-v1-pytorchjob failurePolicy: Fail name: mpytorchjob.kb.io rules: - apiGroups: - kubeflow.org apiVersions: - v1 operations: - CREATE resources: - pytorchjobs sideEffects: None - admissionReviewVersions: - v1 clientConfig: service: name: kueue-webhook-service namespace: kueue-system path: /mutate-kubeflow-org-v1-tfjob failurePolicy: Fail name: mtfjob.kb.io rules: - apiGroups: - kubeflow.org apiVersions: - v1 operations: - CREATE resources: - tfjobs sideEffects: None - admissionReviewVersions: - v1 clientConfig: service: name: kueue-webhook-service namespace: kueue-system path: /mutate-kubeflow-org-v1-xgboostjob failurePolicy: Fail name: mxgboostjob.kb.io rules: - apiGroups: - kubeflow.org apiVersions: - v1 operations: - CREATE resources: - xgboostjobs sideEffects: None - admissionReviewVersions: - v1 clientConfig: service: name: kueue-webhook-service namespace: kueue-system path: /mutate-kubeflow-org-v2beta1-mpijob failurePolicy: Fail name: mmpijob.kb.io rules: - apiGroups: - kubeflow.org apiVersions: - v2beta1 operations: - CREATE resources: - mpijobs sideEffects: None - admissionReviewVersions: - v1 clientConfig: service: name: kueue-webhook-service namespace: kueue-system path: /mutate-ray-io-v1-raycluster failurePolicy: Fail name: mraycluster.kb.io rules: - apiGroups: - ray.io apiVersions: - v1 operations: - CREATE resources: - rayclusters sideEffects: None - admissionReviewVersions: - v1 clientConfig: service: name: kueue-webhook-service namespace: kueue-system path: /mutate-ray-io-v1alpha1-rayjob failurePolicy: Fail name: mrayjob.kb.io rules: - apiGroups: - ray.io apiVersions: - v1alpha1 operations: - CREATE resources: - rayjobs sideEffects: None - admissionReviewVersions: - v1 clientConfig: service: name: kueue-webhook-service namespace: kueue-system path: /mutate-kueue-x-k8s-io-v1beta1-clusterqueue failurePolicy: Fail name: mclusterqueue.kb.io rules: - apiGroups: - kueue.x-k8s.io apiVersions: - v1beta1 operations: - CREATE resources: - clusterqueues sideEffects: None - admissionReviewVersions: - v1 clientConfig: service: name: kueue-webhook-service namespace: kueue-system path: /mutate-kueue-x-k8s-io-v1beta1-resourceflavor failurePolicy: Fail name: mresourceflavor.kb.io rules: - apiGroups: - kueue.x-k8s.io apiVersions: - v1beta1 operations: - CREATE resources: - resourceflavors sideEffects: None - admissionReviewVersions: - v1 clientConfig: service: name: kueue-webhook-service namespace: kueue-system path: /mutate-kueue-x-k8s-io-v1beta1-workload failurePolicy: Fail name: mworkload.kb.io rules: - apiGroups: - kueue.x-k8s.io apiVersions: - v1beta1 operations: - CREATE resources: - workloads sideEffects: None --- apiVersion: admissionregistration.k8s.io/v1 kind: ValidatingWebhookConfiguration metadata: name: kueue-validating-webhook-configuration webhooks: - admissionReviewVersions: - v1 clientConfig: service: name: kueue-webhook-service namespace: kueue-system path: /validate--v1-pod failurePolicy: Fail name: vpod.kb.io namespaceSelector: matchExpressions: - key: kubernetes.io/metadata.name operator: NotIn values: - kube-system - kueue-system rules: - apiGroups: - \"\" apiVersions: - v1 operations: - CREATE - UPDATE resources: - pods sideEffects: None - admissionReviewVersions: - v1 clientConfig: service: name: kueue-webhook-service namespace: kueue-system path: /validate-batch-v1-job failurePolicy: Fail name: vjob.kb.io rules: - apiGroups: - batch apiVersions: - v1 operations: - CREATE - UPDATE resources: - jobs sideEffects: None - admissionReviewVersions: - v1 clientConfig: service: name: kueue-webhook-service namespace: kueue-system path: /validate-jobset-x-k8s-io-v1alpha2-jobset failurePolicy: Fail name: vjobset.kb.io rules: - apiGroups: - jobset.x-k8s.io apiVersions: - v1alpha2 operations: - CREATE - UPDATE resources: - jobsets sideEffects: None - admissionReviewVersions: - v1 clientConfig: service: name: kueue-webhook-service namespace: kueue-system path: /validate-kubeflow-org-v1-mxjob failurePolicy: Fail name: vmxjob.kb.io rules: - apiGroups: - kubeflow.org apiVersions: - v1 operations: - CREATE - UPDATE resources: - mxjobs sideEffects: None - admissionReviewVersions: - v1 clientConfig: service: name: kueue-webhook-service namespace: kueue-system path: /validate-kubeflow-org-v1-paddlejob failurePolicy: Fail name: vpaddlejob.kb.io rules: - apiGroups: - kubeflow.org apiVersions: - v1 operations: - CREATE - UPDATE resources: - paddlejobs sideEffects: None - admissionReviewVersions: - v1 clientConfig: service: name: kueue-webhook-service namespace: kueue-system path: /validate-kubeflow-org-v1-pytorchjob failurePolicy: Fail name: vpytorchjob.kb.io rules: - apiGroups: - kubeflow.org apiVersions: - v1 operations: - CREATE - UPDATE resources: - pytorchjobs sideEffects: None - admissionReviewVersions: - v1 clientConfig: service: name: kueue-webhook-service namespace: kueue-system path: /validate-kubeflow-org-v1-tfjob failurePolicy: Fail name: vtfjob.kb.io rules: - apiGroups: - kubeflow.org apiVersions: - v1 operations: - CREATE - UPDATE resources: - tfjobs sideEffects: None - admissionReviewVersions: - v1 clientConfig: service: name: kueue-webhook-service namespace: kueue-system path: /validate-kubeflow-org-v1-xgboostjob failurePolicy: Fail name: vxgboostjob.kb.io rules: - apiGroups: - kubeflow.org apiVersions: - v1 operations: - CREATE - UPDATE resources: - xgboostjobs sideEffects: None - admissionReviewVersions: - v1 clientConfig: service: name: kueue-webhook-service namespace: kueue-system path: /validate-kubeflow-org-v2beta1-mpijob failurePolicy: Fail name: vmpijob.kb.io rules: - apiGroups: - kubeflow.org apiVersions: - v2beta1 operations: - CREATE - UPDATE resources: - mpijobs sideEffects: None - admissionReviewVersions: - v1 clientConfig: service: name: kueue-webhook-service namespace: kueue-system path: /validate-ray-io-v1-raycluster failurePolicy: Fail name: vraycluster.kb.io rules: - apiGroups: - ray.io apiVersions: - v1 operations: - CREATE - UPDATE resources: - rayclusters sideEffects: None - admissionReviewVersions: - v1 clientConfig: service: name: kueue-webhook-service namespace: kueue-system path: /validate-ray-io-v1alpha1-rayjob failurePolicy: Fail name: vrayjob.kb.io rules: - apiGroups: - ray.io apiVersions: - v1alpha1 operations: - CREATE - UPDATE resources: - rayjobs sideEffects: None - admissionReviewVersions: - v1 clientConfig: service: name: kueue-webhook-service namespace: kueue-system path: /validate-kueue-x-k8s-io-v1beta1-admissioncheck failurePolicy: Fail name: vadmissioncheck.kb.io rules: - apiGroups: - kueue.x-k8s.io apiVersions: - v1beta1 operations: - CREATE - UPDATE resources: - admissionchecks sideEffects: None - admissionReviewVersions: - v1 clientConfig: service: name: kueue-webhook-service namespace: kueue-system path: /validate-kueue-x-k8s-io-v1beta1-clusterqueue failurePolicy: Fail name: vclusterqueue.kb.io rules: - apiGroups: - kueue.x-k8s.io apiVersions: - v1beta1 operations: - CREATE - UPDATE resources: - clusterqueues sideEffects: None - admissionReviewVersions: - v1 clientConfig: service: name: kueue-webhook-service namespace: kueue-system path: /validate-kueue-x-k8s-io-v1beta1-localqueue failurePolicy: Fail name: vlocalqueue.kb.io rules: - apiGroups: - kueue.x-k8s.io apiVersions: - v1beta1 operations: - CREATE - UPDATE resources: - localqueues sideEffects: None - admissionReviewVersions: - v1 clientConfig: service: name: kueue-webhook-service namespace: kueue-system path: /validate-kueue-x-k8s-io-v1beta1-resourceflavor failurePolicy: Fail name: vresourceflavor.kb.io rules: - apiGroups: - kueue.x-k8s.io apiVersions: - v1beta1 operations: - CREATE - UPDATE resources: - resourceflavors sideEffects: None - admissionReviewVersions: - v1 clientConfig: service: name: kueue-webhook-service namespace: kueue-system path: /validate-kueue-x-k8s-io-v1beta1-workload failurePolicy: Fail name: vworkload.kb.io rules: - apiGroups: - kueue.x-k8s.io apiVersions: - v1beta1 operations: - CREATE - UPDATE resources: - workloads - workloads/status sideEffects: None %/accordion% 初始化 CRD 资源 kubectl create -f 01kueue-crds.yaml 创建 Namespace kubectl create -f 02kueue-ns.yaml 初始化 RBAC 权限 kubectl -n kueue-system create -f 03kueue-rbac.yaml 部署 Kueue Controller kubectl -n kueue-system create -f 04deploy.yaml 创建 Webhook kubectl -n kueue-system create -f 05webhook.yaml 生态 Kubeflow (TFJob, MPIJob, etc.) Spark Ray Workflows (Tekton, Argo, etc.) Copyright © Zhenhai Gao 2021 all right reserved发布时间： 2024-06-10 23:03:15 "},"docker/":{"url":"docker/","title":"Docker","keywords":"","body":"Docker — 从入门到实践Docker — 从入门到实践 [][1] v1.3.0 语言 - 简体中文 阅读 Docker 是个划时代的开源项目，它彻底释放了计算虚拟化的威力，极大提高了应用的维护效率，降低了云计算应用开发的成本！使用 Docker，可以让应用的部署、测试和分发都变得前所未有的高效和轻松！ 无论是应用开发者、运维人员、还是其他信息技术从业人员，都有必要认识和掌握 Docker，节约有限的生命。 本书既适用于具备基础 Linux 知识的 Docker 初学者，也希望可供理解原理和实现的高级用户参考。同时，书中给出的实践案例，可供在进行实际部署时借鉴。前六章为基础内容，供用户理解 Docker 的基本概念和操作；7 ~ 9 章介绍包括数据管理、网络等高级操作；第 10 ~ 12 章介绍了容器生态中的几个核心项目；13、14 章讨论了关于 Docker 安全和实现技术等高级话题。后续章节则分别介绍包括 Etcd、Fedora CoreOS、Kubernetes、容器云等相关热门开源项目。最后，还展示了使用容器技术的典型的应用场景和实践案例。 在线阅读：docker-practice.com，GitBook，Github 离线阅读：$ docker run -it --rm -p 4000:80 ccr.ccs.tencentyun.com/dockerpracticesig/docker_practice:vuepress Docker 自身仍在快速发展中，生态环境也在蓬勃成长。建议初学者使用最新稳定版本的 Docker 进行学习实践。欢迎 参与项目维护。 Copyright © Zhenhai Gao 2021 all right reserved发布时间： 2024-06-10 23:03:15 "},"docker/introduction/":{"url":"docker/introduction/","title":"Docker 简介","keywords":"","body":"简介简介 本章将带领你进入 Docker 的世界。 什么是 Docker？ 用它会带来什么样的好处？ 好吧，让我们带着问题开始这神奇之旅。 Copyright © Zhenhai Gao 2021 all right reserved发布时间： 2024-06-10 23:03:15 "},"docker/introduction/what.html":{"url":"docker/introduction/what.html","title":"什么是 Docker","keywords":"","body":"什么是 Docker什么是 Docker Docker 最初是 dotCloud 公司创始人 Solomon Hykes 在法国期间发起的一个公司内部项目，它是基于 dotCloud 公司多年云服务技术的一次革新，并于 2013 年 3 月以 Apache 2.0 授权协议开源，主要项目代码在 GitHub 上进行维护。Docker 项目后来还加入了 Linux 基金会，并成立推动 开放容器联盟（OCI）。 Docker 自开源后受到广泛的关注和讨论，至今其 GitHub 项目 已经超过 5 万 7 千个星标和一万多个 fork。甚至由于 Docker 项目的火爆，在 2013 年底，dotCloud 公司决定改名为 Docker。Docker 最初是在 Ubuntu 12.04 上开发实现的；Red Hat 则从 RHEL 6.5 开始对 Docker 进行支持；Google 也在其 PaaS 产品中广泛应用 Docker。 Docker 使用 Google 公司推出的 Go 语言 进行开发实现，基于 Linux 内核的 cgroup，namespace，以及 OverlayFS 类的 Union FS 等技术，对进程进行封装隔离，属于 操作系统层面的虚拟化技术。由于隔离的进程独立于宿主和其它的隔离的进程，因此也称其为容器。最初实现是基于 LXC，从 0.7 版本以后开始去除 LXC，转而使用自行开发的 libcontainer，从 1.11 版本开始，则进一步演进为使用 runC 和 containerd。 runc 是一个 Linux 命令行工具，用于根据 OCI容器运行时规范 创建和运行容器。 containerd 是一个守护程序，它管理容器生命周期，提供了在一个节点上执行容器和管理镜像的最小功能集。 Docker 在容器的基础上，进行了进一步的封装，从文件系统、网络互联到进程隔离等等，极大的简化了容器的创建和维护。使得 Docker 技术比虚拟机技术更为轻便、快捷。 下面的图片比较了 Docker 和传统虚拟化方式的不同之处。传统虚拟机技术是虚拟出一套硬件后，在其上运行一个完整操作系统，在该系统上再运行所需应用进程；而容器内的应用进程直接运行于宿主的内核，容器内没有自己的内核，而且也没有进行硬件虚拟。因此容器要比传统虚拟机更为轻便。 Copyright © Zhenhai Gao 2021 all right reserved发布时间： 2024-06-10 23:03:15 "},"docker/introduction/why.html":{"url":"docker/introduction/why.html","title":"为什么要用 Docker","keywords":"","body":"为什么要使用 Docker？更高效的利用系统资源更快速的启动时间一致的运行环境持续交付和部署更轻松的迁移更轻松的维护和扩展对比传统虚拟机总结为什么要使用 Docker？ 作为一种新兴的虚拟化方式，Docker 跟传统的虚拟化方式相比具有众多的优势。 更高效的利用系统资源 由于容器不需要进行硬件虚拟以及运行完整操作系统等额外开销，Docker 对系统资源的利用率更高。无论是应用执行速度、内存损耗或者文件存储速度，都要比传统虚拟机技术更高效。因此，相比虚拟机技术，一个相同配置的主机，往往可以运行更多数量的应用。 更快速的启动时间 传统的虚拟机技术启动应用服务往往需要数分钟，而 Docker 容器应用，由于直接运行于宿主内核，无需启动完整的操作系统，因此可以做到秒级、甚至毫秒级的启动时间。大大的节约了开发、测试、部署的时间。 一致的运行环境 开发过程中一个常见的问题是环境一致性问题。由于开发环境、测试环境、生产环境不一致，导致有些 bug 并未在开发过程中被发现。而 Docker 的镜像提供了除内核外完整的运行时环境，确保了应用运行环境一致性，从而不会再出现 「这段代码在我机器上没问题啊」 这类问题。 持续交付和部署 对开发和运维（DevOps）人员来说，最希望的就是一次创建或配置，可以在任意地方正常运行。 使用 Docker 可以通过定制应用镜像来实现持续集成、持续交付、部署。开发人员可以通过 Dockerfile 来进行镜像构建，并结合 持续集成(Continuous Integration) 系统进行集成测试，而运维人员则可以直接在生产环境中快速部署该镜像，甚至结合 持续部署(Continuous Delivery/Deployment) 系统进行自动部署。 而且使用 Dockerfile 使镜像构建透明化，不仅仅开发团队可以理解应用运行环境，也方便运维团队理解应用运行所需条件，帮助更好的生产环境中部署该镜像。 更轻松的迁移 由于 Docker 确保了执行环境的一致性，使得应用的迁移更加容易。Docker 可以在很多平台上运行，无论是物理机、虚拟机、公有云、私有云，甚至是笔记本，其运行结果是一致的。因此用户可以很轻易的将在一个平台上运行的应用，迁移到另一个平台上，而不用担心运行环境的变化导致应用无法正常运行的情况。 更轻松的维护和扩展 Docker 使用的分层存储以及镜像的技术，使得应用重复部分的复用更为容易，也使得应用的维护更新更加简单，基于基础镜像进一步扩展镜像也变得非常简单。此外，Docker 团队同各个开源项目团队一起维护了一大批高质量的 官方镜像，既可以直接在生产环境使用，又可以作为基础进一步定制，大大的降低了应用服务的镜像制作成本。 对比传统虚拟机总结 特性 容器 虚拟机 启动 秒级 分钟级 硬盘使用 一般为 MB 一般为 GB 性能 接近原生 弱于 系统支持量 单机支持上千个容器 一般几十个 Copyright © Zhenhai Gao 2021 all right reserved发布时间： 2024-06-10 23:03:15 "},"docker/basic-concept/":{"url":"docker/basic-concept/","title":"基本概念","keywords":"","body":"基本概念基本概念 Docker 包括三个基本概念 镜像（Image） 容器（Container） 仓库（Repository） 理解了这三个概念，就理解了 Docker 的整个生命周期。 Copyright © Zhenhai Gao 2021 all right reserved发布时间： 2024-06-10 23:03:15 "},"docker/basic-concept/image.html":{"url":"docker/basic-concept/image.html","title":"镜像","keywords":"","body":"Docker 镜像分层存储Docker 镜像 我们都知道，操作系统分为 内核 和 用户空间。对于 Linux 而言，内核启动后，会挂载 root 文件系统为其提供用户空间支持。而 Docker 镜像（Image），就相当于是一个 root 文件系统。比如官方镜像 ubuntu:18.04 就包含了完整的一套 Ubuntu 18.04 最小系统的 root 文件系统。 Docker 镜像 是一个特殊的文件系统，除了提供容器运行时所需的程序、库、资源、配置等文件外，还包含了一些为运行时准备的一些配置参数（如匿名卷、环境变量、用户等）。镜像 不包含 任何动态数据，其内容在构建之后也不会被改变。 分层存储 因为镜像包含操作系统完整的 root 文件系统，其体积往往是庞大的，因此在 Docker 设计时，就充分利用 Union FS 的技术，将其设计为分层存储的架构。所以严格来说，镜像并非是像一个 ISO 那样的打包文件，镜像只是一个虚拟的概念，其实际体现并非由一个文件组成，而是由一组文件系统组成，或者说，由多层文件系统联合组成。 镜像构建时，会一层层构建，前一层是后一层的基础。每一层构建完就不会再发生改变，后一层上的任何改变只发生在自己这一层。比如，删除前一层文件的操作，实际不是真的删除前一层的文件，而是仅在当前层标记为该文件已删除。在最终容器运行的时候，虽然不会看到这个文件，但是实际上该文件会一直跟随镜像。因此，在构建镜像的时候，需要额外小心，每一层尽量只包含该层需要添加的东西，任何额外的东西应该在该层构建结束前清理掉。 分层存储的特征还使得镜像的复用、定制变的更为容易。甚至可以用之前构建好的镜像作为基础层，然后进一步添加新的层，以定制自己所需的内容，构建新的镜像。 关于镜像构建，将会在后续相关章节中做进一步的讲解。 Copyright © Zhenhai Gao 2021 all right reserved发布时间： 2024-06-10 23:03:15 "},"docker/basic-concept/container.html":{"url":"docker/basic-concept/container.html","title":"容器","keywords":"","body":"Docker 容器Docker 容器 镜像（Image）和容器（Container）的关系，就像是面向对象程序设计中的 类 和 实例 一样，镜像是静态的定义，容器是镜像运行时的实体。容器可以被创建、启动、停止、删除、暂停等。 容器的实质是进程，但与直接在宿主执行的进程不同，容器进程运行于属于自己的独立的 命名空间。因此容器可以拥有自己的 root 文件系统、自己的网络配置、自己的进程空间，甚至自己的用户 ID 空间。容器内的进程是运行在一个隔离的环境里，使用起来，就好像是在一个独立于宿主的系统下操作一样。这种特性使得容器封装的应用比直接在宿主运行更加安全。也因为这种隔离的特性，很多人初学 Docker 时常常会混淆容器和虚拟机。 前面讲过镜像使用的是分层存储，容器也是如此。每一个容器运行时，是以镜像为基础层，在其上创建一个当前容器的存储层，我们可以称这个为容器运行时读写而准备的存储层为 容器存储层。 容器存储层的生存周期和容器一样，容器消亡时，容器存储层也随之消亡。因此，任何保存于容器存储层的信息都会随容器删除而丢失。 按照 Docker 最佳实践的要求，容器不应该向其存储层内写入任何数据，容器存储层要保持无状态化。所有的文件写入操作，都应该使用 数据卷（Volume）、或者 绑定宿主目录，在这些位置的读写会跳过容器存储层，直接对宿主（或网络存储）发生读写，其性能和稳定性更高。 数据卷的生存周期独立于容器，容器消亡，数据卷不会消亡。因此，使用数据卷后，容器删除或者重新运行之后，数据却不会丢失。 Copyright © Zhenhai Gao 2021 all right reserved发布时间： 2024-06-10 23:03:15 "},"docker/basic-concept/repository.html":{"url":"docker/basic-concept/repository.html","title":"仓库","keywords":"","body":"Docker RegistryDocker Registry 公开服务私有 Docker RegistryDocker Registry 镜像构建完成后，可以很容易的在当前宿主机上运行，但是，如果需要在其它服务器上使用这个镜像，我们就需要一个集中的存储、分发镜像的服务，Docker Registry 就是这样的服务。 一个 Docker Registry 中可以包含多个 仓库（Repository）；每个仓库可以包含多个 标签（Tag）；每个标签对应一个镜像。 通常，一个仓库会包含同一个软件不同版本的镜像，而标签就常用于对应该软件的各个版本。我们可以通过 : 的格式来指定具体是这个软件哪个版本的镜像。如果不给出标签，将以 latest 作为默认标签。 以 Ubuntu 镜像 为例，ubuntu 是仓库的名字，其内包含有不同的版本标签，如，16.04, 18.04。我们可以通过 ubuntu:16.04，或者 ubuntu:18.04 来具体指定所需哪个版本的镜像。如果忽略了标签，比如 ubuntu，那将视为 ubuntu:latest。 仓库名经常以 两段式路径 形式出现，比如 jwilder/nginx-proxy，前者往往意味着 Docker Registry 多用户环境下的用户名，后者则往往是对应的软件名。但这并非绝对，取决于所使用的具体 Docker Registry 的软件或服务。 Docker Registry 公开服务 Docker Registry 公开服务是开放给用户使用、允许用户管理镜像的 Registry 服务。一般这类公开服务允许用户免费上传、下载公开的镜像，并可能提供收费服务供用户管理私有镜像。 最常使用的 Registry 公开服务是官方的 Docker Hub，这也是默认的 Registry，并拥有大量的高质量的 官方镜像。除此以外，还有 Red Hat 的 Quay.io；Google 的 Google Container Registry，Kubernetes 的镜像使用的就是这个服务；代码托管平台 GitHub 推出的 ghcr.io。 由于某些原因，在国内访问这些服务可能会比较慢。国内的一些云服务商提供了针对 Docker Hub 的镜像服务（Registry Mirror），这些镜像服务被称为 加速器。常见的有 阿里云加速器、DaoCloud 加速器 等。使用加速器会直接从国内的地址下载 Docker Hub 的镜像，比直接从 Docker Hub 下载速度会提高很多。在 安装 Docker 一节中有详细的配置方法。 国内也有一些云服务商提供类似于 Docker Hub 的公开服务。比如 网易云镜像服务、DaoCloud 镜像市场、阿里云镜像库 等。 私有 Docker Registry 除了使用公开服务外，用户还可以在本地搭建私有 Docker Registry。Docker 官方提供了 Docker Registry 镜像，可以直接使用做为私有 Registry 服务。在 私有仓库 一节中，会有进一步的搭建私有 Registry 服务的讲解。 开源的 Docker Registry 镜像只提供了 Docker Registry API 的服务端实现，足以支持 docker 命令，不影响使用。但不包含图形界面，以及镜像维护、用户管理、访问控制等高级功能。 除了官方的 Docker Registry 外，还有第三方软件实现了 Docker Registry API，甚至提供了用户界面以及一些高级功能。比如，Harbor 和 Sonatype Nexus。 Copyright © Zhenhai Gao 2021 all right reserved发布时间： 2024-06-10 23:03:15 "},"docker/docker-install/":{"url":"docker/docker-install/","title":"安装 Docker","keywords":"","body":"安装 Docker安装 Docker Docker 分为 stable test 和 nightly 三个更新频道。 官方网站上有各种环境下的 安装指南，这里主要介绍 Docker 在 Linux 、Windows 10 和 macOS 上的安装。 Copyright © Zhenhai Gao 2021 all right reserved发布时间： 2024-06-10 23:03:15 "},"docker/docker-install/ubuntu.html":{"url":"docker/docker-install/ubuntu.html","title":"Ubuntu","keywords":"","body":"Ubuntu 安装 Docker准备工作系统要求卸载旧版本使用 APT 安装安装 Docker使用脚本自动安装启动 Docker建立 docker 用户组测试 Docker 是否安装正确镜像加速参考文档Ubuntu 安装 Docker 警告：切勿在没有配置 Docker APT 源的情况下直接使用 apt 命令安装 Docker. 准备工作 系统要求 Docker 支持以下版本的 Ubuntu 操作系统： Ubuntu Hirsute 21.04 Ubuntu Groovy 20.10 Ubuntu Focal 20.04 (LTS) Ubuntu Bionic 18.04 (LTS) Docker 可以安装在 64 位的 x86 平台或 ARM 平台上。Ubuntu 发行版中，LTS（Long-Term-Support）长期支持版本，会获得 5 年的升级维护支持，这样的版本会更稳定，因此在生产环境中推荐使用 LTS 版本。 卸载旧版本 旧版本的 Docker 称为 docker 或者 docker-engine，使用以下命令卸载旧版本： $ sudo apt-get remove docker \\ docker-engine \\ docker.io 使用 APT 安装 由于 apt 源使用 HTTPS 以确保软件下载过程中不被篡改。因此，我们首先需要添加使用 HTTPS 传输的软件包以及 CA 证书。 $ sudo apt-get update $ sudo apt-get install \\ apt-transport-https \\ ca-certificates \\ curl \\ gnupg \\ lsb-release 鉴于国内网络问题，强烈建议使用国内源，官方源请在注释中查看。 为了确认所下载软件包的合法性，需要添加软件源的 GPG 密钥。 $ curl -fsSL https://mirrors.aliyun.com/docker-ce/linux/ubuntu/gpg | sudo gpg --dearmor -o /usr/share/keyrings/docker-archive-keyring.gpg # 官方源 # $ curl -fsSL https://download.docker.com/linux/ubuntu/gpg | sudo gpg --dearmor -o /usr/share/keyrings/docker-archive-keyring.gpg 然后，我们需要向 sources.list 中添加 Docker 软件源 $ echo \\ \"deb [arch=amd64 signed-by=/usr/share/keyrings/docker-archive-keyring.gpg] https://mirrors.aliyun.com/docker-ce/linux/ubuntu \\ $(lsb_release -cs) stable\" | sudo tee /etc/apt/sources.list.d/docker.list > /dev/null # 官方源 # $ echo \\ # \"deb [arch=amd64 signed-by=/usr/share/keyrings/docker-archive-keyring.gpg] https://download.docker.com/linux/ubuntu \\ # $(lsb_release -cs) stable\" | sudo tee /etc/apt/sources.list.d/docker.list > /dev/null 以上命令会添加稳定版本的 Docker APT 镜像源，如果需要测试版本的 Docker 请将 stable 改为 test。 安装 Docker 更新 apt 软件包缓存，并安装 docker-ce： $ sudo apt-get update $ sudo apt-get install docker-ce docker-ce-cli containerd.io 使用脚本自动安装 在测试或开发环境中 Docker 官方为了简化安装流程，提供了一套便捷的安装脚本，Ubuntu 系统上可以使用这套脚本安装，另外可以通过 --mirror 选项使用国内源进行安装： 若你想安装测试版的 Docker, 请从 test.docker.com 获取脚本 # $ curl -fsSL test.docker.com -o get-docker.sh $ curl -fsSL get.docker.com -o get-docker.sh $ sudo sh get-docker.sh --mirror Aliyun # $ sudo sh get-docker.sh --mirror AzureChinaCloud 执行这个命令后，脚本就会自动的将一切准备工作做好，并且把 Docker 的稳定(stable)版本安装在系统中。 启动 Docker $ sudo systemctl enable docker $ sudo systemctl start docker 建立 docker 用户组 默认情况下，docker 命令会使用 Unix socket 与 Docker 引擎通讯。而只有 root 用户和 docker 组的用户才可以访问 Docker 引擎的 Unix socket。出于安全考虑，一般 Linux 系统上不会直接使用 root 用户。因此，更好地做法是将需要使用 docker 的用户加入 docker 用户组。 建立 docker 组： $ sudo groupadd docker 将当前用户加入 docker 组： $ sudo usermod -aG docker $USER 退出当前终端并重新登录，进行如下测试。 测试 Docker 是否安装正确 $ docker run --rm hello-world Unable to find image 'hello-world:latest' locally latest: Pulling from library/hello-world b8dfde127a29: Pull complete Digest: sha256:308866a43596e83578c7dfa15e27a73011bdd402185a84c5cd7f32a88b501a24 Status: Downloaded newer image for hello-world:latest Hello from Docker! This message shows that your installation appears to be working correctly. To generate this message, Docker took the following steps: 1. The Docker client contacted the Docker daemon. 2. The Docker daemon pulled the \"hello-world\" image from the Docker Hub. (amd64) 3. The Docker daemon created a new container from that image which runs the executable that produces the output you are currently reading. 4. The Docker daemon streamed that output to the Docker client, which sent it to your terminal. To try something more ambitious, you can run an Ubuntu container with: $ docker run -it ubuntu bash Share images, automate workflows, and more with a free Docker ID: https://hub.docker.com/ For more examples and ideas, visit: https://docs.docker.com/get-started/ 若能正常输出以上信息，则说明安装成功。 镜像加速 如果在使用过程中发现拉取 Docker 镜像十分缓慢，可以配置 Docker 国内镜像加速。 参考文档 Docker 官方 Ubuntu 安装文档 Copyright © Zhenhai Gao 2021 all right reserved发布时间： 2024-06-10 23:03:15 "},"docker/docker-install/debian.html":{"url":"docker/docker-install/debian.html","title":"Debian","keywords":"","body":"Debian 安装 Docker准备工作系统要求卸载旧版本使用 APT 安装安装 Docker使用脚本自动安装启动 Docker建立 docker 用户组测试 Docker 是否安装正确镜像加速参考文档Debian 安装 Docker 警告：切勿在没有配置 Docker APT 源的情况下直接使用 apt 命令安装 Docker. 准备工作 系统要求 Docker 支持以下版本的 Debian 操作系统： Debian Bullseye 11 Debian Buster 10 卸载旧版本 旧版本的 Docker 称为 docker 或者 docker-engine，使用以下命令卸载旧版本： $ sudo apt-get remove docker \\ docker-engine \\ docker.io 使用 APT 安装 由于 apt 源使用 HTTPS 以确保软件下载过程中不被篡改。因此，我们首先需要添加使用 HTTPS 传输的软件包以及 CA 证书。 $ sudo apt-get update $ sudo apt-get install \\ apt-transport-https \\ ca-certificates \\ curl \\ gnupg \\ lsb-release 鉴于国内网络问题，强烈建议使用国内源，官方源请在注释中查看。 为了确认所下载软件包的合法性，需要添加软件源的 GPG 密钥。 $ curl -fsSL https://mirrors.aliyun.com/docker-ce/linux/debian/gpg | sudo gpg --dearmor -o /usr/share/keyrings/docker-archive-keyring.gpg # 官方源 # $ curl -fsSL https://download.docker.com/linux/debian/gpg | sudo gpg --dearmor -o /usr/share/keyrings/docker-archive-keyring.gpg 然后，我们需要向 sources.list 中添加 Docker 软件源： 在一些基于 Debian 的 Linux 发行版中 $(lsb_release -cs) 可能不会返回 Debian 的版本代号，例如 Kail Linux、 BunsenLabs Linux。在这些发行版中我们需要将下面命令中的 $(lsb_release -cs) 替换为 https://mirrors.aliyun.com/docker-ce/linux/debian/dists/ 中支持的 Debian 版本代号，例如 buster。 $ echo \\ \"deb [arch=amd64 signed-by=/usr/share/keyrings/docker-archive-keyring.gpg] https://mirrors.aliyun.com/docker-ce/linux/debian \\ $(lsb_release -cs) stable\" | sudo tee /etc/apt/sources.list.d/docker.list > /dev/null # 官方源 # $ echo \\ # \"deb [arch=amd64 signed-by=/usr/share/keyrings/docker-archive-keyring.gpg] https://download.docker.com/linux/debian \\ # $(lsb_release -cs) stable\" | sudo tee /etc/apt/sources.list.d/docker.list > /dev/null 以上命令会添加稳定版本的 Docker APT 源，如果需要测试版本的 Docker 请将 stable 改为 test。 安装 Docker 更新 apt 软件包缓存，并安装 docker-ce。 $ sudo apt-get update $ sudo apt-get install docker-ce docker-ce-cli containerd.io 使用脚本自动安装 在测试或开发环境中 Docker 官方为了简化安装流程，提供了一套便捷的安装脚本，Debian 系统上可以使用这套脚本安装，另外可以通过 --mirror 选项使用国内源进行安装： 若你想安装测试版的 Docker, 请从 test.docker.com 获取脚本 # $ curl -fsSL test.docker.com -o get-docker.sh $ curl -fsSL get.docker.com -o get-docker.sh $ sudo sh get-docker.sh --mirror Aliyun # $ sudo sh get-docker.sh --mirror AzureChinaCloud 执行这个命令后，脚本就会自动的将一切准备工作做好，并且把 Docker 的稳定(stable)版本安装在系统中。 启动 Docker $ sudo systemctl enable docker $ sudo systemctl start docker 建立 docker 用户组 默认情况下，docker 命令会使用 Unix socket 与 Docker 引擎通讯。而只有 root 用户和 docker 组的用户才可以访问 Docker 引擎的 Unix socket。出于安全考虑，一般 Linux 系统上不会直接使用 root 用户。因此，更好地做法是将需要使用 docker 的用户加入 docker 用户组。 建立 docker 组： $ sudo groupadd docker 将当前用户加入 docker 组： $ sudo usermod -aG docker $USER 退出当前终端并重新登录，进行如下测试。 测试 Docker 是否安装正确 $ docker run --rm hello-world Unable to find image 'hello-world:latest' locally latest: Pulling from library/hello-world b8dfde127a29: Pull complete Digest: sha256:308866a43596e83578c7dfa15e27a73011bdd402185a84c5cd7f32a88b501a24 Status: Downloaded newer image for hello-world:latest Hello from Docker! This message shows that your installation appears to be working correctly. To generate this message, Docker took the following steps: 1. The Docker client contacted the Docker daemon. 2. The Docker daemon pulled the \"hello-world\" image from the Docker Hub. (amd64) 3. The Docker daemon created a new container from that image which runs the executable that produces the output you are currently reading. 4. The Docker daemon streamed that output to the Docker client, which sent it to your terminal. To try something more ambitious, you can run an Ubuntu container with: $ docker run -it ubuntu bash Share images, automate workflows, and more with a free Docker ID: https://hub.docker.com/ For more examples and ideas, visit: https://docs.docker.com/get-started/ 若能正常输出以上信息，则说明安装成功。 镜像加速 如果在使用过程中发现拉取 Docker 镜像十分缓慢，可以配置 Docker 国内镜像加速。 参考文档 Docker 官方 Debian 安装文档 Copyright © Zhenhai Gao 2021 all right reserved发布时间： 2024-06-10 23:03:15 "},"docker/docker-install/fedora.html":{"url":"docker/docker-install/fedora.html","title":"Fedora","keywords":"","body":"Fedora 安装 Docker准备工作系统要求卸载旧版本使用 dnf 安装安装 Docker使用脚本自动安装启动 Docker建立 docker 用户组测试 Docker 是否安装正确镜像加速参考文档Fedora 安装 Docker 警告：切勿在没有配置 Docker dnf 源的情况下直接使用 dnf 命令安装 Docker. 准备工作 系统要求 Docker 支持以下版本的 Fedora 操作系统： 33 34 卸载旧版本 旧版本的 Docker 称为 docker 或者 docker-engine，使用以下命令卸载旧版本： $ sudo dnf remove docker \\ docker-client \\ docker-client-latest \\ docker-common \\ docker-latest \\ docker-latest-logrotate \\ docker-logrotate \\ docker-selinux \\ docker-engine-selinux \\ docker-engine 使用 dnf 安装 执行以下命令安装依赖包： $ sudo dnf -y install dnf-plugins-core 鉴于国内网络问题，强烈建议使用国内源，官方源请在注释中查看。 执行下面的命令添加 dnf 软件源： $ sudo dnf config-manager \\ --add-repo \\ https://mirrors.aliyun.com/docker-ce/linux/fedora/docker-ce.repo $ sudo sed -i 's/download.docker.com/mirrors.aliyun.com\\/docker-ce/g' /etc/yum.repos.d/docker-ce.repo # 官方源 # $ sudo dnf config-manager \\ # --add-repo \\ # https://download.docker.com/linux/fedora/docker-ce.repo 如果需要测试版本的 Docker 请使用以下命令： $ sudo dnf config-manager --set-enabled docker-ce-test 你也可以禁用测试版本的 Docker $ sudo dnf config-manager --set-disabled docker-ce-test 安装 Docker 更新 dnf 软件源缓存，并安装 docker-ce。 $ sudo dnf update $ sudo dnf install docker-ce docker-ce-cli containerd.io 你也可以使用以下命令安装指定版本的 Docker $ dnf list docker-ce --showduplicates | sort -r docker-ce.x86_64 18.06.1.ce-3.fc28 docker-ce-stable $ sudo dnf -y install docker-ce-18.06.1.ce 使用脚本自动安装 在测试或开发环境中 Docker 官方为了简化安装流程，提供了一套便捷的安装脚本，Debian 系统上可以使用这套脚本安装，另外可以通过 --mirror 选项使用国内源进行安装： 若你想安装测试版的 Docker, 请从 test.docker.com 获取脚本 # $ curl -fsSL test.docker.com -o get-docker.sh $ curl -fsSL get.docker.com -o get-docker.sh $ sudo sh get-docker.sh --mirror Aliyun # $ sudo sh get-docker.sh --mirror AzureChinaCloud 执行这个命令后，脚本就会自动的将一切准备工作做好，并且把 Docker 最新稳定(stable)版本安装在系统中。 启动 Docker $ sudo systemctl enable docker $ sudo systemctl start docker 建立 docker 用户组 默认情况下，docker 命令会使用 Unix socket 与 Docker 引擎通讯。而只有 root 用户和 docker 组的用户才可以访问 Docker 引擎的 Unix socket。出于安全考虑，一般 Linux 系统上不会直接使用 root 用户。因此，更好地做法是将需要使用 docker 的用户加入 docker 用户组。 建立 docker 组： $ sudo groupadd docker 将当前用户加入 docker 组： $ sudo usermod -aG docker $USER 退出当前终端并重新登录，进行如下测试。 测试 Docker 是否安装正确 $ docker run --rm hello-world Unable to find image 'hello-world:latest' locally latest: Pulling from library/hello-world b8dfde127a29: Pull complete Digest: sha256:308866a43596e83578c7dfa15e27a73011bdd402185a84c5cd7f32a88b501a24 Status: Downloaded newer image for hello-world:latest Hello from Docker! This message shows that your installation appears to be working correctly. To generate this message, Docker took the following steps: 1. The Docker client contacted the Docker daemon. 2. The Docker daemon pulled the \"hello-world\" image from the Docker Hub. (amd64) 3. The Docker daemon created a new container from that image which runs the executable that produces the output you are currently reading. 4. The Docker daemon streamed that output to the Docker client, which sent it to your terminal. To try something more ambitious, you can run an Ubuntu container with: $ docker run -it ubuntu bash Share images, automate workflows, and more with a free Docker ID: https://hub.docker.com/ For more examples and ideas, visit: https://docs.docker.com/get-started/ 若能正常输出以上信息，则说明安装成功。 镜像加速 如果在使用过程中发现拉取 Docker 镜像十分缓慢，可以配置 Docker 国内镜像加速。 参考文档 Docker 官方 Fedora 安装文档。 Copyright © Zhenhai Gao 2021 all right reserved发布时间： 2024-06-10 23:03:15 "},"docker/docker-install/centos.html":{"url":"docker/docker-install/centos.html","title":"CentOS","keywords":"","body":"CentOS 安装 Docker准备工作系统要求卸载旧版本使用 yum 安装安装 DockerCentOS8 额外设置使用脚本自动安装启动 Docker建立 docker 用户组测试 Docker 是否安装正确镜像加速添加内核参数参考文档CentOS 安装 Docker 警告：切勿在没有配置 Docker YUM 源的情况下直接使用 yum 命令安装 Docker. 准备工作 系统要求 Docker 支持 64 位版本 CentOS 7/8，并且要求内核版本不低于 3.10。 CentOS 7 满足最低内核的要求，但由于内核版本比较低，部分功能（如 overlay2 存储层驱动）无法使用，并且部分功能可能不太稳定。 卸载旧版本 旧版本的 Docker 称为 docker 或者 docker-engine，使用以下命令卸载旧版本： $ sudo yum remove docker \\ docker-client \\ docker-client-latest \\ docker-common \\ docker-latest \\ docker-latest-logrotate \\ docker-logrotate \\ docker-selinux \\ docker-engine-selinux \\ docker-engine 使用 yum 安装 执行以下命令安装依赖包： $ sudo yum install -y yum-utils 鉴于国内网络问题，强烈建议使用国内源，官方源请在注释中查看。 执行下面的命令添加 yum 软件源： $ sudo yum-config-manager \\ --add-repo \\ https://mirrors.aliyun.com/docker-ce/linux/centos/docker-ce.repo $ sudo sed -i 's/download.docker.com/mirrors.aliyun.com\\/docker-ce/g' /etc/yum.repos.d/docker-ce.repo # 官方源 # $ sudo yum-config-manager \\ # --add-repo \\ # https://download.docker.com/linux/centos/docker-ce.repo 如果需要测试版本的 Docker 请执行以下命令： $ sudo yum-config-manager --enable docker-ce-test 安装 Docker 更新 yum 软件源缓存，并安装 docker-ce。 $ sudo yum install docker-ce docker-ce-cli containerd.io CentOS8 额外设置 由于 CentOS8 防火墙使用了 nftables，但 Docker 尚未支持 nftables， 我们可以使用如下设置使用 iptables： 更改 /etc/firewalld/firewalld.conf # FirewallBackend=nftables FirewallBackend=iptables 或者执行如下命令： $ firewall-cmd --permanent --zone=trusted --add-interface=docker0 $ firewall-cmd --reload 使用脚本自动安装 在测试或开发环境中 Docker 官方为了简化安装流程，提供了一套便捷的安装脚本，CentOS 系统上可以使用这套脚本安装，另外可以通过 --mirror 选项使用国内源进行安装： 若你想安装测试版的 Docker, 请从 test.docker.com 获取脚本 # $ curl -fsSL test.docker.com -o get-docker.sh $ curl -fsSL get.docker.com -o get-docker.sh $ sudo sh get-docker.sh --mirror Aliyun # $ sudo sh get-docker.sh --mirror AzureChinaCloud 执行这个命令后，脚本就会自动的将一切准备工作做好，并且把 Docker 的稳定(stable)版本安装在系统中。 启动 Docker $ sudo systemctl enable docker $ sudo systemctl start docker 建立 docker 用户组 默认情况下，docker 命令会使用 Unix socket 与 Docker 引擎通讯。而只有 root 用户和 docker 组的用户才可以访问 Docker 引擎的 Unix socket。出于安全考虑，一般 Linux 系统上不会直接使用 root 用户。因此，更好地做法是将需要使用 docker 的用户加入 docker 用户组。 建立 docker 组： $ sudo groupadd docker 将当前用户加入 docker 组： $ sudo usermod -aG docker $USER 退出当前终端并重新登录，进行如下测试。 测试 Docker 是否安装正确 $ docker run --rm hello-world Unable to find image 'hello-world:latest' locally latest: Pulling from library/hello-world b8dfde127a29: Pull complete Digest: sha256:308866a43596e83578c7dfa15e27a73011bdd402185a84c5cd7f32a88b501a24 Status: Downloaded newer image for hello-world:latest Hello from Docker! This message shows that your installation appears to be working correctly. To generate this message, Docker took the following steps: 1. The Docker client contacted the Docker daemon. 2. The Docker daemon pulled the \"hello-world\" image from the Docker Hub. (amd64) 3. The Docker daemon created a new container from that image which runs the executable that produces the output you are currently reading. 4. The Docker daemon streamed that output to the Docker client, which sent it to your terminal. To try something more ambitious, you can run an Ubuntu container with: $ docker run -it ubuntu bash Share images, automate workflows, and more with a free Docker ID: https://hub.docker.com/ For more examples and ideas, visit: https://docs.docker.com/get-started/ 若能正常输出以上信息，则说明安装成功。 镜像加速 如果在使用过程中发现拉取 Docker 镜像十分缓慢，可以配置 Docker 国内镜像加速。 添加内核参数 如果在 CentOS 使用 Docker 看到下面的这些警告信息： WARNING: bridge-nf-call-iptables is disabled WARNING: bridge-nf-call-ip6tables is disabled 请添加内核配置参数以启用这些功能。 $ sudo tee -a /etc/sysctl.conf 然后重新加载 sysctl.conf 即可 $ sudo sysctl -p 参考文档 Docker 官方 CentOS 安装文档。 https://firewalld.org/2018/07/nftables-backend https://github.com/moby/libnetwork/issues/2496 Copyright © Zhenhai Gao 2021 all right reserved发布时间： 2024-06-10 23:03:15 "},"docker/docker-install/raspberry-pi.html":{"url":"docker/docker-install/raspberry-pi.html","title":"Raspberry Pi","keywords":"","body":"树莓派卡片电脑安装 Docker系统要求使用 APT 安装安装 Docker使用脚本自动安装启动 Docker建立 docker 用户组测试 Docker 是否安装正确镜像加速树莓派卡片电脑安装 Docker 警告：切勿在没有配置 Docker APT 源的情况下直接使用 apt 命令安装 Docker. 系统要求 Docker 不仅支持 x86_64 架构的计算机，同时也支持 ARM 架构的计算机，本小节内容以树莓派单片电脑为例讲解 ARM 架构安装 Docker。 Docker 支持以下版本的 Raspberry Pi OS 操作系统： Raspberry Pi OS Buster 注： Raspberry Pi OS 由树莓派的开发与维护机构 树莓派基金会 官方支持，并推荐用作树莓派的首选系统，其基于 Debian。 使用 APT 安装 由于 apt 源使用 HTTPS 以确保软件下载过程中不被篡改。因此，我们首先需要添加使用 HTTPS 传输的软件包以及 CA 证书。 $ sudo apt-get update $ sudo apt-get install \\ apt-transport-https \\ ca-certificates \\ curl \\ gnupg2 \\ lsb-release \\ software-properties-common 鉴于国内网络问题，强烈建议使用国内源，官方源请在注释中查看。 为了确认所下载软件包的合法性，需要添加软件源的 GPG 密钥。 $ curl -fsSL https://mirrors.aliyun.com/docker-ce/linux/raspbian/gpg | sudo apt-key add - # 官方源 # $ curl -fsSL https://download.docker.com/linux/raspbian/gpg | sudo apt-key add - 然后，我们需要向 sources.list 中添加 Docker 软件源： $ sudo add-apt-repository \\ \"deb [arch=armhf] https://mirrors.aliyun.com/docker-ce/linux/raspbian \\ $(lsb_release -cs) \\ stable\" # 官方源 # $ sudo add-apt-repository \\ # \"deb [arch=armhf] https://download.docker.com/linux/raspbian \\ # $(lsb_release -cs) \\ # stable\" 以上命令会添加稳定版本的 Docker APT 源，如果需要测试版本的 Docker 请将 stable 改为 test。 安装 Docker 更新 apt 软件包缓存，并安装 docker-ce。 $ sudo apt-get update $ sudo apt-get install docker-ce 使用脚本自动安装 在测试或开发环境中 Docker 官方为了简化安装流程，提供了一套便捷的安装脚本，Raspberry Pi OS 系统上可以使用这套脚本安装，另外可以通过 --mirror 选项使用国内源进行安装： 若你想安装测试版的 Docker, 请从 test.docker.com 获取脚本 # $ curl -fsSL test.docker.com -o get-docker.sh $ curl -fsSL get.docker.com -o get-docker.sh $ sudo sh get-docker.sh --mirror Aliyun # $ sudo sh get-docker.sh --mirror AzureChinaCloud 执行这个命令后，脚本就会自动的将一切准备工作做好，并且把 Docker 的稳定(stable)版本安装在系统中。 启动 Docker $ sudo systemctl enable docker $ sudo systemctl start docker 建立 docker 用户组 默认情况下，docker 命令会使用 Unix socket 与 Docker 引擎通讯。而只有 root 用户和 docker 组的用户才可以访问 Docker 引擎的 Unix socket。出于安全考虑，一般 Linux 系统上不会直接使用 root 用户。因此，更好地做法是将需要使用 docker 的用户加入 docker 用户组。 建立 docker 组： $ sudo groupadd docker 将当前用户加入 docker 组： $ sudo usermod -aG docker $USER 退出当前终端并重新登录，进行如下测试。 测试 Docker 是否安装正确 $ docker run --rm hello-world Unable to find image 'hello-world:latest' locally latest: Pulling from library/hello-world 4ee5c797bcd7: Pull complete Digest: sha256:308866a43596e83578c7dfa15e27a73011bdd402185a84c5cd7f32a88b501a24 Status: Downloaded newer image for hello-world:latest Hello from Docker! This message shows that your installation appears to be working correctly. To generate this message, Docker took the following steps: 1. The Docker client contacted the Docker daemon. 2. The Docker daemon pulled the \"hello-world\" image from the Docker Hub. (arm32v7) 3. The Docker daemon created a new container from that image which runs the executable that produces the output you are currently reading. 4. The Docker daemon streamed that output to the Docker client, which sent it to your terminal. To try something more ambitious, you can run an Ubuntu container with: $ docker run -it ubuntu bash Share images, automate workflows, and more with a free Docker ID: https://hub.docker.com/ For more examples and ideas, visit: https://docs.docker.com/get-started/ 若能正常输出以上信息，则说明安装成功。 注意： ARM 平台不能使用 x86 镜像，查看 Raspberry Pi OS 可使用镜像请访问 arm32v7 或者 arm64v8。 镜像加速 如果在使用过程中发现拉取 Docker 镜像十分缓慢，可以配置 Docker 国内镜像加速。 Copyright © Zhenhai Gao 2021 all right reserved发布时间： 2024-06-10 23:03:15 "},"docker/docker-install/offline.html":{"url":"docker/docker-install/offline.html","title":"Linux 离线安装","keywords":"","body":"离线部署DockerCentos7 离线安装DockerYUM本地文件安装（推荐）YUM 本地源服务器搭建安装Docker离线部署Docker [TOC] 生产环境中一般都是没有公网资源的，本文介绍如何在生产服务器上离线部署Docker 括号内的字母表示该操作需要在哪些服务器上执行 Centos7 离线安装Docker YUM本地文件安装（推荐） 推荐这种方式，是因为在生产环境种一般会选定某个指定的文档软件版本使用。 查询可用的软件版本(A) #下载清华的镜像源文件 wget -O /etc/yum.repos.d/docker-ce.repo https://download.docker.com/linux/centos/docker-ce.repo sudo sed -i 's+download.docker.com+mirrors.tuna.tsinghua.edu.cn/docker-ce+' /etc/yum.repos.d/docker-ce.repo yum update sudo yum list docker-ce --showduplicates|sort -r Loading mirror speeds from cached hostfile Loaded plugins: fastestmirror docker-ce.x86_64 3:19.03.8-3.el7 docker-ce-stable docker-ce.x86_64 3:19.03.7-3.el7 docker-ce-stable docker-ce.x86_64 3:19.03.6-3.el7 docker-ce-stable docker-ce.x86_64 3:19.03.5-3.el7 docker-ce-stable docker-ce.x86_64 3:19.03.4-3.el7 docker-ce-stable docker-ce.x86_64 3:19.03.3-3.el7 docker-ce-stable docker-ce.x86_64 3:19.03.2-3.el7 docker-ce-stable docker-ce.x86_64 3:19.03.1-3.el7 docker-ce-stable .... 下载到指定文件夹(A) sudo yum install --downloadonly --downloaddir=/tmp/docker-19.03 docker-ce-19.03.8-3.el7 docker-ce-cli-19.03.8-3.el7 Dependencies Resolved ==================================================================================================================================================================================== Package Arch Version Repository Size ==================================================================================================================================================================================== Installing: docker-ce x86_64 3:19.03.8-3.el7 docker 25 M Installing for dependencies: container-selinux noarch 2:2.107-3.el7 extras 39 k containerd.io x86_64 1.2.13-3.1.el7 docker 23 M docker-ce-cli x86_64 1:19.03.8-3.el7 docker 40 M Transaction Summary ==================================================================================================================================================================================== Install 1 Package (+3 Dependent packages) Total download size: 87 M Installed size: 363 M Background downloading packages, then exiting: (1/4): container-selinux-2.107-3.el7.noarch.rpm | 39 kB 00:00:00 (2/4): containerd.io-1.2.13-3.1.el7.x86_64.rpm | 23 MB 00:00:00 (3/4): docker-ce-19.03.8-3.el7.x86_64.rpm | 25 MB 00:00:00 (4/4): docker-ce-cli-19.03.8-3.el7.x86_64.rpm | 40 MB 00:00:00 ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------ Total 118 MB/s | 87 MB 00:00:00 exiting because \"Download Only\" specified 复制到目标服务器之后进入文件夹安装(C-N) yum install *.rpm 锁定软件版本(C-N) 下载锁定版本软件 可参考下文的网络源搭建 sudo yum install yum-plugin-versionlock 锁定软件版本 sudo yum versionlock add docker 查看锁定列表 sudo yum versionlock list Loaded plugins: fastestmirror, versionlock 3:docker-ce-18.09.9-3.el7.* versionlock list done 锁定后无法再更新 sudo yum install docker-ce Loaded plugins: fastestmirror, versionlock Loading mirror speeds from cached hostfile Excluding 1 update due to versionlock (use \"yum versionlock status\" to show it) Package 3:docker-ce-18.09.9-3.el7.x86_64 already installed and latest version Nothing to do 解锁指定软件 sudo yum versionlock delete docker-ce Loaded plugins: fastestmirror, versionlock Deleting versionlock for: 3:docker-ce-18.09.9-3.el7.* versionlock deleted: 1 解锁所有软件 sudo yum versionlock delete all YUM 本地源服务器搭建安装Docker 挂载 ISO 镜像搭建本地 File 源（AB） # 删除其他网络源 rm -f /etc/yum.repo.d/* # 挂载光盘或者iso镜像 mount /dev/cdrom /mnt # 添加本地源 cat >/etc/yum.repos.d/local_files.repo # 测试刚才的本地源,安装createrepo软件 yum clean all yum install createrepo -y 根据本地文件搭建BASE网络源（B） # 安装apache 服务器 yum install httpd -y # 挂载光盘 mount /dev/cdrom /mnt # 新建centos目录 mkdir /var/www/html/base # 复制光盘内的文件到刚才新建的目录 cp -R /mnt/Packages/* /var/www/html/base/ createrepo /var/www/html/centos/ systemctl enable httpd systemctl start httpd 下载Docker-CE 镜像仓库（A） 在有网络的服务器上下载Docker-ce镜像 # 下载清华的镜像源文件 wget -O /etc/yum.repos.d/docker-ce.repo https://download.docker.com/linux/centos/docker-ce.repo sudo sed -i 's+download.docker.com+mirrors.tuna.tsinghua.edu.cn/docker-ce+' /etc/yum.repos.d/docker-ce.repo # 新建 docker-ce目录 mkdir /tmp/docker-ce/ # 把镜像源同步到镜像文件中 reposync -r docker-ce-stable -p /tmp/docker-ce/ 创建仓库索引（B） 把下载的 docker-ce 文件夹复制到离线的服务器 # 把docker-ce 文件夹复制到/var/www/html/docker-ce # 重建索引 createrepo /var/www/html/docker-ce/ YUM 客户端设置（C...N） rm -f /etc/yum.repo.d/* cat >/etc/yum.repos.d/local_files.repo Docker 安装（C...N） sudo yum makecache fast sudo yum install docker-ce docker-ce-cli containerd.io sudo systemctl enable docker Copyright © Zhenhai Gao 2021 all right reserved发布时间： 2024-06-10 23:03:15 "},"docker/docker-install/mac.html":{"url":"docker/docker-install/mac.html","title":"macOS","keywords":"","body":"macOS 安装 Docker系统要求安装使用 Homebrew 安装手动下载安装运行镜像加速参考链接macOS 安装 Docker 系统要求 Docker Desktop for Mac 要求系统最低为 macOS Mojave 10.14。 安装 使用 Homebrew 安装 Homebrew 的 Cask 已经支持 Docker Desktop for Mac，因此可以很方便的使用 Homebrew Cask 来进行安装： $ brew install --cask docker 手动下载安装 如果需要手动下载，请点击以下 链接 下载 Docker Desktop for Mac。 如果你的电脑搭载的是 M1 芯片（arm64 架构），请点击以下 链接 下载 Docker Desktop for Mac。你可以在 官方文档 查阅已知的问题。 如同 macOS 其它软件一样，安装也非常简单，双击下载的 .dmg 文件，然后将那只叫 Moby 的鲸鱼图标拖拽到 Application 文件夹即可（其间需要输入用户密码）。 运行 从应用中找到 Docker 图标并点击运行。 运行之后，会在右上角菜单栏看到多了一个鲸鱼图标，这个图标表明了 Docker 的运行状态。 每次点击鲸鱼图标会弹出操作菜单。 之后，你可以在终端通过命令检查安装后的 Docker 版本。 $ docker --version Docker version 20.10.0, build 7287ab3 如果 docker version、docker info 都正常的话，可以尝试运行一个 Nginx 服务器： $ docker run -d -p 80:80 --name webserver nginx 服务运行后，可以访问 http://localhost，如果看到了 \"Welcome to nginx!\"，就说明 Docker Desktop for Mac 安装成功了。 要停止 Nginx 服务器并删除执行下面的命令： $ docker stop webserver $ docker rm webserver 镜像加速 如果在使用过程中发现拉取 Docker 镜像十分缓慢，可以配置 Docker 国内镜像加速。 参考链接 官方文档 Copyright © Zhenhai Gao 2021 all right reserved发布时间： 2024-06-10 23:03:15 "},"docker/docker-install/windows.html":{"url":"docker/docker-install/windows.html","title":"Windows 10","keywords":"","body":"Windows 10 安装 Docker系统要求安装在 WSL2 运行 Docker运行镜像加速参考链接Windows 10 安装 Docker 系统要求 Docker Desktop for Windows 支持 64 位版本的 Windows 10 Pro，且必须开启 Hyper-V（若版本为 v1903 及以上则无需开启 Hyper-V），或者 64 位版本的 Windows 10 Home v1903 及以上版本。 安装 手动下载安装 点击以下 链接 下载 Docker Desktop for Windows。 下载好之后双击 Docker Desktop Installer.exe 开始安装。 使用 winget 安装 $ winget install Docker.DockerDesktop 在 WSL2 运行 Docker 若你的 Windows 版本为 Windows 10 专业版或家庭版 v1903 及以上版本可以使用 WSL2 运行 Docker，具体请查看 Docker Desktop WSL 2 backend。 运行 在 Windows 搜索栏输入 Docker 点击 Docker Desktop 开始运行。 Docker 启动之后会在 Windows 任务栏出现鲸鱼图标。 等待片刻，当鲸鱼图标静止时，说明 Docker 启动成功，之后你可以打开 PowerShell 使用 Docker。 推荐使用 Windows Terminal 在终端使用 Docker。 镜像加速 如果在使用过程中发现拉取 Docker 镜像十分缓慢，可以配置 Docker 国内镜像加速。 参考链接 官方文档 WSL 2 Support is coming to Windows 10 Versions 1903 and 1909 Copyright © Zhenhai Gao 2021 all right reserved发布时间： 2024-06-10 23:03:15 "},"docker/docker-install/mirror.html":{"url":"docker/docker-install/mirror.html","title":"镜像加速器","keywords":"","body":"镜像加速器Ubuntu 16.04+、Debian 8+、CentOS 7+Windows 10macOS检查加速器是否生效k8s.gcr.io 镜像不再提供服务的镜像云服务商镜像加速器 国内从 Docker Hub 拉取镜像有时会遇到困难，此时可以配置镜像加速器。国内很多云服务商都提供了国内加速器服务，例如： 阿里云加速器(点击管理控制台 -> 登录账号(淘宝账号) -> 右侧镜像工具 -> 镜像加速器 -> 复制加速器地址) 网易云加速器 https://hub-mirror.c.163.com 百度云加速器 https://mirror.baidubce.com 由于镜像服务可能出现宕机，建议同时配置多个镜像。各个镜像站测试结果请到 docker-practice/docker-registry-cn-mirror-test 查看。 国内各大云服务商（腾讯云、阿里云、百度云）均提供了 Docker 镜像加速服务，建议根据运行 Docker 的云平台选择对应的镜像加速服务，具体请参考本页最后一小节。 本节我们以 网易云 镜像服务 https://hub-mirror.c.163.com 为例进行介绍。 Ubuntu 16.04+、Debian 8+、CentOS 7+ 目前主流 Linux 发行版均已使用 systemd 进行服务管理，这里介绍如何在使用 systemd 的 Linux 发行版中配置镜像加速器。 请首先执行以下命令，查看是否在 docker.service 文件中配置过镜像地址。 $ systemctl cat docker | grep '\\-\\-registry\\-mirror' 如果该命令有输出，那么请执行 $ systemctl cat docker 查看 ExecStart= 出现的位置，修改对应的文件内容去掉 --registry-mirror 参数及其值，并按接下来的步骤进行配置。 如果以上命令没有任何输出，那么就可以在 /etc/docker/daemon.json 中写入如下内容（如果文件不存在请新建该文件）： { \"registry-mirrors\": [ \"https://hub-mirror.c.163.com\", \"https://mirror.baidubce.com\" ] } 注意，一定要保证该文件符合 json 规范，否则 Docker 将不能启动。 之后重新启动服务。 $ sudo systemctl daemon-reload $ sudo systemctl restart docker Windows 10 对于使用 Windows 10 的用户，在任务栏托盘 Docker 图标内右键菜单选择 Settings，打开配置窗口后在左侧导航菜单选择 Docker Engine，在右侧像下边一样编辑 json 文件，之后点击 Apply & Restart 保存后 Docker 就会重启并应用配置的镜像地址了。 { \"registry-mirrors\": [ \"https://hub-mirror.c.163.com\", \"https://mirror.baidubce.com\" ] } macOS 对于使用 macOS 的用户，在任务栏点击 Docker Desktop 应用图标 -> Perferences，在左侧导航菜单选择 Docker Engine，在右侧像下边一样编辑 json 文件。修改完成之后，点击 Apply & Restart 按钮，Docker 就会重启并应用配置的镜像地址了。 { \"registry-mirrors\": [ \"https://hub-mirror.c.163.com\", \"https://mirror.baidubce.com\" ] } 检查加速器是否生效 执行 $ docker info，如果从结果中看到了如下内容，说明配置成功。 Registry Mirrors: https://hub-mirror.c.163.com/ k8s.gcr.io 镜像 可以登录 阿里云 容器镜像服务 镜像中心 -> 镜像搜索 查找。 例如 k8s.gcr.io/coredns:1.6.7 镜像可以用 registry.cn-hangzhou.aliyuncs.com/google_containers/coredns:1.6.7 代替。 一般情况下有如下对应关系： # $ docker pull k8s.gcr.io/xxx $ docker pull registry.cn-hangzhou.aliyuncs.com/google_containers/xxx 不再提供服务的镜像 某些镜像不再提供服务，添加无用的镜像加速器，会拖慢镜像拉取速度，你可以从镜像配置列表中删除它们。 https://dockerhub.azk8s.cn 已转为私有 https://reg-mirror.qiniu.com https://registry.docker-cn.com 建议 watch（页面右上角） 镜像测试 这个 GitHub 仓库，我们会在此更新各个镜像地址的状态。 云服务商 某些云服务商提供了 仅供内部 访问的镜像服务，当您的 Docker 运行在云平台时可以选择它们。 Azure 中国镜像 https://dockerhub.azk8s.cn 腾讯云 https://mirror.ccs.tencentyun.com Copyright © Zhenhai Gao 2021 all right reserved发布时间： 2024-06-10 23:03:15 "},"docker/docker-install/experimental.html":{"url":"docker/docker-install/experimental.html","title":"开启实验特性","keywords":"","body":"开启实验特性Docker CLI 的实验特性开启 dockerd 的实验特性开启实验特性 一些 docker 命令或功能仅当 实验特性 开启时才能使用，请按照以下方法进行设置。 Docker CLI 的实验特性 从 v20.10 版本开始，Docker CLI 所有实验特性的命令均默认开启，无需再进行配置或设置系统环境变量。 开启 dockerd 的实验特性 编辑 /etc/docker/daemon.json，新增如下条目 { \"experimental\": true } Copyright © Zhenhai Gao 2021 all right reserved发布时间： 2024-06-10 23:03:15 "},"docker/docker-image/":{"url":"docker/docker-image/","title":"操作镜像","keywords":"","body":"使用 Docker 镜像使用 Docker 镜像 在之前的介绍中，我们知道镜像是 Docker 的三大组件之一。 Docker 运行容器前需要本地存在对应的镜像，如果本地不存在该镜像，Docker 会从镜像仓库下载该镜像。 本章将介绍更多关于镜像的内容，包括： 从仓库获取镜像； 管理本地主机上的镜像； 介绍镜像实现的基本原理。 Copyright © Zhenhai Gao 2021 all right reserved发布时间： 2024-06-10 23:03:15 "},"docker/docker-image/pull.html":{"url":"docker/docker-image/pull.html","title":"获取镜像","keywords":"","body":"获取镜像运行获取镜像 之前提到过，Docker Hub 上有大量的高质量的镜像可以用，这里我们就说一下怎么获取这些镜像。 从 Docker 镜像仓库获取镜像的命令是 docker pull。其命令格式为： $ docker pull [选项] [Docker Registry 地址[:端口号]/]仓库名[:标签] 具体的选项可以通过 docker pull --help 命令看到，这里我们说一下镜像名称的格式。 Docker 镜像仓库地址：地址的格式一般是 [:端口号]。默认地址是 Docker Hub(docker.io)。 仓库名：如之前所说，这里的仓库名是两段式名称，即 /。对于 Docker Hub，如果不给出用户名，则默认为 library，也就是官方镜像。 比如： $ docker pull ubuntu:18.04 18.04: Pulling from library/ubuntu 92dc2a97ff99: Pull complete be13a9d27eb8: Pull complete c8299583700a: Pull complete Digest: sha256:4bc3ae6596938cb0d9e5ac51a1152ec9dcac2a1c50829c74abd9c4361e321b26 Status: Downloaded newer image for ubuntu:18.04 docker.io/library/ubuntu:18.04 上面的命令中没有给出 Docker 镜像仓库地址，因此将会从 Docker Hub （docker.io）获取镜像。而镜像名称是 ubuntu:18.04，因此将会获取官方镜像 library/ubuntu 仓库中标签为 18.04 的镜像。docker pull 命令的输出结果最后一行给出了镜像的完整名称，即： docker.io/library/ubuntu:18.04。 从下载过程中可以看到我们之前提及的分层存储的概念，镜像是由多层存储所构成。下载也是一层层的去下载，并非单一文件。下载过程中给出了每一层的 ID 的前 12 位。并且下载结束后，给出该镜像完整的 sha256 的摘要，以确保下载一致性。 在使用上面命令的时候，你可能会发现，你所看到的层 ID 以及 sha256 的摘要和这里的不一样。这是因为官方镜像是一直在维护的，有任何新的 bug，或者版本更新，都会进行修复再以原来的标签发布，这样可以确保任何使用这个标签的用户可以获得更安全、更稳定的镜像。 如果从 Docker Hub 下载镜像非常缓慢，可以参照 镜像加速器 一节配置加速器。 运行 有了镜像后，我们就能够以这个镜像为基础启动并运行一个容器。以上面的 ubuntu:18.04 为例，如果我们打算启动里面的 bash 并且进行交互式操作的话，可以执行下面的命令。 $ docker run -it --rm ubuntu:18.04 bash root@e7009c6ce357:/# cat /etc/os-release NAME=\"Ubuntu\" VERSION=\"18.04.1 LTS (Bionic Beaver)\" ID=ubuntu ID_LIKE=debian PRETTY_NAME=\"Ubuntu 18.04.1 LTS\" VERSION_ID=\"18.04\" HOME_URL=\"https://www.ubuntu.com/\" SUPPORT_URL=\"https://help.ubuntu.com/\" BUG_REPORT_URL=\"https://bugs.launchpad.net/ubuntu/\" PRIVACY_POLICY_URL=\"https://www.ubuntu.com/legal/terms-and-policies/privacy-policy\" VERSION_CODENAME=bionic UBUNTU_CODENAME=bionic docker run 就是运行容器的命令，具体格式我们会在 容器 一节进行详细讲解，我们这里简要的说明一下上面用到的参数。 -it：这是两个参数，一个是 -i：交互式操作，一个是 -t 终端。我们这里打算进入 bash 执行一些命令并查看返回结果，因此我们需要交互式终端。 --rm：这个参数是说容器退出后随之将其删除。默认情况下，为了排障需求，退出的容器并不会立即删除，除非手动 docker rm。我们这里只是随便执行个命令，看看结果，不需要排障和保留结果，因此使用 --rm 可以避免浪费空间。 ubuntu:18.04：这是指用 ubuntu:18.04 镜像为基础来启动容器。 bash：放在镜像名后的是 命令，这里我们希望有个交互式 Shell，因此用的是 bash。 进入容器后，我们可以在 Shell 下操作，执行任何所需的命令。这里，我们执行了 cat /etc/os-release，这是 Linux 常用的查看当前系统版本的命令，从返回的结果可以看到容器内是 Ubuntu 18.04.1 LTS 系统。 最后我们通过 exit 退出了这个容器。 Copyright © Zhenhai Gao 2021 all right reserved发布时间： 2024-06-10 23:03:15 "},"docker/docker-image/list.html":{"url":"docker/docker-image/list.html","title":"列出镜像","keywords":"","body":"列出镜像镜像体积虚悬镜像中间层镜像列出部分镜像以特定格式显示列出镜像 要想列出已经下载下来的镜像，可以使用 docker image ls 命令。 $ docker image ls REPOSITORY TAG IMAGE ID CREATED SIZE redis latest 5f515359c7f8 5 days ago 183 MB nginx latest 05a60462f8ba 5 days ago 181 MB mongo 3.2 fe9198c04d62 5 days ago 342 MB 00285df0df87 5 days ago 342 MB ubuntu 18.04 329ed837d508 3 days ago 63.3MB ubuntu bionic 329ed837d508 3 days ago 63.3MB 列表包含了 仓库名、标签、镜像 ID、创建时间 以及 所占用的空间。 其中仓库名、标签在之前的基础概念章节已经介绍过了。镜像 ID 则是镜像的唯一标识，一个镜像可以对应多个 标签。因此，在上面的例子中，我们可以看到 ubuntu:18.04 和 ubuntu:bionic 拥有相同的 ID，因为它们对应的是同一个镜像。 镜像体积 如果仔细观察，会注意到，这里标识的所占用空间和在 Docker Hub 上看到的镜像大小不同。比如，ubuntu:18.04 镜像大小，在这里是 63.3MB，但是在 Docker Hub 显示的却是 25.47 MB。这是因为 Docker Hub 中显示的体积是压缩后的体积。在镜像下载和上传过程中镜像是保持着压缩状态的，因此 Docker Hub 所显示的大小是网络传输中更关心的流量大小。而 docker image ls 显示的是镜像下载到本地后，展开的大小，准确说，是展开后的各层所占空间的总和，因为镜像到本地后，查看空间的时候，更关心的是本地磁盘空间占用的大小。 另外一个需要注意的问题是，docker image ls 列表中的镜像体积总和并非是所有镜像实际硬盘消耗。由于 Docker 镜像是多层存储结构，并且可以继承、复用，因此不同镜像可能会因为使用相同的基础镜像，从而拥有共同的层。由于 Docker 使用 Union FS，相同的层只需要保存一份即可，因此实际镜像硬盘占用空间很可能要比这个列表镜像大小的总和要小的多。 你可以通过 docker system df 命令来便捷的查看镜像、容器、数据卷所占用的空间。 $ docker system df TYPE TOTAL ACTIVE SIZE RECLAIMABLE Images 24 0 1.992GB 1.992GB (100%) Containers 1 0 62.82MB 62.82MB (100%) Local Volumes 9 0 652.2MB 652.2MB (100%) Build Cache 0B 0B 虚悬镜像 上面的镜像列表中，还可以看到一个特殊的镜像，这个镜像既没有仓库名，也没有标签，均为 。： 00285df0df87 5 days ago 342 MB 这个镜像原本是有镜像名和标签的，原来为 mongo:3.2，随着官方镜像维护，发布了新版本后，重新 docker pull mongo:3.2 时，mongo:3.2 这个镜像名被转移到了新下载的镜像身上，而旧的镜像上的这个名称则被取消，从而成为了 。除了 docker pull 可能导致这种情况，docker build 也同样可以导致这种现象。由于新旧镜像同名，旧镜像名称被取消，从而出现仓库名、标签均为 的镜像。这类无标签镜像也被称为 虚悬镜像(dangling image) ，可以用下面的命令专门显示这类镜像： $ docker image ls -f dangling=true REPOSITORY TAG IMAGE ID CREATED SIZE 00285df0df87 5 days ago 342 MB 一般来说，虚悬镜像已经失去了存在的价值，是可以随意删除的，可以用下面的命令删除。 $ docker image prune 中间层镜像 为了加速镜像构建、重复利用资源，Docker 会利用 中间层镜像。所以在使用一段时间后，可能会看到一些依赖的中间层镜像。默认的 docker image ls 列表中只会显示顶层镜像，如果希望显示包括中间层镜像在内的所有镜像的话，需要加 -a 参数。 $ docker image ls -a 这样会看到很多无标签的镜像，与之前的虚悬镜像不同，这些无标签的镜像很多都是中间层镜像，是其它镜像所依赖的镜像。这些无标签镜像不应该删除，否则会导致上层镜像因为依赖丢失而出错。实际上，这些镜像也没必要删除，因为之前说过，相同的层只会存一遍，而这些镜像是别的镜像的依赖，因此并不会因为它们被列出来而多存了一份，无论如何你也会需要它们。只要删除那些依赖它们的镜像后，这些依赖的中间层镜像也会被连带删除。 列出部分镜像 不加任何参数的情况下，docker image ls 会列出所有顶层镜像，但是有时候我们只希望列出部分镜像。docker image ls 有好几个参数可以帮助做到这个事情。 根据仓库名列出镜像 $ docker image ls ubuntu REPOSITORY TAG IMAGE ID CREATED SIZE ubuntu 18.04 329ed837d508 3 days ago 63.3MB ubuntu bionic 329ed837d508 3 days ago 63.3MB 列出特定的某个镜像，也就是说指定仓库名和标签 $ docker image ls ubuntu:18.04 REPOSITORY TAG IMAGE ID CREATED SIZE ubuntu 18.04 329ed837d508 3 days ago 63.3MB 除此以外，docker image ls 还支持强大的过滤器参数 --filter，或者简写 -f。之前我们已经看到了使用过滤器来列出虚悬镜像的用法，它还有更多的用法。比如，我们希望看到在 mongo:3.2 之后建立的镜像，可以用下面的命令： $ docker image ls -f since=mongo:3.2 REPOSITORY TAG IMAGE ID CREATED SIZE redis latest 5f515359c7f8 5 days ago 183 MB nginx latest 05a60462f8ba 5 days ago 181 MB 想查看某个位置之前的镜像也可以，只需要把 since 换成 before 即可。 此外，如果镜像构建时，定义了 LABEL，还可以通过 LABEL 来过滤。 $ docker image ls -f label=com.example.version=0.1 ... 以特定格式显示 默认情况下，docker image ls 会输出一个完整的表格，但是我们并非所有时候都会需要这些内容。比如，刚才删除虚悬镜像的时候，我们需要利用 docker image ls 把所有的虚悬镜像的 ID 列出来，然后才可以交给 docker image rm 命令作为参数来删除指定的这些镜像，这个时候就用到了 -q 参数。 $ docker image ls -q 5f515359c7f8 05a60462f8ba fe9198c04d62 00285df0df87 329ed837d508 329ed837d508 --filter 配合 -q 产生出指定范围的 ID 列表，然后送给另一个 docker 命令作为参数，从而针对这组实体成批的进行某种操作的做法在 Docker 命令行使用过程中非常常见，不仅仅是镜像，将来我们会在各个命令中看到这类搭配以完成很强大的功能。因此每次在文档看到过滤器后，可以多注意一下它们的用法。 另外一些时候，我们可能只是对表格的结构不满意，希望自己组织列；或者不希望有标题，这样方便其它程序解析结果等，这就用到了 Go 的模板语法。 比如，下面的命令会直接列出镜像结果，并且只包含镜像ID和仓库名： $ docker image ls --format \"{{.ID}}: {{.Repository}}\" 5f515359c7f8: redis 05a60462f8ba: nginx fe9198c04d62: mongo 00285df0df87: 329ed837d508: ubuntu 329ed837d508: ubuntu 或者打算以表格等距显示，并且有标题行，和默认一样，不过自己定义列： $ docker image ls --format \"table {{.ID}}\\t{{.Repository}}\\t{{.Tag}}\" IMAGE ID REPOSITORY TAG 5f515359c7f8 redis latest 05a60462f8ba nginx latest fe9198c04d62 mongo 3.2 00285df0df87 329ed837d508 ubuntu 18.04 329ed837d508 ubuntu bionic Copyright © Zhenhai Gao 2021 all right reserved发布时间： 2024-06-10 23:03:15 "},"docker/docker-image/rm.html":{"url":"docker/docker-image/rm.html","title":"删除本地镜像","keywords":"","body":"删除本地镜像用 ID、镜像名、摘要删除镜像Untagged 和 Deleted用 docker image ls 命令来配合删除本地镜像 如果要删除本地的镜像，可以使用 docker image rm 命令，其格式为： $ docker image rm [选项] [ ...] 用 ID、镜像名、摘要删除镜像 其中， 可以是 镜像短 ID、镜像长 ID、镜像名 或者 镜像摘要。 比如我们有这么一些镜像： $ docker image ls REPOSITORY TAG IMAGE ID CREATED SIZE centos latest 0584b3d2cf6d 3 weeks ago 196.5 MB redis alpine 501ad78535f0 3 weeks ago 21.03 MB docker latest cf693ec9b5c7 3 weeks ago 105.1 MB nginx latest e43d811ce2f4 5 weeks ago 181.5 MB 我们可以用镜像的完整 ID，也称为 长 ID，来删除镜像。使用脚本的时候可能会用长 ID，但是人工输入就太累了，所以更多的时候是用 短 ID 来删除镜像。docker image ls 默认列出的就已经是短 ID 了，一般取前3个字符以上，只要足够区分于别的镜像就可以了。 比如这里，如果我们要删除 redis:alpine 镜像，可以执行： $ docker image rm 501 Untagged: redis:alpine Untagged: redis@sha256:f1ed3708f538b537eb9c2a7dd50dc90a706f7debd7e1196c9264edeea521a86d Deleted: sha256:501ad78535f015d88872e13fa87a828425117e3d28075d0c117932b05bf189b7 Deleted: sha256:96167737e29ca8e9d74982ef2a0dda76ed7b430da55e321c071f0dbff8c2899b Deleted: sha256:32770d1dcf835f192cafd6b9263b7b597a1778a403a109e2cc2ee866f74adf23 Deleted: sha256:127227698ad74a5846ff5153475e03439d96d4b1c7f2a449c7a826ef74a2d2fa Deleted: sha256:1333ecc582459bac54e1437335c0816bc17634e131ea0cc48daa27d32c75eab3 Deleted: sha256:4fc455b921edf9c4aea207c51ab39b10b06540c8b4825ba57b3feed1668fa7c7 我们也可以用镜像名，也就是 :，来删除镜像。 $ docker image rm centos Untagged: centos:latest Untagged: centos@sha256:b2f9d1c0ff5f87a4743104d099a3d561002ac500db1b9bfa02a783a46e0d366c Deleted: sha256:0584b3d2cf6d235ee310cf14b54667d889887b838d3f3d3033acd70fc3c48b8a Deleted: sha256:97ca462ad9eeae25941546209454496e1d66749d53dfa2ee32bf1faabd239d38 当然，更精确的是使用 镜像摘要 删除镜像。 $ docker image ls --digests REPOSITORY TAG DIGEST IMAGE ID CREATED SIZE node slim sha256:b4f0e0bdeb578043c1ea6862f0d40cc4afe32a4a582f3be235a3b164422be228 6e0c4c8e3913 3 weeks ago 214 MB $ docker image rm node@sha256:b4f0e0bdeb578043c1ea6862f0d40cc4afe32a4a582f3be235a3b164422be228 Untagged: node@sha256:b4f0e0bdeb578043c1ea6862f0d40cc4afe32a4a582f3be235a3b164422be228 Untagged 和 Deleted 如果观察上面这几个命令的运行输出信息的话，你会注意到删除行为分为两类，一类是 Untagged，另一类是 Deleted。我们之前介绍过，镜像的唯一标识是其 ID 和摘要，而一个镜像可以有多个标签。 因此当我们使用上面命令删除镜像的时候，实际上是在要求删除某个标签的镜像。所以首先需要做的是将满足我们要求的所有镜像标签都取消，这就是我们看到的 Untagged 的信息。因为一个镜像可以对应多个标签，因此当我们删除了所指定的标签后，可能还有别的标签指向了这个镜像，如果是这种情况，那么 Delete 行为就不会发生。所以并非所有的 docker image rm 都会产生删除镜像的行为，有可能仅仅是取消了某个标签而已。 当该镜像所有的标签都被取消了，该镜像很可能会失去了存在的意义，因此会触发删除行为。镜像是多层存储结构，因此在删除的时候也是从上层向基础层方向依次进行判断删除。镜像的多层结构让镜像复用变得非常容易，因此很有可能某个其它镜像正依赖于当前镜像的某一层。这种情况，依旧不会触发删除该层的行为。直到没有任何层依赖当前层时，才会真实的删除当前层。这就是为什么，有时候会奇怪，为什么明明没有别的标签指向这个镜像，但是它还是存在的原因，也是为什么有时候会发现所删除的层数和自己 docker pull 看到的层数不一样的原因。 除了镜像依赖以外，还需要注意的是容器对镜像的依赖。如果有用这个镜像启动的容器存在（即使容器没有运行），那么同样不可以删除这个镜像。之前讲过，容器是以镜像为基础，再加一层容器存储层，组成这样的多层存储结构去运行的。因此该镜像如果被这个容器所依赖的，那么删除必然会导致故障。如果这些容器是不需要的，应该先将它们删除，然后再来删除镜像。 用 docker image ls 命令来配合 像其它可以承接多个实体的命令一样，可以使用 docker image ls -q 来配合使用 docker image rm，这样可以成批的删除希望删除的镜像。我们在“镜像列表”章节介绍过很多过滤镜像列表的方式都可以拿过来使用。 比如，我们需要删除所有仓库名为 redis 的镜像： $ docker image rm $(docker image ls -q redis) 或者删除所有在 mongo:3.2 之前的镜像： $ docker image rm $(docker image ls -q -f before=mongo:3.2) 充分利用你的想象力和 Linux 命令行的强大，你可以完成很多非常赞的功能。 Copyright © Zhenhai Gao 2021 all right reserved发布时间： 2024-06-10 23:03:15 "},"docker/docker-image/commit.html":{"url":"docker/docker-image/commit.html","title":"利用 commit 理解镜像构成","keywords":"","body":"利用 commit 理解镜像构成慎用 docker commit利用 commit 理解镜像构成 注意：如果您是初学者，您可以暂时跳过后面的内容，直接学习 容器 一节。 注意： docker commit 命令除了学习之外，还有一些特殊的应用场合，比如被入侵后保存现场等。但是，不要使用 docker commit 定制镜像，定制镜像应该使用 Dockerfile 来完成。如果你想要定制镜像请查看下一小节。 镜像是容器的基础，每次执行 docker run 的时候都会指定哪个镜像作为容器运行的基础。在之前的例子中，我们所使用的都是来自于 Docker Hub 的镜像。直接使用这些镜像是可以满足一定的需求，而当这些镜像无法直接满足需求时，我们就需要定制这些镜像。接下来的几节就将讲解如何定制镜像。 回顾一下之前我们学到的知识，镜像是多层存储，每一层是在前一层的基础上进行的修改；而容器同样也是多层存储，是在以镜像为基础层，在其基础上加一层作为容器运行时的存储层。 现在让我们以定制一个 Web 服务器为例子，来讲解镜像是如何构建的。 $ docker run --name webserver -d -p 80:80 nginx 这条命令会用 nginx 镜像启动一个容器，命名为 webserver，并且映射了 80 端口，这样我们可以用浏览器去访问这个 nginx 服务器。 如果是在本机运行的 Docker，那么可以直接访问：http://localhost ，如果是在虚拟机、云服务器上安装的 Docker，则需要将 localhost 换为虚拟机地址或者实际云服务器地址。 直接用浏览器访问的话，我们会看到默认的 Nginx 欢迎页面。 现在，假设我们非常不喜欢这个欢迎页面，我们希望改成欢迎 Docker 的文字，我们可以使用 docker exec 命令进入容器，修改其内容。 $ docker exec -it webserver bash root@3729b97e8226:/# echo 'Hello, Docker!' > /usr/share/nginx/html/index.html root@3729b97e8226:/# exit exit 我们以交互式终端方式进入 webserver 容器，并执行了 bash 命令，也就是获得一个可操作的 Shell。 然后，我们用 Hello, Docker! 覆盖了 /usr/share/nginx/html/index.html 的内容。 现在我们再刷新浏览器的话，会发现内容被改变了。 我们修改了容器的文件，也就是改动了容器的存储层。我们可以通过 docker diff 命令看到具体的改动。 $ docker diff webserver C /root A /root/.bash_history C /run C /usr C /usr/share C /usr/share/nginx C /usr/share/nginx/html C /usr/share/nginx/html/index.html C /var C /var/cache C /var/cache/nginx A /var/cache/nginx/client_temp A /var/cache/nginx/fastcgi_temp A /var/cache/nginx/proxy_temp A /var/cache/nginx/scgi_temp A /var/cache/nginx/uwsgi_temp 现在我们定制好了变化，我们希望能将其保存下来形成镜像。 要知道，当我们运行一个容器的时候（如果不使用卷的话），我们做的任何文件修改都会被记录于容器存储层里。而 Docker 提供了一个 docker commit 命令，可以将容器的存储层保存下来成为镜像。换句话说，就是在原有镜像的基础上，再叠加上容器的存储层，并构成新的镜像。以后我们运行这个新镜像的时候，就会拥有原有容器最后的文件变化。 docker commit 的语法格式为： docker commit [选项] [[:]] 我们可以用下面的命令将容器保存为镜像： $ docker commit \\ --author \"Tao Wang \" \\ --message \"修改了默认网页\" \\ webserver \\ nginx:v2 sha256:07e33465974800ce65751acc279adc6ed2dc5ed4e0838f8b86f0c87aa1795214 其中 --author 是指定修改的作者，而 --message 则是记录本次修改的内容。这点和 git 版本控制相似，不过这里这些信息可以省略留空。 我们可以在 docker image ls 中看到这个新定制的镜像： $ docker image ls nginx REPOSITORY TAG IMAGE ID CREATED SIZE nginx v2 07e334659748 9 seconds ago 181.5 MB nginx 1.11 05a60462f8ba 12 days ago 181.5 MB nginx latest e43d811ce2f4 4 weeks ago 181.5 MB 我们还可以用 docker history 具体查看镜像内的历史记录，如果比较 nginx:latest 的历史记录，我们会发现新增了我们刚刚提交的这一层。 $ docker history nginx:v2 IMAGE CREATED CREATED BY SIZE COMMENT 07e334659748 54 seconds ago nginx -g daemon off; 95 B 修改了默认网页 e43d811ce2f4 4 weeks ago /bin/sh -c #(nop) CMD [\"nginx\" \"-g\" \"daemon 0 B 4 weeks ago /bin/sh -c #(nop) EXPOSE 443/tcp 80/tcp 0 B 4 weeks ago /bin/sh -c ln -sf /dev/stdout /var/log/nginx/ 22 B 4 weeks ago /bin/sh -c apt-key adv --keyserver hkp://pgp. 58.46 MB 4 weeks ago /bin/sh -c #(nop) ENV NGINX_VERSION=1.11.5-1 0 B 4 weeks ago /bin/sh -c #(nop) MAINTAINER NGINX Docker Ma 0 B 4 weeks ago /bin/sh -c #(nop) CMD [\"/bin/bash\"] 0 B 4 weeks ago /bin/sh -c #(nop) ADD file:23aa4f893e3288698c 123 MB 新的镜像定制好后，我们可以来运行这个镜像。 docker run --name web2 -d -p 81:80 nginx:v2 这里我们命名为新的服务为 web2，并且映射到 81 端口。访问 http://localhost:81 看到结果，其内容应该和之前修改后的 webserver 一样。 至此，我们第一次完成了定制镜像，使用的是 docker commit 命令，手动操作给旧的镜像添加了新的一层，形成新的镜像，对镜像多层存储应该有了更直观的感觉。 慎用 docker commit 使用 docker commit 命令虽然可以比较直观的帮助理解镜像分层存储的概念，但是实际环境中并不会这样使用。 首先，如果仔细观察之前的 docker diff webserver 的结果，你会发现除了真正想要修改的 /usr/share/nginx/html/index.html 文件外，由于命令的执行，还有很多文件被改动或添加了。这还仅仅是最简单的操作，如果是安装软件包、编译构建，那会有大量的无关内容被添加进来，将会导致镜像极为臃肿。 此外，使用 docker commit 意味着所有对镜像的操作都是黑箱操作，生成的镜像也被称为 黑箱镜像，换句话说，就是除了制作镜像的人知道执行过什么命令、怎么生成的镜像，别人根本无从得知。而且，即使是这个制作镜像的人，过一段时间后也无法记清具体的操作。这种黑箱镜像的维护工作是非常痛苦的。 而且，回顾之前提及的镜像所使用的分层存储的概念，除当前层外，之前的每一层都是不会发生改变的，换句话说，任何修改的结果仅仅是在当前层进行标记、添加、修改，而不会改动上一层。如果使用 docker commit 制作镜像，以及后期修改的话，每一次修改都会让镜像更加臃肿一次，所删除的上一层的东西并不会丢失，会一直如影随形的跟着这个镜像，即使根本无法访问到。这会让镜像更加臃肿。 Copyright © Zhenhai Gao 2021 all right reserved发布时间： 2024-06-10 23:03:15 "},"docker/docker-image/build.html":{"url":"docker/docker-image/build.html","title":"使用 Dockerfile 定制镜像","keywords":"","body":"使用 Dockerfile 定制镜像FROM 指定基础镜像RUN 执行命令构建镜像镜像构建上下文（Context）其它 docker build 的用法直接用 Git repo 进行构建用给定的 tar 压缩包构建从标准输入中读取 Dockerfile 进行构建从标准输入中读取上下文压缩包进行构建使用 Dockerfile 定制镜像 从刚才的 docker commit 的学习中，我们可以了解到，镜像的定制实际上就是定制每一层所添加的配置、文件。如果我们可以把每一层修改、安装、构建、操作的命令都写入一个脚本，用这个脚本来构建、定制镜像，那么之前提及的无法重复的问题、镜像构建透明性的问题、体积的问题就都会解决。这个脚本就是 Dockerfile。 Dockerfile 是一个文本文件，其内包含了一条条的 指令(Instruction)，每一条指令构建一层，因此每一条指令的内容，就是描述该层应当如何构建。 还以之前定制 nginx 镜像为例，这次我们使用 Dockerfile 来定制。 在一个空白目录中，建立一个文本文件，并命名为 Dockerfile： $ mkdir mynginx $ cd mynginx $ touch Dockerfile 其内容为： FROM nginx RUN echo 'Hello, Docker!' > /usr/share/nginx/html/index.html 这个 Dockerfile 很简单，一共就两行。涉及到了两条指令，FROM 和 RUN。 FROM 指定基础镜像 所谓定制镜像，那一定是以一个镜像为基础，在其上进行定制。就像我们之前运行了一个 nginx 镜像的容器，再进行修改一样，基础镜像是必须指定的。而 FROM 就是指定 基础镜像，因此一个 Dockerfile 中 FROM 是必备的指令，并且必须是第一条指令。 在 Docker Hub 上有非常多的高质量的官方镜像，有可以直接拿来使用的服务类的镜像，如 nginx、redis、mongo、mysql、httpd、php、tomcat 等；也有一些方便开发、构建、运行各种语言应用的镜像，如 node、openjdk、python、ruby、golang 等。可以在其中寻找一个最符合我们最终目标的镜像为基础镜像进行定制。 如果没有找到对应服务的镜像，官方镜像中还提供了一些更为基础的操作系统镜像，如 ubuntu、debian、centos、fedora、alpine 等，这些操作系统的软件库为我们提供了更广阔的扩展空间。 除了选择现有镜像为基础镜像外，Docker 还存在一个特殊的镜像，名为 scratch。这个镜像是虚拟的概念，并不实际存在，它表示一个空白的镜像。 FROM scratch ... 如果你以 scratch 为基础镜像的话，意味着你不以任何镜像为基础，接下来所写的指令将作为镜像第一层开始存在。 不以任何系统为基础，直接将可执行文件复制进镜像的做法并不罕见，对于 Linux 下静态编译的程序来说，并不需要有操作系统提供运行时支持，所需的一切库都已经在可执行文件里了，因此直接 FROM scratch 会让镜像体积更加小巧。使用 Go 语言 开发的应用很多会使用这种方式来制作镜像，这也是为什么有人认为 Go 是特别适合容器微服务架构的语言的原因之一。 RUN 执行命令 RUN 指令是用来执行命令行命令的。由于命令行的强大能力，RUN 指令在定制镜像时是最常用的指令之一。其格式有两种： shell 格式：RUN ，就像直接在命令行中输入的命令一样。刚才写的 Dockerfile 中的 RUN 指令就是这种格式。 RUN echo 'Hello, Docker!' > /usr/share/nginx/html/index.html exec 格式：RUN [\"可执行文件\", \"参数1\", \"参数2\"]，这更像是函数调用中的格式。 既然 RUN 就像 Shell 脚本一样可以执行命令，那么我们是否就可以像 Shell 脚本一样把每个命令对应一个 RUN 呢？比如这样： FROM debian:stretch RUN apt-get update RUN apt-get install -y gcc libc6-dev make wget RUN wget -O redis.tar.gz \"http://download.redis.io/releases/redis-5.0.3.tar.gz\" RUN mkdir -p /usr/src/redis RUN tar -xzf redis.tar.gz -C /usr/src/redis --strip-components=1 RUN make -C /usr/src/redis RUN make -C /usr/src/redis install 之前说过，Dockerfile 中每一个指令都会建立一层，RUN 也不例外。每一个 RUN 的行为，就和刚才我们手工建立镜像的过程一样：新建立一层，在其上执行这些命令，执行结束后，commit 这一层的修改，构成新的镜像。 而上面的这种写法，创建了 7 层镜像。这是完全没有意义的，而且很多运行时不需要的东西，都被装进了镜像里，比如编译环境、更新的软件包等等。结果就是产生非常臃肿、非常多层的镜像，不仅仅增加了构建部署的时间，也很容易出错。 这是很多初学 Docker 的人常犯的一个错误。 Union FS 是有最大层数限制的，比如 AUFS，曾经是最大不得超过 42 层，现在是不得超过 127 层。 上面的 Dockerfile 正确的写法应该是这样： FROM debian:stretch RUN set -x; buildDeps='gcc libc6-dev make wget' \\ && apt-get update \\ && apt-get install -y $buildDeps \\ && wget -O redis.tar.gz \"http://download.redis.io/releases/redis-5.0.3.tar.gz\" \\ && mkdir -p /usr/src/redis \\ && tar -xzf redis.tar.gz -C /usr/src/redis --strip-components=1 \\ && make -C /usr/src/redis \\ && make -C /usr/src/redis install \\ && rm -rf /var/lib/apt/lists/* \\ && rm redis.tar.gz \\ && rm -r /usr/src/redis \\ && apt-get purge -y --auto-remove $buildDeps 首先，之前所有的命令只有一个目的，就是编译、安装 redis 可执行文件。因此没有必要建立很多层，这只是一层的事情。因此，这里没有使用很多个 RUN 一一对应不同的命令，而是仅仅使用一个 RUN 指令，并使用 && 将各个所需命令串联起来。将之前的 7 层，简化为了 1 层。在撰写 Dockerfile 的时候，要经常提醒自己，这并不是在写 Shell 脚本，而是在定义每一层该如何构建。 并且，这里为了格式化还进行了换行。Dockerfile 支持 Shell 类的行尾添加 \\ 的命令换行方式，以及行首 # 进行注释的格式。良好的格式，比如换行、缩进、注释等，会让维护、排障更为容易，这是一个比较好的习惯。 此外，还可以看到这一组命令的最后添加了清理工作的命令，删除了为了编译构建所需要的软件，清理了所有下载、展开的文件，并且还清理了 apt 缓存文件。这是很重要的一步，我们之前说过，镜像是多层存储，每一层的东西并不会在下一层被删除，会一直跟随着镜像。因此镜像构建时，一定要确保每一层只添加真正需要添加的东西，任何无关的东西都应该清理掉。 很多人初学 Docker 制作出了很臃肿的镜像的原因之一，就是忘记了每一层构建的最后一定要清理掉无关文件。 构建镜像 好了，让我们再回到之前定制的 nginx 镜像的 Dockerfile 来。现在我们明白了这个 Dockerfile 的内容，那么让我们来构建这个镜像吧。 在 Dockerfile 文件所在目录执行： $ docker build -t nginx:v3 . Sending build context to Docker daemon 2.048 kB Step 1 : FROM nginx ---> e43d811ce2f4 Step 2 : RUN echo 'Hello, Docker!' > /usr/share/nginx/html/index.html ---> Running in 9cdc27646c7b ---> 44aa4490ce2c Removing intermediate container 9cdc27646c7b Successfully built 44aa4490ce2c 从命令的输出结果中，我们可以清晰的看到镜像的构建过程。在 Step 2 中，如同我们之前所说的那样，RUN 指令启动了一个容器 9cdc27646c7b，执行了所要求的命令，并最后提交了这一层 44aa4490ce2c，随后删除了所用到的这个容器 9cdc27646c7b。 这里我们使用了 docker build 命令进行镜像构建。其格式为： docker build [选项] 在这里我们指定了最终镜像的名称 -t nginx:v3，构建成功后，我们可以像之前运行 nginx:v2 那样来运行这个镜像，其结果会和 nginx:v2 一样。 镜像构建上下文（Context） 如果注意，会看到 docker build 命令最后有一个 .。. 表示当前目录，而 Dockerfile 就在当前目录，因此不少初学者以为这个路径是在指定 Dockerfile 所在路径，这么理解其实是不准确的。如果对应上面的命令格式，你可能会发现，这是在指定 上下文路径。那么什么是上下文呢？ 首先我们要理解 docker build 的工作原理。Docker 在运行时分为 Docker 引擎（也就是服务端守护进程）和客户端工具。Docker 的引擎提供了一组 REST API，被称为 Docker Remote API，而如 docker 命令这样的客户端工具，则是通过这组 API 与 Docker 引擎交互，从而完成各种功能。因此，虽然表面上我们好像是在本机执行各种 docker 功能，但实际上，一切都是使用的远程调用形式在服务端（Docker 引擎）完成。也因为这种 C/S 设计，让我们操作远程服务器的 Docker 引擎变得轻而易举。 当我们进行镜像构建的时候，并非所有定制都会通过 RUN 指令完成，经常会需要将一些本地文件复制进镜像，比如通过 COPY 指令、ADD 指令等。而 docker build 命令构建镜像，其实并非在本地构建，而是在服务端，也就是 Docker 引擎中构建的。那么在这种客户端/服务端的架构中，如何才能让服务端获得本地文件呢？ 这就引入了上下文的概念。当构建的时候，用户会指定构建镜像上下文的路径，docker build 命令得知这个路径后，会将路径下的所有内容打包，然后上传给 Docker 引擎。这样 Docker 引擎收到这个上下文包后，展开就会获得构建镜像所需的一切文件。 如果在 Dockerfile 中这么写： COPY ./package.json /app/ 这并不是要复制执行 docker build 命令所在的目录下的 package.json，也不是复制 Dockerfile 所在目录下的 package.json，而是复制 上下文（context） 目录下的 package.json。 因此，COPY 这类指令中的源文件的路径都是相对路径。这也是初学者经常会问的为什么 COPY ../package.json /app 或者 COPY /opt/xxxx /app 无法工作的原因，因为这些路径已经超出了上下文的范围，Docker 引擎无法获得这些位置的文件。如果真的需要那些文件，应该将它们复制到上下文目录中去。 现在就可以理解刚才的命令 docker build -t nginx:v3 . 中的这个 .，实际上是在指定上下文的目录，docker build 命令会将该目录下的内容打包交给 Docker 引擎以帮助构建镜像。 如果观察 docker build 输出，我们其实已经看到了这个发送上下文的过程： $ docker build -t nginx:v3 . Sending build context to Docker daemon 2.048 kB ... 理解构建上下文对于镜像构建是很重要的，避免犯一些不应该的错误。比如有些初学者在发现 COPY /opt/xxxx /app 不工作后，于是干脆将 Dockerfile 放到了硬盘根目录去构建，结果发现 docker build 执行后，在发送一个几十 GB 的东西，极为缓慢而且很容易构建失败。那是因为这种做法是在让 docker build 打包整个硬盘，这显然是使用错误。 一般来说，应该会将 Dockerfile 置于一个空目录下，或者项目根目录下。如果该目录下没有所需文件，那么应该把所需文件复制一份过来。如果目录下有些东西确实不希望构建时传给 Docker 引擎，那么可以用 .gitignore 一样的语法写一个 .dockerignore，该文件是用于剔除不需要作为上下文传递给 Docker 引擎的。 那么为什么会有人误以为 . 是指定 Dockerfile 所在目录呢？这是因为在默认情况下，如果不额外指定 Dockerfile 的话，会将上下文目录下的名为 Dockerfile 的文件作为 Dockerfile。 这只是默认行为，实际上 Dockerfile 的文件名并不要求必须为 Dockerfile，而且并不要求必须位于上下文目录中，比如可以用 -f ../Dockerfile.php 参数指定某个文件作为 Dockerfile。 当然，一般大家习惯性的会使用默认的文件名 Dockerfile，以及会将其置于镜像构建上下文目录中。 其它 docker build 的用法 直接用 Git repo 进行构建 或许你已经注意到了，docker build 还支持从 URL 构建，比如可以直接从 Git repo 中构建： # $env:DOCKER_BUILDKIT=0 # export DOCKER_BUILDKIT=0 $ docker build -t hello-world https://github.com/docker-library/hello-world.git#master:amd64/hello-world Step 1/3 : FROM scratch ---> Step 2/3 : COPY hello / ---> ac779757d46e Step 3/3 : CMD [\"/hello\"] ---> Running in d2a513a760ed Removing intermediate container d2a513a760ed ---> 038ad4142d2b Successfully built 038ad4142d2b 这行命令指定了构建所需的 Git repo，并且指定分支为 master，构建目录为 /amd64/hello-world/，然后 Docker 就会自己去 git clone 这个项目、切换到指定分支、并进入到指定目录后开始构建。 用给定的 tar 压缩包构建 $ docker build http://server/context.tar.gz 如果所给出的 URL 不是个 Git repo，而是个 tar 压缩包，那么 Docker 引擎会下载这个包，并自动解压缩，以其作为上下文，开始构建。 从标准输入中读取 Dockerfile 进行构建 docker build - 或 cat Dockerfile | docker build - 如果标准输入传入的是文本文件，则将其视为 Dockerfile，并开始构建。这种形式由于直接从标准输入中读取 Dockerfile 的内容，它没有上下文，因此不可以像其他方法那样可以将本地文件 COPY 进镜像之类的事情。 从标准输入中读取上下文压缩包进行构建 $ docker build - 如果发现标准输入的文件格式是 gzip、bzip2 以及 xz 的话，将会使其为上下文压缩包，直接将其展开，将里面视为上下文，并开始构建。 Copyright © Zhenhai Gao 2021 all right reserved发布时间： 2024-06-10 23:03:15 "},"docker/docker-image/dockerfile/":{"url":"docker/docker-image/dockerfile/","title":"Dockerfile 指令详解","keywords":"","body":"Dockerfile 指令详解Dockerfile 指令详解 我们已经介绍了 FROM，RUN，还提及了 COPY, ADD，其实 Dockerfile 功能很强大，它提供了十多个指令。下面我们继续讲解其他的指令。 Copyright © Zhenhai Gao 2021 all right reserved发布时间： 2024-06-10 23:03:15 "},"docker/docker-image/dockerfile/copy.html":{"url":"docker/docker-image/dockerfile/copy.html","title":"COPY 复制文件","keywords":"","body":"COPY 复制文件COPY 复制文件 格式： COPY [--chown=:] ... COPY [--chown=:] [\"\",... \"\"] 和 RUN 指令一样，也有两种格式，一种类似于命令行，一种类似于函数调用。 COPY 指令将从构建上下文目录中 的文件/目录复制到新的一层的镜像内的 位置。比如： COPY package.json /usr/src/app/ 可以是多个，甚至可以是通配符，其通配符规则要满足 Go 的 filepath.Match 规则，如： COPY hom* /mydir/ COPY hom?.txt /mydir/ 可以是容器内的绝对路径，也可以是相对于工作目录的相对路径（工作目录可以用 WORKDIR 指令来指定）。目标路径不需要事先创建，如果目录不存在会在复制文件前先行创建缺失目录。 此外，还需要注意一点，使用 COPY 指令，源文件的各种元数据都会保留。比如读、写、执行权限、文件变更时间等。这个特性对于镜像定制很有用。特别是构建相关文件都在使用 Git 进行管理的时候。 在使用该指令的时候还可以加上 --chown=: 选项来改变文件的所属用户及所属组。 COPY --chown=55:mygroup files* /mydir/ COPY --chown=bin files* /mydir/ COPY --chown=1 files* /mydir/ COPY --chown=10:11 files* /mydir/ 如果源路径为文件夹，复制的时候不是直接复制该文件夹，而是将文件夹中的内容复制到目标路径。 Copyright © Zhenhai Gao 2021 all right reserved发布时间： 2024-06-10 23:03:15 "},"docker/docker-image/dockerfile/add.html":{"url":"docker/docker-image/dockerfile/add.html","title":"ADD 更高级的复制文件","keywords":"","body":"ADD 更高级的复制文件ADD 更高级的复制文件 ADD 指令和 COPY 的格式和性质基本一致。但是在 COPY 基础上增加了一些功能。 比如 可以是一个 URL，这种情况下，Docker 引擎会试图去下载这个链接的文件放到 去。下载后的文件权限自动设置为 600，如果这并不是想要的权限，那么还需要增加额外的一层 RUN 进行权限调整，另外，如果下载的是个压缩包，需要解压缩，也一样还需要额外的一层 RUN 指令进行解压缩。所以不如直接使用 RUN 指令，然后使用 wget 或者 curl 工具下载，处理权限、解压缩、然后清理无用文件更合理。因此，这个功能其实并不实用，而且不推荐使用。 如果 为一个 tar 压缩文件的话，压缩格式为 gzip, bzip2 以及 xz 的情况下，ADD 指令将会自动解压缩这个压缩文件到 去。 在某些情况下，这个自动解压缩的功能非常有用，比如官方镜像 ubuntu 中： FROM scratch ADD ubuntu-xenial-core-cloudimg-amd64-root.tar.gz / ... 但在某些情况下，如果我们真的是希望复制个压缩文件进去，而不解压缩，这时就不可以使用 ADD 命令了。 在 Docker 官方的 Dockerfile 最佳实践文档 中要求，尽可能的使用 COPY，因为 COPY 的语义很明确，就是复制文件而已，而 ADD 则包含了更复杂的功能，其行为也不一定很清晰。最适合使用 ADD 的场合，就是所提及的需要自动解压缩的场合。 另外需要注意的是，ADD 指令会令镜像构建缓存失效，从而可能会令镜像构建变得比较缓慢。 因此在 COPY 和 ADD 指令中选择的时候，可以遵循这样的原则，所有的文件复制均使用 COPY 指令，仅在需要自动解压缩的场合使用 ADD。 在使用该指令的时候还可以加上 --chown=: 选项来改变文件的所属用户及所属组。 ADD --chown=55:mygroup files* /mydir/ ADD --chown=bin files* /mydir/ ADD --chown=1 files* /mydir/ ADD --chown=10:11 files* /mydir/ Copyright © Zhenhai Gao 2021 all right reserved发布时间： 2024-06-10 23:03:15 "},"docker/docker-image/dockerfile/cmd.html":{"url":"docker/docker-image/dockerfile/cmd.html","title":"CMD 容器启动命令","keywords":"","body":"CMD 容器启动命令CMD 容器启动命令 CMD 指令的格式和 RUN 相似，也是两种格式： shell 格式：CMD exec 格式：CMD [\"可执行文件\", \"参数1\", \"参数2\"...] 参数列表格式：CMD [\"参数1\", \"参数2\"...]。在指定了 ENTRYPOINT 指令后，用 CMD 指定具体的参数。 之前介绍容器的时候曾经说过，Docker 不是虚拟机，容器就是进程。既然是进程，那么在启动容器的时候，需要指定所运行的程序及参数。CMD 指令就是用于指定默认的容器主进程的启动命令的。 在运行时可以指定新的命令来替代镜像设置中的这个默认命令，比如，ubuntu 镜像默认的 CMD 是 /bin/bash，如果我们直接 docker run -it ubuntu 的话，会直接进入 bash。我们也可以在运行时指定运行别的命令，如 docker run -it ubuntu cat /etc/os-release。这就是用 cat /etc/os-release 命令替换了默认的 /bin/bash 命令了，输出了系统版本信息。 在指令格式上，一般推荐使用 exec 格式，这类格式在解析时会被解析为 JSON 数组，因此一定要使用双引号 \"，而不要使用单引号。 如果使用 shell 格式的话，实际的命令会被包装为 sh -c 的参数的形式进行执行。比如： CMD echo $HOME 在实际执行中，会将其变更为： CMD [ \"sh\", \"-c\", \"echo $HOME\" ] 这就是为什么我们可以使用环境变量的原因，因为这些环境变量会被 shell 进行解析处理。 提到 CMD 就不得不提容器中应用在前台执行和后台执行的问题。这是初学者常出现的一个混淆。 Docker 不是虚拟机，容器中的应用都应该以前台执行，而不是像虚拟机、物理机里面那样，用 systemd 去启动后台服务，容器内没有后台服务的概念。 一些初学者将 CMD 写为： CMD service nginx start 然后发现容器执行后就立即退出了。甚至在容器内去使用 systemctl 命令结果却发现根本执行不了。这就是因为没有搞明白前台、后台的概念，没有区分容器和虚拟机的差异，依旧在以传统虚拟机的角度去理解容器。 对于容器而言，其启动程序就是容器应用进程，容器就是为了主进程而存在的，主进程退出，容器就失去了存在的意义，从而退出，其它辅助进程不是它需要关心的东西。 而使用 service nginx start 命令，则是希望 upstart 来以后台守护进程形式启动 nginx 服务。而刚才说了 CMD service nginx start 会被理解为 CMD [ \"sh\", \"-c\", \"service nginx start\"]，因此主进程实际上是 sh。那么当 service nginx start 命令结束后，sh 也就结束了，sh 作为主进程退出了，自然就会令容器退出。 正确的做法是直接执行 nginx 可执行文件，并且要求以前台形式运行。比如： CMD [\"nginx\", \"-g\", \"daemon off;\"] Copyright © Zhenhai Gao 2021 all right reserved发布时间： 2024-06-10 23:03:15 "},"docker/docker-image/dockerfile/entrypoint.html":{"url":"docker/docker-image/dockerfile/entrypoint.html","title":"ENTRYPOINT 入口点","keywords":"","body":"ENTRYPOINT 入口点ENTRYPOINT 入口点 ENTRYPOINT 的格式和 RUN 指令格式一样，分为 exec 格式和 shell 格式。 ENTRYPOINT 的目的和 CMD 一样，都是在指定容器启动程序及参数。ENTRYPOINT 在运行时也可以替代，不过比 CMD 要略显繁琐，需要通过 docker run 的参数 --entrypoint 来指定。 当指定了 ENTRYPOINT 后，CMD 的含义就发生了改变，不再是直接的运行其命令，而是将 CMD 的内容作为参数传给 ENTRYPOINT 指令，换句话说实际执行时，将变为： \"\" 那么有了 CMD 后，为什么还要有 ENTRYPOINT 呢？这种 \"\" 有什么好处么？让我们来看几个场景。 场景一：让镜像变成像命令一样使用 假设我们需要一个得知自己当前公网 IP 的镜像，那么可以先用 CMD 来实现： FROM ubuntu:18.04 RUN apt-get update \\ && apt-get install -y curl \\ && rm -rf /var/lib/apt/lists/* CMD [ \"curl\", \"-s\", \"http://myip.ipip.net\" ] 假如我们使用 docker build -t myip . 来构建镜像的话，如果我们需要查询当前公网 IP，只需要执行： $ docker run myip 当前 IP：61.148.226.66 来自：北京市 联通 嗯，这么看起来好像可以直接把镜像当做命令使用了，不过命令总有参数，如果我们希望加参数呢？比如从上面的 CMD 中可以看到实质的命令是 curl，那么如果我们希望显示 HTTP 头信息，就需要加上 -i 参数。那么我们可以直接加 -i 参数给 docker run myip 么？ $ docker run myip -i docker: Error response from daemon: invalid header field value \"oci runtime error: container_linux.go:247: starting container process caused \\\"exec: \\\\\\\"-i\\\\\\\": executable file not found in $PATH\\\"\\n\". 我们可以看到可执行文件找不到的报错，executable file not found。之前我们说过，跟在镜像名后面的是 command，运行时会替换 CMD 的默认值。因此这里的 -i 替换了原来的 CMD，而不是添加在原来的 curl -s http://myip.ipip.net 后面。而 -i 根本不是命令，所以自然找不到。 那么如果我们希望加入 -i 这参数，我们就必须重新完整的输入这个命令： $ docker run myip curl -s http://myip.ipip.net -i 这显然不是很好的解决方案，而使用 ENTRYPOINT 就可以解决这个问题。现在我们重新用 ENTRYPOINT 来实现这个镜像： FROM ubuntu:18.04 RUN apt-get update \\ && apt-get install -y curl \\ && rm -rf /var/lib/apt/lists/* ENTRYPOINT [ \"curl\", \"-s\", \"http://myip.ipip.net\" ] 这次我们再来尝试直接使用 docker run myip -i： $ docker run myip 当前 IP：61.148.226.66 来自：北京市 联通 $ docker run myip -i HTTP/1.1 200 OK Server: nginx/1.8.0 Date: Tue, 22 Nov 2016 05:12:40 GMT Content-Type: text/html; charset=UTF-8 Vary: Accept-Encoding X-Powered-By: PHP/5.6.24-1~dotdeb+7.1 X-Cache: MISS from cache-2 X-Cache-Lookup: MISS from cache-2:80 X-Cache: MISS from proxy-2_6 Transfer-Encoding: chunked Via: 1.1 cache-2:80, 1.1 proxy-2_6:8006 Connection: keep-alive 当前 IP：61.148.226.66 来自：北京市 联通 可以看到，这次成功了。这是因为当存在 ENTRYPOINT 后，CMD 的内容将会作为参数传给 ENTRYPOINT，而这里 -i 就是新的 CMD，因此会作为参数传给 curl，从而达到了我们预期的效果。 场景二：应用运行前的准备工作 启动容器就是启动主进程，但有些时候，启动主进程前，需要一些准备工作。 比如 mysql 类的数据库，可能需要一些数据库配置、初始化的工作，这些工作要在最终的 mysql 服务器运行之前解决。 此外，可能希望避免使用 root 用户去启动服务，从而提高安全性，而在启动服务前还需要以 root 身份执行一些必要的准备工作，最后切换到服务用户身份启动服务。或者除了服务外，其它命令依旧可以使用 root 身份执行，方便调试等。 这些准备工作是和容器 CMD 无关的，无论 CMD 为什么，都需要事先进行一个预处理的工作。这种情况下，可以写一个脚本，然后放入 ENTRYPOINT 中去执行，而这个脚本会将接到的参数（也就是 ）作为命令，在脚本最后执行。比如官方镜像 redis 中就是这么做的： FROM alpine:3.4 ... RUN addgroup -S redis && adduser -S -G redis redis ... ENTRYPOINT [\"docker-entrypoint.sh\"] EXPOSE 6379 CMD [ \"redis-server\" ] 可以看到其中为了 redis 服务创建了 redis 用户，并在最后指定了 ENTRYPOINT 为 docker-entrypoint.sh 脚本。 #!/bin/sh ... # allow the container to be started with `--user` if [ \"$1\" = 'redis-server' -a \"$(id -u)\" = '0' ]; then find . \\! -user redis -exec chown redis '{}' + exec gosu redis \"$0\" \"$@\" fi exec \"$@\" 该脚本的内容就是根据 CMD 的内容来判断，如果是 redis-server 的话，则切换到 redis 用户身份启动服务器，否则依旧使用 root 身份执行。比如： $ docker run -it redis id uid=0(root) gid=0(root) groups=0(root) Copyright © Zhenhai Gao 2021 all right reserved发布时间： 2024-06-10 23:03:15 "},"docker/docker-image/dockerfile/env.html":{"url":"docker/docker-image/dockerfile/env.html","title":"ENV 设置环境变量","keywords":"","body":"ENV 设置环境变量ENV 设置环境变量 格式有两种： ENV ENV = =... 这个指令很简单，就是设置环境变量而已，无论是后面的其它指令，如 RUN，还是运行时的应用，都可以直接使用这里定义的环境变量。 ENV VERSION=1.0 DEBUG=on \\ NAME=\"Happy Feet\" 这个例子中演示了如何换行，以及对含有空格的值用双引号括起来的办法，这和 Shell 下的行为是一致的。 定义了环境变量，那么在后续的指令中，就可以使用这个环境变量。比如在官方 node 镜像 Dockerfile 中，就有类似这样的代码： ENV NODE_VERSION 7.2.0 RUN curl -SLO \"https://nodejs.org/dist/v$NODE_VERSION/node-v$NODE_VERSION-linux-x64.tar.xz\" \\ && curl -SLO \"https://nodejs.org/dist/v$NODE_VERSION/SHASUMS256.txt.asc\" \\ && gpg --batch --decrypt --output SHASUMS256.txt SHASUMS256.txt.asc \\ && grep \" node-v$NODE_VERSION-linux-x64.tar.xz\\$\" SHASUMS256.txt | sha256sum -c - \\ && tar -xJf \"node-v$NODE_VERSION-linux-x64.tar.xz\" -C /usr/local --strip-components=1 \\ && rm \"node-v$NODE_VERSION-linux-x64.tar.xz\" SHASUMS256.txt.asc SHASUMS256.txt \\ && ln -s /usr/local/bin/node /usr/local/bin/nodejs 在这里先定义了环境变量 NODE_VERSION，其后的 RUN 这层里，多次使用 $NODE_VERSION 来进行操作定制。可以看到，将来升级镜像构建版本的时候，只需要更新 7.2.0 即可，Dockerfile 构建维护变得更轻松了。 下列指令可以支持环境变量展开： ADD、COPY、ENV、EXPOSE、FROM、LABEL、USER、WORKDIR、VOLUME、STOPSIGNAL、ONBUILD、RUN。 可以从这个指令列表里感觉到，环境变量可以使用的地方很多，很强大。通过环境变量，我们可以让一份 Dockerfile 制作更多的镜像，只需使用不同的环境变量即可。 Copyright © Zhenhai Gao 2021 all right reserved发布时间： 2024-06-10 23:03:15 "},"docker/docker-image/dockerfile/arg.html":{"url":"docker/docker-image/dockerfile/arg.html","title":"ARG 构建参数","keywords":"","body":"ARG 构建参数ARG 构建参数 格式：ARG [=] 构建参数和 ENV 的效果一样，都是设置环境变量。所不同的是，ARG 所设置的构建环境的环境变量，在将来容器运行时是不会存在这些环境变量的。但是不要因此就使用 ARG 保存密码之类的信息，因为 docker history 还是可以看到所有值的。 Dockerfile 中的 ARG 指令是定义参数名称，以及定义其默认值。该默认值可以在构建命令 docker build 中用 --build-arg = 来覆盖。 灵活的使用 ARG 指令，能够在不修改 Dockerfile 的情况下，构建出不同的镜像。 ARG 指令有生效范围，如果在 FROM 指令之前指定，那么只能用于 FROM 指令中。 ARG DOCKER_USERNAME=library FROM ${DOCKER_USERNAME}/alpine RUN set -x ; echo ${DOCKER_USERNAME} 使用上述 Dockerfile 会发现无法输出 ${DOCKER_USERNAME} 变量的值，要想正常输出，你必须在 FROM 之后再次指定 ARG # 只在 FROM 中生效 ARG DOCKER_USERNAME=library FROM ${DOCKER_USERNAME}/alpine # 要想在 FROM 之后使用，必须再次指定 ARG DOCKER_USERNAME=library RUN set -x ; echo ${DOCKER_USERNAME} 对于多阶段构建，尤其要注意这个问题 # 这个变量在每个 FROM 中都生效 ARG DOCKER_USERNAME=library FROM ${DOCKER_USERNAME}/alpine RUN set -x ; echo 1 FROM ${DOCKER_USERNAME}/alpine RUN set -x ; echo 2 对于上述 Dockerfile 两个 FROM 指令都可以使用 ${DOCKER_USERNAME}，对于在各个阶段中使用的变量都必须在每个阶段分别指定： ARG DOCKER_USERNAME=library FROM ${DOCKER_USERNAME}/alpine # 在FROM 之后使用变量，必须在每个阶段分别指定 ARG DOCKER_USERNAME=library RUN set -x ; echo ${DOCKER_USERNAME} FROM ${DOCKER_USERNAME}/alpine # 在FROM 之后使用变量，必须在每个阶段分别指定 ARG DOCKER_USERNAME=library RUN set -x ; echo ${DOCKER_USERNAME} Copyright © Zhenhai Gao 2021 all right reserved发布时间： 2024-06-10 23:03:15 "},"docker/docker-image/dockerfile/volume.html":{"url":"docker/docker-image/dockerfile/volume.html","title":"VOLUME 定义匿名卷","keywords":"","body":"VOLUME 定义匿名卷VOLUME 定义匿名卷 格式为： VOLUME [\"\", \"\"...] VOLUME 之前我们说过，容器运行时应该尽量保持容器存储层不发生写操作，对于数据库类需要保存动态数据的应用，其数据库文件应该保存于卷(volume)中，后面的章节我们会进一步介绍 Docker 卷的概念。为了防止运行时用户忘记将动态文件所保存目录挂载为卷，在 Dockerfile 中，我们可以事先指定某些目录挂载为匿名卷，这样在运行时如果用户不指定挂载，其应用也可以正常运行，不会向容器存储层写入大量数据。 VOLUME /data 这里的 /data 目录就会在容器运行时自动挂载为匿名卷，任何向 /data 中写入的信息都不会记录进容器存储层，从而保证了容器存储层的无状态化。当然，运行容器时可以覆盖这个挂载设置。比如： $ docker run -d -v mydata:/data xxxx 在这行命令中，就使用了 mydata 这个命名卷挂载到了 /data 这个位置，替代了 Dockerfile 中定义的匿名卷的挂载配置。 Copyright © Zhenhai Gao 2021 all right reserved发布时间： 2024-06-10 23:03:15 "},"docker/docker-image/dockerfile/expose.html":{"url":"docker/docker-image/dockerfile/expose.html","title":"EXPOSE 暴露端口","keywords":"","body":"EXPOSE 声明端口EXPOSE 声明端口 格式为 EXPOSE [...]。 EXPOSE 指令是声明容器运行时提供服务的端口，这只是一个声明，在容器运行时并不会因为这个声明应用就会开启这个端口的服务。在 Dockerfile 中写入这样的声明有两个好处，一个是帮助镜像使用者理解这个镜像服务的守护端口，以方便配置映射；另一个用处则是在运行时使用随机端口映射时，也就是 docker run -P 时，会自动随机映射 EXPOSE 的端口。 要将 EXPOSE 和在运行时使用 -p : 区分开来。-p，是映射宿主端口和容器端口，换句话说，就是将容器的对应端口服务公开给外界访问，而 EXPOSE 仅仅是声明容器打算使用什么端口而已，并不会自动在宿主进行端口映射。 Copyright © Zhenhai Gao 2021 all right reserved发布时间： 2024-06-10 23:03:15 "},"docker/docker-image/dockerfile/workdir.html":{"url":"docker/docker-image/dockerfile/workdir.html","title":"WORKDIR 指定工作目录","keywords":"","body":"WORKDIR 指定工作目录WORKDIR 指定工作目录 格式为 WORKDIR 。 使用 WORKDIR 指令可以来指定工作目录（或者称为当前目录），以后各层的当前目录就被改为指定的目录，如该目录不存在，WORKDIR 会帮你建立目录。 之前提到一些初学者常犯的错误是把 Dockerfile 等同于 Shell 脚本来书写，这种错误的理解还可能会导致出现下面这样的错误： RUN cd /app RUN echo \"hello\" > world.txt 如果将这个 Dockerfile 进行构建镜像运行后，会发现找不到 /app/world.txt 文件，或者其内容不是 hello。原因其实很简单，在 Shell 中，连续两行是同一个进程执行环境，因此前一个命令修改的内存状态，会直接影响后一个命令；而在 Dockerfile 中，这两行 RUN 命令的执行环境根本不同，是两个完全不同的容器。这就是对 Dockerfile 构建分层存储的概念不了解所导致的错误。 之前说过每一个 RUN 都是启动一个容器、执行命令、然后提交存储层文件变更。第一层 RUN cd /app 的执行仅仅是当前进程的工作目录变更，一个内存上的变化而已，其结果不会造成任何文件变更。而到第二层的时候，启动的是一个全新的容器，跟第一层的容器更完全没关系，自然不可能继承前一层构建过程中的内存变化。 因此如果需要改变以后各层的工作目录的位置，那么应该使用 WORKDIR 指令。 WORKDIR /app RUN echo \"hello\" > world.txt 如果你的 WORKDIR 指令使用的相对路径，那么所切换的路径与之前的 WORKDIR 有关： WORKDIR /a WORKDIR b WORKDIR c RUN pwd RUN pwd 的工作目录为 /a/b/c。 Copyright © Zhenhai Gao 2021 all right reserved发布时间： 2024-06-10 23:03:15 "},"docker/docker-image/dockerfile/user.html":{"url":"docker/docker-image/dockerfile/user.html","title":"USER 指定当前用户","keywords":"","body":"USER 指定当前用户USER 指定当前用户 格式：USER [:] USER 指令和 WORKDIR 相似，都是改变环境状态并影响以后的层。WORKDIR 是改变工作目录，USER 则是改变之后层的执行 RUN, CMD 以及 ENTRYPOINT 这类命令的身份。 注意，USER 只是帮助你切换到指定用户而已，这个用户必须是事先建立好的，否则无法切换。 RUN groupadd -r redis && useradd -r -g redis redis USER redis RUN [ \"redis-server\" ] 如果以 root 执行的脚本，在执行期间希望改变身份，比如希望以某个已经建立好的用户来运行某个服务进程，不要使用 su 或者 sudo，这些都需要比较麻烦的配置，而且在 TTY 缺失的环境下经常出错。建议使用 gosu。 # 建立 redis 用户，并使用 gosu 换另一个用户执行命令 RUN groupadd -r redis && useradd -r -g redis redis # 下载 gosu RUN wget -O /usr/local/bin/gosu \"https://github.com/tianon/gosu/releases/download/1.12/gosu-amd64\" \\ && chmod +x /usr/local/bin/gosu \\ && gosu nobody true # 设置 CMD，并以另外的用户执行 CMD [ \"exec\", \"gosu\", \"redis\", \"redis-server\" ] Copyright © Zhenhai Gao 2021 all right reserved发布时间： 2024-06-10 23:03:15 "},"docker/docker-image/dockerfile/healthcheck.html":{"url":"docker/docker-image/dockerfile/healthcheck.html","title":"HEALTHCHECK 健康检查","keywords":"","body":"HEALTHCHECK 健康检查HEALTHCHECK 健康检查 格式： HEALTHCHECK [选项] CMD ：设置检查容器健康状况的命令 HEALTHCHECK NONE：如果基础镜像有健康检查指令，使用这行可以屏蔽掉其健康检查指令 HEALTHCHECK 指令是告诉 Docker 应该如何进行判断容器的状态是否正常，这是 Docker 1.12 引入的新指令。 在没有 HEALTHCHECK 指令前，Docker 引擎只可以通过容器内主进程是否退出来判断容器是否状态异常。很多情况下这没问题，但是如果程序进入死锁状态，或者死循环状态，应用进程并不退出，但是该容器已经无法提供服务了。在 1.12 以前，Docker 不会检测到容器的这种状态，从而不会重新调度，导致可能会有部分容器已经无法提供服务了却还在接受用户请求。 而自 1.12 之后，Docker 提供了 HEALTHCHECK 指令，通过该指令指定一行命令，用这行命令来判断容器主进程的服务状态是否还正常，从而比较真实的反应容器实际状态。 当在一个镜像指定了 HEALTHCHECK 指令后，用其启动容器，初始状态会为 starting，在 HEALTHCHECK 指令检查成功后变为 healthy，如果连续一定次数失败，则会变为 unhealthy。 HEALTHCHECK 支持下列选项： --interval=：两次健康检查的间隔，默认为 30 秒； --timeout=：健康检查命令运行超时时间，如果超过这个时间，本次健康检查就被视为失败，默认 30 秒； --retries=：当连续失败指定次数后，则将容器状态视为 unhealthy，默认 3 次。 和 CMD, ENTRYPOINT 一样，HEALTHCHECK 只可以出现一次，如果写了多个，只有最后一个生效。 在 HEALTHCHECK [选项] CMD 后面的命令，格式和 ENTRYPOINT 一样，分为 shell 格式，和 exec 格式。命令的返回值决定了该次健康检查的成功与否：0：成功；1：失败；2：保留，不要使用这个值。 假设我们有个镜像是个最简单的 Web 服务，我们希望增加健康检查来判断其 Web 服务是否在正常工作，我们可以用 curl 来帮助判断，其 Dockerfile 的 HEALTHCHECK 可以这么写： FROM nginx RUN apt-get update && apt-get install -y curl && rm -rf /var/lib/apt/lists/* HEALTHCHECK --interval=5s --timeout=3s \\ CMD curl -fs http://localhost/ || exit 1 这里我们设置了每 5 秒检查一次（这里为了试验所以间隔非常短，实际应该相对较长），如果健康检查命令超过 3 秒没响应就视为失败，并且使用 curl -fs http://localhost/ || exit 1 作为健康检查命令。 使用 docker build 来构建这个镜像： $ docker build -t myweb:v1 . 构建好了后，我们启动一个容器： $ docker run -d --name web -p 80:80 myweb:v1 当运行该镜像后，可以通过 docker container ls 看到最初的状态为 (health: starting)： $ docker container ls CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES 03e28eb00bd0 myweb:v1 \"nginx -g 'daemon off\" 3 seconds ago Up 2 seconds (health: starting) 80/tcp, 443/tcp web 在等待几秒钟后，再次 docker container ls，就会看到健康状态变化为了 (healthy)： $ docker container ls CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES 03e28eb00bd0 myweb:v1 \"nginx -g 'daemon off\" 18 seconds ago Up 16 seconds (healthy) 80/tcp, 443/tcp web 如果健康检查连续失败超过了重试次数，状态就会变为 (unhealthy)。 为了帮助排障，健康检查命令的输出（包括 stdout 以及 stderr）都会被存储于健康状态里，可以用 docker inspect 来查看。 $ docker inspect --format '{{json .State.Health}}' web | python -m json.tool { \"FailingStreak\": 0, \"Log\": [ { \"End\": \"2016-11-25T14:35:37.940957051Z\", \"ExitCode\": 0, \"Output\": \"\\n\\n\\nWelcome to nginx!\\n\\n body {\\n width: 35em;\\n margin: 0 auto;\\n font-family: Tahoma, Verdana, Arial, sans-serif;\\n }\\n\\n\\n\\nWelcome to nginx!\\nIf you see this page, the nginx web server is successfully installed and\\nworking. Further configuration is required.\\n\\nFor online documentation and support please refer to\\nnginx.org.\\nCommercial support is available at\\nnginx.com.\\n\\nThank you for using nginx.\\n\\n\\n\", \"Start\": \"2016-11-25T14:35:37.780192565Z\" } ], \"Status\": \"healthy\" } Copyright © Zhenhai Gao 2021 all right reserved发布时间： 2024-06-10 23:03:15 "},"docker/docker-image/dockerfile/onbuild.html":{"url":"docker/docker-image/dockerfile/onbuild.html","title":"ONBUILD 为他人作嫁衣裳","keywords":"","body":"ONBUILD 为他人做嫁衣裳ONBUILD 为他人做嫁衣裳 格式：ONBUILD 。 ONBUILD 是一个特殊的指令，它后面跟的是其它指令，比如 RUN, COPY 等，而这些指令，在当前镜像构建时并不会被执行。只有当以当前镜像为基础镜像，去构建下一级镜像的时候才会被执行。 Dockerfile 中的其它指令都是为了定制当前镜像而准备的，唯有 ONBUILD 是为了帮助别人定制自己而准备的。 假设我们要制作 Node.js 所写的应用的镜像。我们都知道 Node.js 使用 npm 进行包管理，所有依赖、配置、启动信息等会放到 package.json 文件里。在拿到程序代码后，需要先进行 npm install 才可以获得所有需要的依赖。然后就可以通过 npm start 来启动应用。因此，一般来说会这样写 Dockerfile： FROM node:slim RUN mkdir /app WORKDIR /app COPY ./package.json /app RUN [ \"npm\", \"install\" ] COPY . /app/ CMD [ \"npm\", \"start\" ] 把这个 Dockerfile 放到 Node.js 项目的根目录，构建好镜像后，就可以直接拿来启动容器运行。但是如果我们还有第二个 Node.js 项目也差不多呢？好吧，那就再把这个 Dockerfile 复制到第二个项目里。那如果有第三个项目呢？再复制么？文件的副本越多，版本控制就越困难，让我们继续看这样的场景维护的问题。 如果第一个 Node.js 项目在开发过程中，发现这个 Dockerfile 里存在问题，比如敲错字了、或者需要安装额外的包，然后开发人员修复了这个 Dockerfile，再次构建，问题解决。\b第一个项目没问题了，但是第二个项目呢？虽然最初 Dockerfile 是复制、粘贴自第一个项目的，但是并不会因为第一个项目修复了他们的 Dockerfile，而第二个项目的 Dockerfile 就会被自动修复。 那么我们可不可以做一个基础镜像，然后各个项目使用这个基础镜像呢？这样基础镜像更新，各个项目不用同步 Dockerfile 的变化，重新构建后就继承了基础镜像的更新？好吧，可以，让我们看看这样的结果。那么上面的这个 Dockerfile 就会变为： FROM node:slim RUN mkdir /app WORKDIR /app CMD [ \"npm\", \"start\" ] 这里我们把项目相关的构建指令拿出来，放到子项目里去。假设这个基础镜像的名字为 my-node 的话，各个项目内的自己的 Dockerfile 就变为： FROM my-node COPY ./package.json /app RUN [ \"npm\", \"install\" ] COPY . /app/ 基础镜像变化后，各个项目都用这个 Dockerfile 重新构建镜像，会继承基础镜像的更新。 那么，问题解决了么？没有。准确说，只解决了一半。如果这个 Dockerfile 里面有些东西需要调整呢？比如 npm install 都需要加一些参数，那怎么办？这一行 RUN 是不可能放入基础镜像的，因为涉及到了当前项目的 ./package.json，难道又要一个个修改么？所以说，这样制作基础镜像，只解决了原来的 Dockerfile 的前4条指令的变化问题，而后面三条指令的变化则完全没办法处理。 ONBUILD 可以解决这个问题。让我们用 ONBUILD 重新写一下基础镜像的 Dockerfile: FROM node:slim RUN mkdir /app WORKDIR /app ONBUILD COPY ./package.json /app ONBUILD RUN [ \"npm\", \"install\" ] ONBUILD COPY . /app/ CMD [ \"npm\", \"start\" ] 这次我们回到原始的 Dockerfile，但是这次将项目相关的指令加上 ONBUILD，这样在构建基础镜像的时候，这三行并不会被执行。然后各个项目的 Dockerfile 就变成了简单地： FROM my-node 是的，只有这么一行。当在各个项目目录中，用这个只有一行的 Dockerfile 构建镜像时，之前基础镜像的那三行 ONBUILD 就会开始执行，成功的将当前项目的代码复制进镜像、并且针对本项目执行 npm install，生成应用镜像。 Copyright © Zhenhai Gao 2021 all right reserved发布时间： 2024-06-10 23:03:15 "},"docker/docker-image/dockerfile/label.html":{"url":"docker/docker-image/dockerfile/label.html","title":"LABEL 为镜像添加元数据","keywords":"","body":"LABEL 指令LABEL 指令 LABEL 指令用来给镜像以键值对的形式添加一些元数据（metadata）。 LABEL = = = ... 我们还可以用一些标签来申明镜像的作者、文档地址等： LABEL org.opencontainers.image.authors=\"yeasy\" LABEL org.opencontainers.image.documentation=\"https://yeasy.gitbooks.io\" 具体可以参考 https://github.com/opencontainers/image-spec/blob/master/annotations.md Copyright © Zhenhai Gao 2021 all right reserved发布时间： 2024-06-10 23:03:15 "},"docker/docker-image/dockerfile/shell.html":{"url":"docker/docker-image/dockerfile/shell.html","title":"SHELL 指令","keywords":"","body":"SHELL 指令SHELL 指令 格式：SHELL [\"executable\", \"parameters\"] SHELL 指令可以指定 RUN ENTRYPOINT CMD 指令的 shell，Linux 中默认为 [\"/bin/sh\", \"-c\"] SHELL [\"/bin/sh\", \"-c\"] RUN lll ; ls SHELL [\"/bin/sh\", \"-cex\"] RUN lll ; ls 两个 RUN 运行同一命令，第二个 RUN 运行的命令会打印出每条命令并当遇到错误时退出。 当 ENTRYPOINT CMD 以 shell 格式指定时，SHELL 指令所指定的 shell 也会成为这两个指令的 shell SHELL [\"/bin/sh\", \"-cex\"] # /bin/sh -cex \"nginx\" ENTRYPOINT nginx SHELL [\"/bin/sh\", \"-cex\"] # /bin/sh -cex \"nginx\" CMD nginx Copyright © Zhenhai Gao 2021 all right reserved发布时间： 2024-06-10 23:03:15 "},"docker/docker-image/dockerfile/references.html":{"url":"docker/docker-image/dockerfile/references.html","title":"参考文档","keywords":"","body":"参考文档参考文档 Dockerfie 官方文档：https://docs.docker.com/engine/reference/builder/ Dockerfile 最佳实践文档：https://docs.docker.com/develop/develop-images/dockerfile_best-practices/ Docker 官方镜像 Dockerfile：https://github.com/docker-library/docs Copyright © Zhenhai Gao 2021 all right reserved发布时间： 2024-06-10 23:03:15 "},"docker/docker-image/multistage-builds/":{"url":"docker/docker-image/multistage-builds/","title":"Dockerfile 多阶段构建","keywords":"","body":"多阶段构建之前的做法全部放入一个 Dockerfile分散到多个 Dockerfile使用多阶段构建只构建某一阶段的镜像构建时从其他镜像复制文件多阶段构建 之前的做法 在 Docker 17.05 版本之前，我们构建 Docker 镜像时，通常会采用两种方式： 全部放入一个 Dockerfile 一种方式是将所有的构建过程编包含在一个 Dockerfile 中，包括项目及其依赖库的编译、测试、打包等流程，这里可能会带来的一些问题： 镜像层次多，镜像体积较大，部署时间变长 源代码存在泄露的风险 例如，编写 app.go 文件，该程序输出 Hello World! package main import \"fmt\" func main(){ fmt.Printf(\"Hello World!\"); } 编写 Dockerfile.one 文件 FROM golang:alpine RUN apk --no-cache add git ca-certificates WORKDIR /go/src/github.com/go/helloworld/ COPY app.go . RUN go get -d -v github.com/go-sql-driver/mysql \\ && CGO_ENABLED=0 GOOS=linux go build -a -installsuffix cgo -o app . \\ && cp /go/src/github.com/go/helloworld/app /root WORKDIR /root/ CMD [\"./app\"] 构建镜像 $ docker build -t go/helloworld:1 -f Dockerfile.one . 分散到多个 Dockerfile 另一种方式，就是我们事先在一个 Dockerfile 将项目及其依赖库编译测试打包好后，再将其拷贝到运行环境中，这种方式需要我们编写两个 Dockerfile 和一些编译脚本才能将其两个阶段自动整合起来，这种方式虽然可以很好地规避第一种方式存在的风险，但明显部署过程较复杂。 例如，编写 Dockerfile.build 文件 FROM golang:alpine RUN apk --no-cache add git WORKDIR /go/src/github.com/go/helloworld COPY app.go . RUN go get -d -v github.com/go-sql-driver/mysql \\ && CGO_ENABLED=0 GOOS=linux go build -a -installsuffix cgo -o app . 编写 Dockerfile.copy 文件 FROM alpine:latest RUN apk --no-cache add ca-certificates WORKDIR /root/ COPY app . CMD [\"./app\"] 新建 build.sh #!/bin/sh echo Building go/helloworld:build docker build -t go/helloworld:build . -f Dockerfile.build docker create --name extract go/helloworld:build docker cp extract:/go/src/github.com/go/helloworld/app ./app docker rm -f extract echo Building go/helloworld:2 docker build --no-cache -t go/helloworld:2 . -f Dockerfile.copy rm ./app 现在运行脚本即可构建镜像 $ chmod +x build.sh $ ./build.sh 对比两种方式生成的镜像大小 $ docker image ls REPOSITORY TAG IMAGE ID CREATED SIZE go/helloworld 2 f7cf3465432c 22 seconds ago 6.47MB go/helloworld 1 f55d3e16affc 2 minutes ago 295MB 使用多阶段构建 为解决以上问题，Docker v17.05 开始支持多阶段构建 (multistage builds)。使用多阶段构建我们就可以很容易解决前面提到的问题，并且只需要编写一个 Dockerfile： 例如，编写 Dockerfile 文件 FROM golang:alpine as builder RUN apk --no-cache add git WORKDIR /go/src/github.com/go/helloworld/ RUN go get -d -v github.com/go-sql-driver/mysql COPY app.go . RUN CGO_ENABLED=0 GOOS=linux go build -a -installsuffix cgo -o app . FROM alpine:latest as prod RUN apk --no-cache add ca-certificates WORKDIR /root/ COPY --from=0 /go/src/github.com/go/helloworld/app . CMD [\"./app\"] 构建镜像 $ docker build -t go/helloworld:3 . 对比三个镜像大小 $ docker image ls REPOSITORY TAG IMAGE ID CREATED SIZE go/helloworld 3 d6911ed9c846 7 seconds ago 6.47MB go/helloworld 2 f7cf3465432c 22 seconds ago 6.47MB go/helloworld 1 f55d3e16affc 2 minutes ago 295MB 很明显使用多阶段构建的镜像体积小，同时也完美解决了上边提到的问题。 只构建某一阶段的镜像 我们可以使用 as 来为某一阶段命名，例如 FROM golang:alpine as builder 例如当我们只想构建 builder 阶段的镜像时，增加 --target=builder 参数即可 $ docker build --target builder -t username/imagename:tag . 构建时从其他镜像复制文件 上面例子中我们使用 COPY --from=0 /go/src/github.com/go/helloworld/app . 从上一阶段的镜像中复制文件，我们也可以复制任意镜像中的文件。 $ COPY --from=nginx:latest /etc/nginx/nginx.conf /nginx.conf Copyright © Zhenhai Gao 2021 all right reserved发布时间： 2024-06-10 23:03:15 "},"docker/docker-image/multistage-builds/laravel.html":{"url":"docker/docker-image/multistage-builds/laravel.html","title":"实战多阶段构建 Laravel 镜像","keywords":"","body":"实战多阶段构建 Laravel 镜像准备前端构建安装 Composer 依赖整合以上阶段所生成的文件最后一个阶段构建 NGINX 镜像构建 Laravel 及 Nginx 镜像启动容器并测试生产环境优化附录实战多阶段构建 Laravel 镜像 本节适用于 PHP 开发者阅读。Laravel 基于 8.x 版本，各个版本的文件结构可能会有差异，请根据实际自行修改。 准备 新建一个 Laravel 项目或在已有的 Laravel 项目根目录下新建 Dockerfile .dockerignore laravel.conf 文件。 在 .dockerignore 文件中写入以下内容。 .idea/ .git/ vendor/ node_modules/ public/js/ public/css/ public/mix-manifest.json yarn-error.log bootstrap/cache/* storage/ # 自行添加其他需要排除的文件，例如 .env.* 文件 在 laravel.conf 文件中写入 nginx 配置。 server { listen 80 default_server; root /app/laravel/public; index index.php index.html; location / { try_files $uri $uri/ /index.php?$query_string; } location ~ .*\\.php(\\/.*)*$ { fastcgi_pass laravel:9000; include fastcgi.conf; # fastcgi_connect_timeout 300; # fastcgi_send_timeout 300; # fastcgi_read_timeout 300; } } 前端构建 第一阶段进行前端构建。 FROM node:alpine as frontend COPY package.json /app/ RUN set -x ; cd /app \\ && npm install --registry=https://registry.npm.taobao.org COPY webpack.mix.js webpack.config.js tailwind.config.js /app/ COPY resources/ /app/resources/ RUN set -x ; cd /app \\ && touch artisan \\ && mkdir -p public \\ && npm run production 安装 Composer 依赖 第二阶段安装 Composer 依赖。 FROM composer as composer COPY database/ /app/database/ COPY composer.json composer.lock /app/ RUN set -x ; cd /app \\ && composer config -g repo.packagist composer https://mirrors.aliyun.com/composer/ \\ && composer install \\ --ignore-platform-reqs \\ --no-interaction \\ --no-plugins \\ --no-scripts \\ --prefer-dist 整合以上阶段所生成的文件 第三阶段对以上阶段生成的文件进行整合。 FROM php:7.4-fpm-alpine as laravel ARG LARAVEL_PATH=/app/laravel COPY --from=composer /app/vendor/ ${LARAVEL_PATH}/vendor/ COPY . ${LARAVEL_PATH} COPY --from=frontend /app/public/js/ ${LARAVEL_PATH}/public/js/ COPY --from=frontend /app/public/css/ ${LARAVEL_PATH}/public/css/ COPY --from=frontend /app/public/mix-manifest.json ${LARAVEL_PATH}/public/mix-manifest.json RUN set -x ; cd ${LARAVEL_PATH} \\ && mkdir -p storage \\ && mkdir -p storage/framework/cache \\ && mkdir -p storage/framework/sessions \\ && mkdir -p storage/framework/testing \\ && mkdir -p storage/framework/views \\ && mkdir -p storage/logs \\ && chmod -R 777 storage \\ && php artisan package:discover 最后一个阶段构建 NGINX 镜像 FROM nginx:alpine as nginx ARG LARAVEL_PATH=/app/laravel COPY laravel.conf /etc/nginx/conf.d/ COPY --from=laravel ${LARAVEL_PATH}/public ${LARAVEL_PATH}/public 构建 Laravel 及 Nginx 镜像 使用 docker build 命令构建镜像。 $ docker build -t my/laravel --target=laravel . $ docker build -t my/nginx --target=nginx . 启动容器并测试 新建 Docker 网络 $ docker network create laravel 启动 laravel 容器， --name=laravel 参数设定的名字必须与 nginx 配置文件中的 fastcgi_pass laravel:9000; 一致 $ docker run -dit --rm --name=laravel --network=laravel my/laravel 启动 nginx 容器 $ docker run -dit --rm --network=laravel -p 8080:80 my/nginx 浏览器访问 127.0.0.1:8080 可以看到 Laravel 项目首页。 也许 Laravel 项目依赖其他外部服务，例如 redis、MySQL，请自行启动这些服务之后再进行测试，本小节不再赘述。 生产环境优化 本小节内容为了方便测试，将配置文件直接放到了镜像中，实际在使用时 建议 将配置文件作为 config 或 secret 挂载到容器中，请读者自行学习 Swarm mode 或 Kubernetes 的相关内容。 由于篇幅所限本小节只是简单列出，更多内容可以参考 https://github.com/khs1994-docker/laravel-demo 项目。 附录 完整的 Dockerfile 文件如下。 FROM node:alpine as frontend COPY package.json /app/ RUN set -x ; cd /app \\ && npm install --registry=https://registry.npm.taobao.org COPY webpack.mix.js webpack.config.js tailwind.config.js /app/ COPY resources/ /app/resources/ RUN set -x ; cd /app \\ && touch artisan \\ && mkdir -p public \\ && npm run production FROM composer as composer COPY database/ /app/database/ COPY composer.json /app/ RUN set -x ; cd /app \\ && composer config -g repo.packagist composer https://mirrors.aliyun.com/composer/ \\ && composer install \\ --ignore-platform-reqs \\ --no-interaction \\ --no-plugins \\ --no-scripts \\ --prefer-dist FROM php:7.4-fpm-alpine as laravel ARG LARAVEL_PATH=/app/laravel COPY --from=composer /app/vendor/ ${LARAVEL_PATH}/vendor/ COPY . ${LARAVEL_PATH} COPY --from=frontend /app/public/js/ ${LARAVEL_PATH}/public/js/ COPY --from=frontend /app/public/css/ ${LARAVEL_PATH}/public/css/ COPY --from=frontend /app/public/mix-manifest.json ${LARAVEL_PATH}/public/mix-manifest.json RUN set -x ; cd ${LARAVEL_PATH} \\ && mkdir -p storage \\ && mkdir -p storage/framework/cache \\ && mkdir -p storage/framework/sessions \\ && mkdir -p storage/framework/testing \\ && mkdir -p storage/framework/views \\ && mkdir -p storage/logs \\ && chmod -R 777 storage \\ && php artisan package:discover FROM nginx:alpine as nginx ARG LARAVEL_PATH=/app/laravel COPY laravel.conf /etc/nginx/conf.d/ COPY --from=laravel ${LARAVEL_PATH}/public ${LARAVEL_PATH}/public Copyright © Zhenhai Gao 2021 all right reserved发布时间： 2024-06-10 23:03:15 "},"docker/docker-image/manifest.html":{"url":"docker/docker-image/manifest.html","title":"构建多种系统架构支持的 Docker 镜像","keywords":"","body":"构建多种系统架构支持的 Docker 镜像 -- docker manifest 命令详解构建镜像创建 manifest 列表设置 manifest 列表查看 manifest 列表推送 manifest 列表测试官方博客构建多种系统架构支持的 Docker 镜像 -- docker manifest 命令详解 我们知道使用镜像创建一个容器，该镜像必须与 Docker 宿主机系统架构一致，例如 Linux x86_64 架构的系统中只能使用 Linux x86_64 的镜像创建容器。 Windows、macOS 除外，其使用了 binfmt_misc 提供了多种架构支持，在 Windows、macOS 系统上 (x86_64) 可以运行 arm 等其他架构的镜像。 例如我们在 Linux x86_64 中构建一个 username/test 镜像。 FROM alpine CMD echo 1 构建镜像后推送到 Docker Hub，之后我们尝试在树莓派 Linux arm64v8 中使用这个镜像。 $ docker run -it --rm username/test 可以发现这个镜像根本获取不到。 要解决这个问题，通常采用的做法是通过镜像名区分不同系统架构的镜像，例如在 Linux x86_64 和 Linux arm64v8 分别构建 username/test 和 username/arm64v8-test 镜像。运行时使用对应架构的镜像即可。 这样做显得很繁琐，那么有没有一种方法让 Docker 引擎根据系统架构自动拉取对应的镜像呢？ 我们发现在 Linux x86_64 和 Linux arm64v8 架构的计算机中分别使用 golang:alpine 镜像运行容器 $ docker run golang:alpine go version 时，容器能够正常的运行。 这是什么原因呢？ 原因就是 golang:alpine 官方镜像有一个 manifest 列表 (manifest list)。 当用户获取一个镜像时，Docker 引擎会首先查找该镜像是否有 manifest 列表，如果有的话 Docker 引擎会按照 Docker 运行环境（系统及架构）查找出对应镜像（例如 golang:alpine）。如果没有的话会直接获取镜像（例如上例中我们构建的 username/test）。 我们可以使用 $ docker manifest inspect golang:alpine 查看这个 manifest 列表的结构。 $ docker manifest inspect golang:alpine { \"schemaVersion\": 2, \"mediaType\": \"application/vnd.docker.distribution.manifest.list.v2+json\", \"manifests\": [ { \"mediaType\": \"application/vnd.docker.distribution.manifest.v2+json\", \"size\": 1365, \"digest\": \"sha256:5e28ac423243b187f464d635bcfe1e909f4a31c6c8bce51d0db0a1062bec9e16\", \"platform\": { \"architecture\": \"amd64\", \"os\": \"linux\" } }, { \"mediaType\": \"application/vnd.docker.distribution.manifest.v2+json\", \"size\": 1365, \"digest\": \"sha256:2945c46e26c9787da884b4065d1de64cf93a3b81ead1b949843dda1fcd458bae\", \"platform\": { \"architecture\": \"arm\", \"os\": \"linux\", \"variant\": \"v7\" } }, { \"mediaType\": \"application/vnd.docker.distribution.manifest.v2+json\", \"size\": 1365, \"digest\": \"sha256:87fff60114fd3402d0c1a7ddf1eea1ded658f171749b57dc782fd33ee2d47b2d\", \"platform\": { \"architecture\": \"arm64\", \"os\": \"linux\", \"variant\": \"v8\" } }, { \"mediaType\": \"application/vnd.docker.distribution.manifest.v2+json\", \"size\": 1365, \"digest\": \"sha256:607b43f1d91144f82a9433764e85eb3ccf83f73569552a49bc9788c31b4338de\", \"platform\": { \"architecture\": \"386\", \"os\": \"linux\" } }, { \"mediaType\": \"application/vnd.docker.distribution.manifest.v2+json\", \"size\": 1365, \"digest\": \"sha256:25ead0e21ed5e246ce31e274b98c09aaf548606788ef28eaf375dc8525064314\", \"platform\": { \"architecture\": \"ppc64le\", \"os\": \"linux\" } }, { \"mediaType\": \"application/vnd.docker.distribution.manifest.v2+json\", \"size\": 1365, \"digest\": \"sha256:69f5907fa93ea591175b2c688673775378ed861eeb687776669a48692bb9754d\", \"platform\": { \"architecture\": \"s390x\", \"os\": \"linux\" } } ] } 可以看出 manifest 列表中包含了不同系统架构所对应的镜像 digest 值，这样 Docker 就可以在不同的架构中使用相同的 manifest (例如 golang:alpine) 获取对应的镜像。 下面介绍如何使用 $ docker manifest 命令创建并推送 manifest 列表到 Docker Hub。 构建镜像 首先在 Linux x86_64 构建 username/x8664-test 镜像。并在 Linux arm64v8 中构建 username/arm64v8-test 镜像，构建好之后推送到 Docker Hub。 创建 manifest 列表 # $ docker manifest create MANIFEST_LIST MANIFEST [MANIFEST...] $ docker manifest create username/test \\ username/x8664-test \\ username/arm64v8-test 当要修改一个 manifest 列表时，可以加入 -a 或 --amend 参数。 设置 manifest 列表 # $ docker manifest annotate [OPTIONS] MANIFEST_LIST MANIFEST $ docker manifest annotate username/test \\ username/x8664-test \\ --os linux --arch x86_64 $ docker manifest annotate username/test \\ username/arm64v8-test \\ --os linux --arch arm64 --variant v8 这样就配置好了 manifest 列表。 查看 manifest 列表 $ docker manifest inspect username/test 推送 manifest 列表 最后我们可以将其推送到 Docker Hub。 $ docker manifest push username/test 测试 我们在 Linux x86_64 Linux arm64v8 中分别执行 $ docker run -it --rm username/test 命令，发现可以正确的执行。 官方博客 详细了解 manifest 可以阅读官方博客。 https://www.docker.com/blog/multi-arch-all-the-things/ Copyright © Zhenhai Gao 2021 all right reserved发布时间： 2024-06-10 23:03:15 "},"docker/docker-image/other.html":{"url":"docker/docker-image/other.html","title":"其它制作镜像的方式","keywords":"","body":"其它制作镜像的方式从 rootfs 压缩包导入Docker 镜像的导入和导出 docker save 和 docker load保存镜像其它制作镜像的方式 除了标准的使用 Dockerfile 生成镜像的方法外，由于各种特殊需求和历史原因，还提供了一些其它方法用以生成镜像。 从 rootfs 压缩包导入 格式：docker import [选项] ||- [[:]] 压缩包可以是本地文件、远程 Web 文件，甚至是从标准输入中得到。压缩包将会在镜像 / 目录展开，并直接作为镜像第一层提交。 比如我们想要创建一个 OpenVZ 的 Ubuntu 16.04 模板的镜像： $ docker import \\ http://download.openvz.org/template/precreated/ubuntu-16.04-x86_64.tar.gz \\ openvz/ubuntu:16.04 Downloading from http://download.openvz.org/template/precreated/ubuntu-16.04-x86_64.tar.gz sha256:412b8fc3e3f786dca0197834a698932b9c51b69bd8cf49e100c35d38c9879213 这条命令自动下载了 ubuntu-16.04-x86_64.tar.gz 文件，并且作为根文件系统展开导入，并保存为镜像 openvz/ubuntu:16.04。 导入成功后，我们可以用 docker image ls 看到这个导入的镜像： $ docker image ls openvz/ubuntu REPOSITORY TAG IMAGE ID CREATED SIZE openvz/ubuntu 16.04 412b8fc3e3f7 55 seconds ago 505MB 如果我们查看其历史的话，会看到描述中有导入的文件链接： $ docker history openvz/ubuntu:16.04 IMAGE CREATED CREATED BY SIZE COMMENT f477a6e18e98 About a minute ago 214.9 MB Imported from http://download.openvz.org/template/precreated/ubuntu-16.04-x86_64.tar.gz Docker 镜像的导入和导出 docker save 和 docker load Docker 还提供了 docker save 和 docker load 命令，用以将镜像保存为一个文件，然后传输到另一个位置上，再加载进来。这是在没有 Docker Registry 时的做法，现在已经不推荐，镜像迁移应该直接使用 Docker Registry，无论是直接使用 Docker Hub 还是使用内网私有 Registry 都可以。 保存镜像 使用 docker save 命令可以将镜像保存为归档文件。 比如我们希望保存这个 alpine 镜像。 $ docker image ls alpine REPOSITORY TAG IMAGE ID CREATED SIZE alpine latest baa5d63471ea 5 weeks ago 4.803 MB 保存镜像的命令为： $ docker save alpine -o filename $ file filename filename: POSIX tar archive 这里的 filename 可以为任意名称甚至任意后缀名，但文件的本质都是归档文件 注意：如果同名则会覆盖（没有警告） 若使用 gzip 压缩： $ docker save alpine | gzip > alpine-latest.tar.gz 然后我们将 alpine-latest.tar.gz 文件复制到了到了另一个机器上，可以用下面这个命令加载镜像： $ docker load -i alpine-latest.tar.gz Loaded image: alpine:latest 如果我们结合这两个命令以及 ssh 甚至 pv 的话，利用 Linux 强大的管道，我们可以写一个命令完成从一个机器将镜像迁移到另一个机器，并且带进度条的功能： docker save | bzip2 | pv | ssh @ 'cat | docker load' Copyright © Zhenhai Gao 2021 all right reserved发布时间： 2024-06-10 23:03:15 "},"docker/docker-image/internal.html":{"url":"docker/docker-image/internal.html","title":"实现原理","keywords":"","body":"镜像的实现原理镜像的实现原理 Docker 镜像是怎么实现增量的修改和维护的？ 每个镜像都由很多层次构成，Docker 使用 Union FS 将这些不同的层结合到一个镜像中去。 通常 Union FS 有两个用途, 一方面可以实现不借助 LVM、RAID 将多个 disk 挂到同一个目录下,另一个更常用的就是将一个只读的分支和一个可写的分支联合在一起，Live CD 正是基于此方法可以允许在镜像不变的基础上允许用户在其上进行一些写操作。 Docker 在 OverlayFS 上构建的容器也是利用了类似的原理。 Copyright © Zhenhai Gao 2021 all right reserved发布时间： 2024-06-10 23:03:15 "},"docker/container/":{"url":"docker/container/","title":"操作容器","keywords":"","body":"操作 Docker 容器操作 Docker 容器 容器是 Docker 又一核心概念。 简单的说，容器是独立运行的一个或一组应用，以及它们的运行态环境。对应的，虚拟机可以理解为模拟运行的一整套操作系统（提供了运行态环境和其他系统环境）和跑在上面的应用。 本章将具体介绍如何来管理一个容器，包括创建、启动和停止等。 Copyright © Zhenhai Gao 2021 all right reserved发布时间： 2024-06-10 23:03:15 "},"docker/container/run.html":{"url":"docker/container/run.html","title":"启动","keywords":"","body":"启动容器新建并启动启动已终止容器启动容器 启动容器有两种方式，一种是基于镜像新建一个容器并启动，另外一个是将在终止状态（exited）的容器重新启动。 因为 Docker 的容器实在太轻量级了，很多时候用户都是随时删除和新创建容器。 新建并启动 所需要的命令主要为 docker run。 例如，下面的命令输出一个 “Hello World”，之后终止容器。 $ docker run ubuntu:18.04 /bin/echo 'Hello world' Hello world 这跟在本地直接执行 /bin/echo 'hello world' 几乎感觉不出任何区别。 下面的命令则启动一个 bash 终端，允许用户进行交互。 $ docker run -t -i ubuntu:18.04 /bin/bash root@af8bae53bdd3:/# 其中，-t 选项让Docker分配一个伪终端（pseudo-tty）并绑定到容器的标准输入上， -i 则让容器的标准输入保持打开。 在交互模式下，用户可以通过所创建的终端来输入命令，例如 root@af8bae53bdd3:/# pwd / root@af8bae53bdd3:/# ls bin boot dev etc home lib lib64 media mnt opt proc root run sbin srv sys tmp usr var 当利用 docker run 来创建容器时，Docker 在后台运行的标准操作包括： 检查本地是否存在指定的镜像，不存在就从 registry 下载 利用镜像创建并启动一个容器 分配一个文件系统，并在只读的镜像层外面挂载一层可读写层 从宿主主机配置的网桥接口中桥接一个虚拟接口到容器中去 从地址池配置一个 ip 地址给容器 执行用户指定的应用程序 执行完毕后容器被终止 启动已终止容器 可以利用 docker container start 命令，直接将一个已经终止（exited）的容器启动运行。 容器的核心为所执行的应用程序，所需要的资源都是应用程序运行所必需的。除此之外，并没有其它的资源。可以在伪终端中利用 ps 或 top 来查看进程信息。 root@ba267838cc1b:/# ps PID TTY TIME CMD 1 ? 00:00:00 bash 11 ? 00:00:00 ps 可见，容器中仅运行了指定的 bash 应用。这种特点使得 Docker 对资源的利用率极高，是货真价实的轻量级虚拟化。 Copyright © Zhenhai Gao 2021 all right reserved发布时间： 2024-06-10 23:03:15 "},"docker/container/daemon.html":{"url":"docker/container/daemon.html","title":"守护态运行","keywords":"","body":"后台运行后台运行 更多的时候，需要让 Docker 在后台运行而不是直接把执行命令的结果输出在当前宿主机下。此时，可以通过添加 -d 参数来实现。 下面举两个例子来说明一下。 如果不使用 -d 参数运行容器。 $ docker run ubuntu:18.04 /bin/sh -c \"while true; do echo hello world; sleep 1; done\" hello world hello world hello world hello world 容器会把输出的结果 (STDOUT) 打印到宿主机上面 如果使用了 -d 参数运行容器。 $ docker run -d ubuntu:18.04 /bin/sh -c \"while true; do echo hello world; sleep 1; done\" 77b2dc01fe0f3f1265df143181e7b9af5e05279a884f4776ee75350ea9d8017a 此时容器会在后台运行并不会把输出的结果 (STDOUT) 打印到宿主机上面(输出结果可以用 docker logs 查看)。 注： 容器是否会长久运行，是和 docker run 指定的命令有关，和 -d 参数无关。 使用 -d 参数启动后会返回一个唯一的 id，也可以通过 docker container ls 命令来查看容器信息。 $ docker container ls CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES 77b2dc01fe0f ubuntu:18.04 /bin/sh -c 'while tr 2 minutes ago Up 1 minute agitated_wright 要获取容器的输出信息，可以通过 docker container logs 命令。 $ docker container logs [container ID or NAMES] hello world hello world hello world . . . Copyright © Zhenhai Gao 2021 all right reserved发布时间： 2024-06-10 23:03:15 "},"docker/container/stop.html":{"url":"docker/container/stop.html","title":"终止","keywords":"","body":"终止容器终止容器 可以使用 docker container stop 来终止一个运行中的容器。 此外，当 Docker 容器中指定的应用终结时，容器也自动终止。 例如对于上一章节中只启动了一个终端的容器，用户通过 exit 命令或 Ctrl+d 来退出终端时，所创建的容器立刻终止。 终止状态的容器可以用 docker container ls -a 命令看到。例如 $ docker container ls -a CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES ba267838cc1b ubuntu:18.04 \"/bin/bash\" 30 minutes ago Exited (0) About a minute ago trusting_newton 处于终止状态的容器，可以通过 docker container start 命令来重新启动。 此外，docker container restart 命令会将一个运行态的容器终止，然后再重新启动它。 Copyright © Zhenhai Gao 2021 all right reserved发布时间： 2024-06-10 23:03:15 "},"docker/container/attach-exec.html":{"url":"docker/container/attach-exec.html","title":"进入容器","keywords":"","body":"进入容器attach 命令exec 命令-i -t 参数进入容器 在使用 -d 参数时，容器启动后会进入后台。 某些时候需要进入容器进行操作，包括使用 docker attach 命令或 docker exec 命令，推荐大家使用 docker exec 命令，原因会在下面说明。 attach 命令 下面示例如何使用 docker attach 命令。 $ docker run -dit ubuntu 243c32535da7d142fb0e6df616a3c3ada0b8ab417937c853a9e1c251f499f550 $ docker container ls CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES 243c32535da7 ubuntu:latest \"/bin/bash\" 18 seconds ago Up 17 seconds nostalgic_hypatia $ docker attach 243c root@243c32535da7:/# 注意： 如果从这个 stdin 中 exit，会导致容器的停止。 exec 命令 -i -t 参数 docker exec 后边可以跟多个参数，这里主要说明 -i -t 参数。 只用 -i 参数时，由于没有分配伪终端，界面没有我们熟悉的 Linux 命令提示符，但命令执行结果仍然可以返回。 当 -i -t 参数一起使用时，则可以看到我们熟悉的 Linux 命令提示符。 $ docker run -dit ubuntu 69d137adef7a8a689cbcb059e94da5489d3cddd240ff675c640c8d96e84fe1f6 $ docker container ls CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES 69d137adef7a ubuntu:latest \"/bin/bash\" 18 seconds ago Up 17 seconds zealous_swirles $ docker exec -i 69d1 bash ls bin boot dev ... $ docker exec -it 69d1 bash root@69d137adef7a:/# 如果从这个 stdin 中 exit，不会导致容器的停止。这就是为什么推荐大家使用 docker exec 的原因。 更多参数说明请使用 docker exec --help 查看。 Copyright © Zhenhai Gao 2021 all right reserved发布时间： 2024-06-10 23:03:15 "},"docker/container/import-export.html":{"url":"docker/container/import-export.html","title":"导出和导入","keywords":"","body":"导出和导入容器导出容器导入容器快照导出和导入容器 导出容器 如果要导出本地某个容器，可以使用 docker export 命令。 $ docker container ls -a CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES 7691a814370e ubuntu:18.04 \"/bin/bash\" 36 hours ago Exited (0) 21 hours ago test $ docker export 7691a814370e > ubuntu.tar 这样将导出容器快照到本地文件。 导入容器快照 可以使用 docker import 从容器快照文件中再导入为镜像，例如 $ cat ubuntu.tar | docker import - test/ubuntu:v1.0 $ docker image ls REPOSITORY TAG IMAGE ID CREATED VIRTUAL SIZE test/ubuntu v1.0 9d37a6082e97 About a minute ago 171.3 MB 此外，也可以通过指定 URL 或者某个目录来导入，例如 $ docker import http://example.com/exampleimage.tgz example/imagerepo 注：用户既可以使用 docker load 来导入镜像存储文件到本地镜像库，也可以使用 docker import 来导入一个容器快照到本地镜像库。这两者的区别在于容器快照文件将丢弃所有的历史记录和元数据信息（即仅保存容器当时的快照状态），而镜像存储文件将保存完整记录，体积也要大。此外，从容器快照文件导入时可以重新指定标签等元数据信息。 Copyright © Zhenhai Gao 2021 all right reserved发布时间： 2024-06-10 23:03:15 "},"docker/container/rm.html":{"url":"docker/container/rm.html","title":"删除","keywords":"","body":"删除容器清理所有处于终止状态的容器删除容器 可以使用 docker container rm 来删除一个处于终止状态的容器。例如 $ docker container rm trusting_newton trusting_newton 如果要删除一个运行中的容器，可以添加 -f 参数。Docker 会发送 SIGKILL 信号给容器。 清理所有处于终止状态的容器 用 docker container ls -a 命令可以查看所有已经创建的包括终止状态的容器，如果数量太多要一个个删除可能会很麻烦，用下面的命令可以清理掉所有处于终止状态的容器。 $ docker container prune Copyright © Zhenhai Gao 2021 all right reserved发布时间： 2024-06-10 23:03:15 "},"docker/repository/":{"url":"docker/repository/","title":"访问仓库","keywords":"","body":"访问仓库访问仓库 仓库（Repository）是集中存放镜像的地方。 一个容易混淆的概念是注册服务器（Registry）。实际上注册服务器是管理仓库的具体服务器，每个服务器上可以有多个仓库，而每个仓库下面有多个镜像。从这方面来说，仓库可以被认为是一个具体的项目或目录。例如对于仓库地址 docker.io/ubuntu 来说，docker.io 是注册服务器地址，ubuntu 是仓库名。 大部分时候，并不需要严格区分这两者的概念。 Copyright © Zhenhai Gao 2021 all right reserved发布时间： 2024-06-10 23:03:15 "},"docker/repository/dockerhub.html":{"url":"docker/repository/dockerhub.html","title":"Docker Hub","keywords":"","body":"Docker Hub注册登录拉取镜像推送镜像自动构建Docker Hub 目前 Docker 官方维护了一个公共仓库 Docker Hub，其中已经包括了数量超过 2,650,000 的镜像。大部分需求都可以通过在 Docker Hub 中直接下载镜像来实现。 注册 你可以在 https://hub.docker.com 免费注册一个 Docker 账号。 登录 可以通过执行 docker login 命令交互式的输入用户名及密码来完成在命令行界面登录 Docker Hub。 你可以通过 docker logout 退出登录。 拉取镜像 你可以通过 docker search 命令来查找官方仓库中的镜像，并利用 docker pull 命令来将它下载到本地。 例如以 centos 为关键词进行搜索： $ docker search centos NAME DESCRIPTION STARS OFFICIAL AUTOMATED centos The official build of CentOS. 6449 [OK] ansible/centos7-ansible Ansible on Centos7 132 [OK] consol/centos-xfce-vnc Centos container with \"headless\" VNC session… 126 [OK] jdeathe/centos-ssh OpenSSH / Supervisor / EPEL/IUS/SCL Repos - … 117 [OK] centos/systemd systemd enabled base container. 96 [OK] 可以看到返回了很多包含关键字的镜像，其中包括镜像名字、描述、收藏数（表示该镜像的受关注程度）、是否官方创建（OFFICIAL）、是否自动构建 （AUTOMATED）。 根据是否是官方提供，可将镜像分为两类。 一种是类似 centos 这样的镜像，被称为基础镜像或根镜像。这些基础镜像由 Docker 公司创建、验证、支持、提供。这样的镜像往往使用单个单词作为名字。 还有一种类型，比如 ansible/centos7-ansible 镜像，它是由 Docker Hub 的注册用户创建并维护的，往往带有用户名称前缀。可以通过前缀 username/ 来指定使用某个用户提供的镜像，比如 ansible 用户。 另外，在查找的时候通过 --filter=stars=N 参数可以指定仅显示收藏数量为 N 以上的镜像。 下载官方 centos 镜像到本地。 $ docker pull centos Using default tag: latest latest: Pulling from library/centos 7a0437f04f83: Pull complete Digest: sha256:5528e8b1b1719d34604c87e11dcd1c0a20bedf46e83b5632cdeac91b8c04efc1 Status: Downloaded newer image for centos:latest docker.io/library/centos:latest 推送镜像 用户也可以在登录后通过 docker push 命令来将自己的镜像推送到 Docker Hub。 以下命令中的 username 请替换为你的 Docker 账号用户名。 $ docker tag ubuntu:18.04 username/ubuntu:18.04 $ docker image ls REPOSITORY TAG IMAGE ID CREATED SIZE ubuntu 18.04 275d79972a86 6 days ago 94.6MB username/ubuntu 18.04 275d79972a86 6 days ago 94.6MB $ docker push username/ubuntu:18.04 $ docker search username NAME DESCRIPTION STARS OFFICIAL AUTOMATED username/ubuntu 自动构建 2021 年 6 月 18 日之后，该项功能仅限付费用户使用。 自动构建（Automated Builds）功能对于需要经常升级镜像内程序来说，十分方便。 有时候，用户构建了镜像，安装了某个软件，当软件发布新版本则需要手动更新镜像。 而自动构建允许用户通过 Docker Hub 指定跟踪一个目标网站（支持 GitHub 或 BitBucket）上的项目，一旦项目发生新的提交 （commit）或者创建了新的标签（tag），Docker Hub 会自动构建镜像并推送到 Docker Hub 中。 要配置自动构建，包括如下的步骤： 登录 Docker Hub； 在 Docker Hub 点击右上角头像，在账号设置（Account Settings）中关联（Linked Accounts）目标网站； 在 Docker Hub 中新建或选择已有的仓库，在 Builds 选项卡中选择 Configure Automated Builds； 选取一个目标网站中的项目（需要含 Dockerfile）和分支； 指定 Dockerfile 的位置，并保存。 之后，可以在 Docker Hub 的仓库页面的 Timeline 选项卡中查看每次构建的状态。 Copyright © Zhenhai Gao 2021 all right reserved发布时间： 2024-06-10 23:03:15 "},"docker/repository/registry.html":{"url":"docker/repository/registry.html","title":"私有仓库","keywords":"","body":"私有仓库安装运行 docker-registry容器运行在私有仓库上传、搜索、下载镜像配置非 https 仓库地址Ubuntu 16.04+, Debian 8+, centos 7其他私有仓库 有时候使用 Docker Hub 这样的公共仓库可能不方便，用户可以创建一个本地仓库供私人使用。 本节介绍如何使用本地仓库。 docker-registry 是官方提供的工具，可以用于构建私有的镜像仓库。本文内容基于 docker-registry v2.x 版本。 安装运行 docker-registry 容器运行 你可以使用官方 registry 镜像来运行。 $ docker run -d -p 5000:5000 --restart=always --name registry registry 这将使用官方的 registry 镜像来启动私有仓库。默认情况下，仓库会被创建在容器的 /var/lib/registry 目录下。你可以通过 -v 参数来将镜像文件存放在本地的指定路径。例如下面的例子将上传的镜像放到本地的 /opt/data/registry 目录。 $ docker run -d \\ -p 5000:5000 \\ -v /opt/data/registry:/var/lib/registry \\ registry 在私有仓库上传、搜索、下载镜像 创建好私有仓库之后，就可以使用 docker tag 来标记一个镜像，然后推送它到仓库。例如私有仓库地址为 127.0.0.1:5000。 先在本机查看已有的镜像。 $ docker image ls REPOSITORY TAG IMAGE ID CREATED VIRTUAL SIZE ubuntu latest ba5877dc9bec 6 weeks ago 192.7 MB 使用 docker tag 将 ubuntu:latest 这个镜像标记为 127.0.0.1:5000/ubuntu:latest。 格式为 docker tag IMAGE[:TAG] [REGISTRY_HOST[:REGISTRY_PORT]/]REPOSITORY[:TAG]。 $ docker tag ubuntu:latest 127.0.0.1:5000/ubuntu:latest $ docker image ls REPOSITORY TAG IMAGE ID CREATED VIRTUAL SIZE ubuntu latest ba5877dc9bec 6 weeks ago 192.7 MB 127.0.0.1:5000/ubuntu:latest latest ba5877dc9bec 6 weeks ago 192.7 MB 使用 docker push 上传标记的镜像。 $ docker push 127.0.0.1:5000/ubuntu:latest The push refers to repository [127.0.0.1:5000/ubuntu] 373a30c24545: Pushed a9148f5200b0: Pushed cdd3de0940ab: Pushed fc56279bbb33: Pushed b38367233d37: Pushed 2aebd096e0e2: Pushed latest: digest: sha256:fe4277621f10b5026266932ddf760f5a756d2facd505a94d2da12f4f52f71f5a size: 1568 用 curl 查看仓库中的镜像。 $ curl 127.0.0.1:5000/v2/_catalog {\"repositories\":[\"ubuntu\"]} 这里可以看到 {\"repositories\":[\"ubuntu\"]}，表明镜像已经被成功上传了。 先删除已有镜像，再尝试从私有仓库中下载这个镜像。 $ docker image rm 127.0.0.1:5000/ubuntu:latest $ docker pull 127.0.0.1:5000/ubuntu:latest Pulling repository 127.0.0.1:5000/ubuntu:latest ba5877dc9bec: Download complete 511136ea3c5a: Download complete 9bad880da3d2: Download complete 25f11f5fb0cb: Download complete ebc34468f71d: Download complete 2318d26665ef: Download complete $ docker image ls REPOSITORY TAG IMAGE ID CREATED VIRTUAL SIZE 127.0.0.1:5000/ubuntu:latest latest ba5877dc9bec 6 weeks ago 192.7 MB 配置非 https 仓库地址 如果你不想使用 127.0.0.1:5000 作为仓库地址，比如想让本网段的其他主机也能把镜像推送到私有仓库。你就得把例如 192.168.199.100:5000 这样的内网地址作为私有仓库地址，这时你会发现无法成功推送镜像。 这是因为 Docker 默认不允许非 HTTPS 方式推送镜像。我们可以通过 Docker 的配置选项来取消这个限制，或者查看下一节配置能够通过 HTTPS 访问的私有仓库。 Ubuntu 16.04+, Debian 8+, centos 7 对于使用 systemd 的系统，请在 /etc/docker/daemon.json 中写入如下内容（如果文件不存在请新建该文件） { \"registry-mirror\": [ \"https://hub-mirror.c.163.com\", \"https://mirror.baidubce.com\" ], \"insecure-registries\": [ \"192.168.199.100:5000\" ] } 注意：该文件必须符合 json 规范，否则 Docker 将不能启动。 其他 对于 Docker Desktop for Windows 、 Docker Desktop for Mac 在设置中的 Docker Engine 中进行编辑 ，增加和上边一样的字符串即可。 Copyright © Zhenhai Gao 2021 all right reserved发布时间： 2024-06-10 23:03:15 "},"docker/repository/registry-auth.html":{"url":"docker/repository/registry-auth.html","title":"私有仓库高级配置","keywords":"","body":"私有仓库高级配置准备站点证书配置私有仓库生成 http 认证文件编辑 docker-compose.yml修改 hosts启动测试私有仓库功能注意事项私有仓库高级配置 上一节我们搭建了一个具有基础功能的私有仓库，本小节我们来使用 Docker Compose 搭建一个拥有权限认证、TLS 的私有仓库。 新建一个文件夹，以下步骤均在该文件夹中进行。 准备站点证书 如果你拥有一个域名，国内各大云服务商均提供免费的站点证书。你也可以使用 openssl 自行签发证书。 这里假设我们将要搭建的私有仓库地址为 docker.domain.com，下面我们介绍使用 openssl 自行签发 docker.domain.com 的站点 SSL 证书。 第一步创建 CA 私钥。 $ openssl genrsa -out \"root-ca.key\" 4096 第二步利用私钥创建 CA 根证书请求文件。 $ openssl req \\ -new -key \"root-ca.key\" \\ -out \"root-ca.csr\" -sha256 \\ -subj '/C=CN/ST=Shanxi/L=Datong/O=Your Company Name/CN=Your Company Name Docker Registry CA' 以上命令中 -subj 参数里的 /C 表示国家，如 CN；/ST 表示省；/L 表示城市或者地区；/O 表示组织名；/CN 通用名称。 第三步配置 CA 根证书，新建 root-ca.cnf。 [root_ca] basicConstraints = critical,CA:TRUE,pathlen:1 keyUsage = critical, nonRepudiation, cRLSign, keyCertSign subjectKeyIdentifier=hash 第四步签发根证书。 $ openssl x509 -req -days 3650 -in \"root-ca.csr\" \\ -signkey \"root-ca.key\" -sha256 -out \"root-ca.crt\" \\ -extfile \"root-ca.cnf\" -extensions \\ root_ca 第五步生成站点 SSL 私钥。 $ openssl genrsa -out \"docker.domain.com.key\" 4096 第六步使用私钥生成证书请求文件。 $ openssl req -new -key \"docker.domain.com.key\" -out \"site.csr\" -sha256 \\ -subj '/C=CN/ST=Shanxi/L=Datong/O=Your Company Name/CN=docker.domain.com' 第七步配置证书，新建 site.cnf 文件。 [server] authorityKeyIdentifier=keyid,issuer basicConstraints = critical,CA:FALSE extendedKeyUsage=serverAuth keyUsage = critical, digitalSignature, keyEncipherment subjectAltName = DNS:docker.domain.com, IP:127.0.0.1 subjectKeyIdentifier=hash 第八步签署站点 SSL 证书。 $ openssl x509 -req -days 750 -in \"site.csr\" -sha256 \\ -CA \"root-ca.crt\" -CAkey \"root-ca.key\" -CAcreateserial \\ -out \"docker.domain.com.crt\" -extfile \"site.cnf\" -extensions server 这样已经拥有了 docker.domain.com 的网站 SSL 私钥 docker.domain.com.key 和 SSL 证书 docker.domain.com.crt 及 CA 根证书 root-ca.crt。 新建 ssl 文件夹并将 docker.domain.com.key docker.domain.com.crt root-ca.crt 这三个文件移入，删除其他文件。 配置私有仓库 私有仓库默认的配置文件位于 /etc/docker/registry/config.yml，我们先在本地编辑 config.yml，之后挂载到容器中。 version: 0.1 log: accesslog: disabled: true level: debug formatter: text fields: service: registry environment: staging storage: delete: enabled: true cache: blobdescriptor: inmemory filesystem: rootdirectory: /var/lib/registry auth: htpasswd: realm: basic-realm path: /etc/docker/registry/auth/nginx.htpasswd http: addr: :443 host: https://docker.domain.com headers: X-Content-Type-Options: [nosniff] http2: disabled: false tls: certificate: /etc/docker/registry/ssl/docker.domain.com.crt key: /etc/docker/registry/ssl/docker.domain.com.key health: storagedriver: enabled: true interval: 10s threshold: 3 生成 http 认证文件 $ mkdir auth $ docker run --rm \\ --entrypoint htpasswd \\ httpd:alpine \\ -Bbn username password > auth/nginx.htpasswd 将上面的 username password 替换为你自己的用户名和密码。 编辑 docker-compose.yml version: '3' services: registry: image: registry ports: - \"443:443\" volumes: - ./:/etc/docker/registry - registry-data:/var/lib/registry volumes: registry-data: 修改 hosts 编辑 /etc/hosts 127.0.0.1 docker.domain.com 启动 $ docker-compose up -d 这样我们就搭建好了一个具有权限认证、TLS 的私有仓库，接下来我们测试其功能是否正常。 测试私有仓库功能 由于自行签发的 CA 根证书不被系统信任，所以我们需要将 CA 根证书 ssl/root-ca.crt 移入 /etc/docker/certs.d/docker.domain.com 文件夹中。 $ sudo mkdir -p /etc/docker/certs.d/docker.domain.com $ sudo cp ssl/root-ca.crt /etc/docker/certs.d/docker.domain.com/ca.crt 登录到私有仓库。 $ docker login docker.domain.com 尝试推送、拉取镜像。 $ docker pull ubuntu:18.04 $ docker tag ubuntu:18.04 docker.domain.com/username/ubuntu:18.04 $ docker push docker.domain.com/username/ubuntu:18.04 $ docker image rm docker.domain.com/username/ubuntu:18.04 $ docker pull docker.domain.com/username/ubuntu:18.04 如果我们退出登录，尝试推送镜像。 $ docker logout docker.domain.com $ docker push docker.domain.com/username/ubuntu:18.04 no basic auth credentials 发现会提示没有登录，不能将镜像推送到私有仓库中。 注意事项 如果你本机占用了 443 端口，你可以配置 Nginx 代理，这里不再赘述。 Copyright © Zhenhai Gao 2021 all right reserved发布时间： 2024-06-10 23:03:15 "},"docker/repository/nexus3-registry.html":{"url":"docker/repository/nexus3-registry.html","title":"Nexus 3","keywords":"","body":"Nexus3.x 的私有仓库启动 Nexus 容器创建仓库添加访问权限NGINX 加密代理Docker 主机访问镜像仓库Nexus3.x 的私有仓库 使用 Docker 官方的 Registry 创建的仓库面临一些维护问题。比如某些镜像删除以后空间默认是不会回收的，需要一些命令去回收空间然后重启 Registry。在企业中把内部的一些工具包放入 Nexus 中是比较常见的做法，最新版本 Nexus3.x 全面支持 Docker 的私有镜像。所以使用 Nexus3.x 一个软件来管理 Docker , Maven , Yum , PyPI 等是一个明智的选择。 启动 Nexus 容器 $ docker run -d --name nexus3 --restart=always \\ -p 8081:8081 \\ --mount src=nexus-data,target=/nexus-data \\ sonatype/nexus3 首次运行需等待 3-5 分钟，你可以使用 docker logs nexus3 -f 查看日志： $ docker logs nexus3 -f 2021-03-11 15:31:21,990+0000 INFO [jetty-main-1] *SYSTEM org.sonatype.nexus.bootstrap.jetty.JettyServer - ------------------------------------------------- Started Sonatype Nexus OSS 3.30.0-01 ------------------------------------------------- 如果你看到以上内容，说明 Nexus 已经启动成功，你可以使用浏览器打开 http://YourIP:8081 访问 Nexus 了。 首次运行请通过以下命令获取初始密码： $ docker exec nexus3 cat /nexus-data/admin.password 9266139e-41a2-4abb-92ec-e4142a3532cb 首次启动 Nexus 的默认帐号是 admin ，密码则是上边命令获取到的，点击右上角登录，首次登录需更改初始密码。 登录之后可以点击页面上方的齿轮按钮按照下面的方法进行设置。 创建仓库 创建一个私有仓库的方法： Repository->Repositories 点击右边菜单 Create repository 选择 docker (hosted) Name: 仓库的名称 HTTP: 仓库单独的访问端口（例如：5001） Hosted -> Deployment pollcy: 请选择 Allow redeploy 否则无法上传 Docker 镜像。 其它的仓库创建方法请各位自己摸索，还可以创建一个 docker (proxy) 类型的仓库链接到 DockerHub 上。再创建一个 docker (group) 类型的仓库把刚才的 hosted 与 proxy 添加在一起。主机在访问的时候默认下载私有仓库中的镜像，如果没有将链接到 DockerHub 中下载并缓存到 Nexus 中。 添加访问权限 菜单 Security->Realms 把 Docker Bearer Token Realm 移到右边的框中保存。 添加用户规则：菜单 Security->Roles->Create role 在 Privlleges 选项搜索 docker 把相应的规则移动到右边的框中然后保存。 添加用户：菜单 Security->Users->Create local user 在 Roles 选项中选中刚才创建的规则移动到右边的窗口保存。 NGINX 加密代理 证书的生成请参见 私有仓库高级配置 里面证书生成一节。 NGINX 示例配置如下 upstream register { server \"YourHostName OR IP\":5001; #端口为上面添加私有镜像仓库时设置的 HTTP 选项的端口号 check interval=3000 rise=2 fall=10 timeout=1000 type=http; check_http_send \"HEAD / HTTP/1.0\\r\\n\\r\\n\"; check_http_expect_alive http_4xx; } server { server_name YourDomainName;#如果没有 DNS 服务器做解析，请删除此选项使用本机 IP 地址访问 listen 443 ssl; ssl_certificate key/example.crt; ssl_certificate_key key/example.key; ssl_session_timeout 5m; ssl_protocols TLSv1 TLSv1.1 TLSv1.2; ssl_ciphers HIGH:!aNULL:!MD5; ssl_prefer_server_ciphers on; large_client_header_buffers 4 32k; client_max_body_size 300m; client_body_buffer_size 512k; proxy_connect_timeout 600; proxy_read_timeout 600; proxy_send_timeout 600; proxy_buffer_size 128k; proxy_buffers 4 64k; proxy_busy_buffers_size 128k; proxy_temp_file_write_size 512k; location / { proxy_set_header Host $host; proxy_set_header X-Forwarded-Proto $scheme; proxy_set_header X-Forwarded-Port $server_port; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; proxy_http_version 1.1; proxy_set_header Upgrade $http_upgrade; proxy_set_header Connection $connection_upgrade; proxy_redirect off; proxy_set_header X-Real-IP $remote_addr; proxy_pass http://register; proxy_read_timeout 900s; } error_page 500 502 503 504 /50x.html; } Docker 主机访问镜像仓库 如果不启用 SSL 加密可以通过 前面章节 的方法添加非 https 仓库地址到 Docker 的配置文件中然后重启 Docker。 使用 SSL 加密以后程序需要访问就不能采用修改配置的方式了。具体方法如下： $ openssl s_client -showcerts -connect YourDomainName OR HostIP:443 /dev/null|openssl x509 -outform PEM >ca.crt $ cat ca.crt | sudo tee -a /etc/ssl/certs/ca-certificates.crt $ systemctl restart docker 使用 docker login YourDomainName OR HostIP 进行测试，用户名密码填写上面 Nexus 中设置的。 Copyright © Zhenhai Gao 2021 all right reserved发布时间： 2024-06-10 23:03:15 "},"docker/data-management/":{"url":"docker/data-management/","title":"数据管理","keywords":"","body":"Docker 数据管理Docker 数据管理 这一章介绍如何在 Docker 内部以及容器之间管理数据，在容器中管理数据主要有两种方式： 数据卷（Volumes） 挂载主机目录 (Bind mounts) Copyright © Zhenhai Gao 2021 all right reserved发布时间： 2024-06-10 23:03:15 "},"docker/data-management/volume.html":{"url":"docker/data-management/volume.html","title":"数据卷","keywords":"","body":"数据卷创建一个数据卷启动一个挂载数据卷的容器查看数据卷的具体信息删除数据卷数据卷 数据卷 是一个可供一个或多个容器使用的特殊目录，它绕过 UFS，可以提供很多有用的特性： 数据卷 可以在容器之间共享和重用 对 数据卷 的修改会立马生效 对 数据卷 的更新，不会影响镜像 数据卷 默认会一直存在，即使容器被删除 注意：数据卷 的使用，类似于 Linux 下对目录或文件进行 mount，镜像中的被指定为挂载点的目录中的文件会复制到数据卷中（仅数据卷为空时会复制）。 创建一个数据卷 $ docker volume create my-vol 查看所有的 数据卷 $ docker volume ls DRIVER VOLUME NAME local my-vol 在主机里使用以下命令可以查看指定 数据卷 的信息 $ docker volume inspect my-vol [ { \"Driver\": \"local\", \"Labels\": {}, \"Mountpoint\": \"/var/lib/docker/volumes/my-vol/_data\", \"Name\": \"my-vol\", \"Options\": {}, \"Scope\": \"local\" } ] 启动一个挂载数据卷的容器 在用 docker run 命令的时候，使用 --mount 标记来将 数据卷 挂载到容器里。在一次 docker run 中可以挂载多个 数据卷。 下面创建一个名为 web 的容器，并加载一个 数据卷 到容器的 /usr/share/nginx/html 目录。 $ docker run -d -P \\ --name web \\ # -v my-vol:/usr/share/nginx/html \\ --mount source=my-vol,target=/usr/share/nginx/html \\ nginx:alpine 查看数据卷的具体信息 在主机里使用以下命令可以查看 web 容器的信息 $ docker inspect web 数据卷 信息在 \"Mounts\" Key 下面 \"Mounts\": [ { \"Type\": \"volume\", \"Name\": \"my-vol\", \"Source\": \"/var/lib/docker/volumes/my-vol/_data\", \"Destination\": \"/usr/share/nginx/html\", \"Driver\": \"local\", \"Mode\": \"\", \"RW\": true, \"Propagation\": \"\" } ], 删除数据卷 $ docker volume rm my-vol 数据卷 是被设计用来持久化数据的，它的生命周期独立于容器，Docker 不会在容器被删除后自动删除 数据卷，并且也不存在垃圾回收这样的机制来处理没有任何容器引用的 数据卷。如果需要在删除容器的同时移除数据卷。可以在删除容器的时候使用 docker rm -v 这个命令。 无主的数据卷可能会占据很多空间，要清理请使用以下命令 $ docker volume prune Copyright © Zhenhai Gao 2021 all right reserved发布时间： 2024-06-10 23:03:15 "},"docker/data-management/bind-mounts.html":{"url":"docker/data-management/bind-mounts.html","title":"挂载主机目录","keywords":"","body":"挂载主机目录挂载一个主机目录作为数据卷查看数据卷的具体信息挂载一个本地主机文件作为数据卷挂载主机目录 挂载一个主机目录作为数据卷 使用 --mount 标记可以指定挂载一个本地主机的目录到容器中去。 $ docker run -d -P \\ --name web \\ # -v /src/webapp:/usr/share/nginx/html \\ --mount type=bind,source=/src/webapp,target=/usr/share/nginx/html \\ nginx:alpine 上面的命令加载主机的 /src/webapp 目录到容器的 /usr/share/nginx/html目录。这个功能在进行测试的时候十分方便，比如用户可以放置一些程序到本地目录中，来查看容器是否正常工作。本地目录的路径必须是绝对路径，以前使用 -v 参数时如果本地目录不存在 Docker 会自动为你创建一个文件夹，现在使用 --mount 参数时如果本地目录不存在，Docker 会报错。 Docker 挂载主机目录的默认权限是 读写，用户也可以通过增加 readonly 指定为 只读。 $ docker run -d -P \\ --name web \\ # -v /src/webapp:/usr/share/nginx/html:ro \\ --mount type=bind,source=/src/webapp,target=/usr/share/nginx/html,readonly \\ nginx:alpine 加了 readonly 之后，就挂载为 只读 了。如果你在容器内 /usr/share/nginx/html 目录新建文件，会显示如下错误 /usr/share/nginx/html # touch new.txt touch: new.txt: Read-only file system 查看数据卷的具体信息 在主机里使用以下命令可以查看 web 容器的信息 $ docker inspect web 挂载主机目录 的配置信息在 \"Mounts\" Key 下面 \"Mounts\": [ { \"Type\": \"bind\", \"Source\": \"/src/webapp\", \"Destination\": \"/usr/share/nginx/html\", \"Mode\": \"\", \"RW\": true, \"Propagation\": \"rprivate\" } ], 挂载一个本地主机文件作为数据卷 --mount 标记也可以从主机挂载单个文件到容器中 $ docker run --rm -it \\ # -v $HOME/.bash_history:/root/.bash_history \\ --mount type=bind,source=$HOME/.bash_history,target=/root/.bash_history \\ ubuntu:18.04 \\ bash root@2affd44b4667:/# history 1 ls 2 diskutil list 这样就可以记录在容器输入过的命令了。 Copyright © Zhenhai Gao 2021 all right reserved发布时间： 2024-06-10 23:03:15 "},"docker/network/":{"url":"docker/network/","title":"使用网络","keywords":"","body":"Docker 中的网络功能介绍Docker 中的网络功能介绍 Docker 允许通过外部访问容器或容器互联的方式来提供网络服务。 Copyright © Zhenhai Gao 2021 all right reserved发布时间： 2024-06-10 23:03:15 "},"docker/network/port-mapping.html":{"url":"docker/network/port-mapping.html","title":"外部访问容器","keywords":"","body":"外部访问容器映射所有接口地址映射到指定地址的指定端口映射到指定地址的任意端口查看映射端口配置外部访问容器 容器中可以运行一些网络应用，要让外部也可以访问这些应用，可以通过 -P 或 -p 参数来指定端口映射。 当使用 -P 标记时，Docker 会随机映射一个端口到内部容器开放的网络端口。 使用 docker container ls 可以看到，本地主机的 32768 被映射到了容器的 80 端口。此时访问本机的 32768 端口即可访问容器内 NGINX 默认页面。 $ docker run -d -P nginx:alpine $ docker container ls -l CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES fae320d08268 nginx:alpine \"/docker-entrypoint.…\" 24 seconds ago Up 20 seconds 0.0.0.0:32768->80/tcp bold_mcnulty 同样的，可以通过 docker logs 命令来查看访问记录。 $ docker logs fa 172.17.0.1 - - [25/Aug/2020:08:34:04 +0000] \"GET / HTTP/1.1\" 200 612 \"-\" \"Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:80.0) Gecko/20100101 Firefox/80.0\" \"-\" -p 则可以指定要映射的端口，并且，在一个指定端口上只可以绑定一个容器。支持的格式有 ip:hostPort:containerPort | ip::containerPort | hostPort:containerPort。 映射所有接口地址 使用 hostPort:containerPort 格式本地的 80 端口映射到容器的 80 端口，可以执行 $ docker run -d -p 80:80 nginx:alpine 此时默认会绑定本地所有接口上的所有地址。 映射到指定地址的指定端口 可以使用 ip:hostPort:containerPort 格式指定映射使用一个特定地址，比如 localhost 地址 127.0.0.1 $ docker run -d -p 127.0.0.1:80:80 nginx:alpine 映射到指定地址的任意端口 使用 ip::containerPort 绑定 localhost 的任意端口到容器的 80 端口，本地主机会自动分配一个端口。 $ docker run -d -p 127.0.0.1::80 nginx:alpine 还可以使用 udp 标记来指定 udp 端口 $ docker run -d -p 127.0.0.1:80:80/udp nginx:alpine 查看映射端口配置 使用 docker port 来查看当前映射的端口配置，也可以查看到绑定的地址 $ docker port fa 80 0.0.0.0:32768 注意： 容器有自己的内部网络和 ip 地址（使用 docker inspect 查看，Docker 还可以有一个可变的网络配置。） -p 标记可以多次使用来绑定多个端口 例如 $ docker run -d \\ -p 80:80 \\ -p 443:443 \\ nginx:alpine Copyright © Zhenhai Gao 2021 all right reserved发布时间： 2024-06-10 23:03:15 "},"docker/network/linking.html":{"url":"docker/network/linking.html","title":"容器互联","keywords":"","body":"容器互联新建网络连接容器Docker Compose容器互联 如果你之前有 Docker 使用经验，你可能已经习惯了使用 --link 参数来使容器互联。 随着 Docker 网络的完善，强烈建议大家将容器加入自定义的 Docker 网络来连接多个容器，而不是使用 --link 参数。 新建网络 下面先创建一个新的 Docker 网络。 $ docker network create -d bridge my-net -d 参数指定 Docker 网络类型，有 bridge overlay。其中 overlay 网络类型用于 Swarm mode，在本小节中你可以忽略它。 连接容器 运行一个容器并连接到新建的 my-net 网络 $ docker run -it --rm --name busybox1 --network my-net busybox sh 打开新的终端，再运行一个容器并加入到 my-net 网络 $ docker run -it --rm --name busybox2 --network my-net busybox sh 再打开一个新的终端查看容器信息 $ docker container ls CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES b47060aca56b busybox \"sh\" 11 minutes ago Up 11 minutes busybox2 8720575823ec busybox \"sh\" 16 minutes ago Up 16 minutes busybox1 下面通过 ping 来证明 busybox1 容器和 busybox2 容器建立了互联关系。 在 busybox1 容器输入以下命令 / # ping busybox2 PING busybox2 (172.19.0.3): 56 data bytes 64 bytes from 172.19.0.3: seq=0 ttl=64 time=0.072 ms 64 bytes from 172.19.0.3: seq=1 ttl=64 time=0.118 ms 用 ping 来测试连接 busybox2 容器，它会解析成 172.19.0.3。 同理在 busybox2 容器执行 ping busybox1，也会成功连接到。 / # ping busybox1 PING busybox1 (172.19.0.2): 56 data bytes 64 bytes from 172.19.0.2: seq=0 ttl=64 time=0.064 ms 64 bytes from 172.19.0.2: seq=1 ttl=64 time=0.143 ms 这样，busybox1 容器和 busybox2 容器建立了互联关系。 Docker Compose 如果你有多个容器之间需要互相连接，推荐使用 Docker Compose。 Copyright © Zhenhai Gao 2021 all right reserved发布时间： 2024-06-10 23:03:15 "},"docker/network/dns.html":{"url":"docker/network/dns.html","title":"配置 DNS","keywords":"","body":"配置 DNS配置 DNS 如何自定义配置容器的主机名和 DNS 呢？秘诀就是 Docker 利用虚拟文件来挂载容器的 3 个相关配置文件。 在容器中使用 mount 命令可以看到挂载信息： $ mount /dev/disk/by-uuid/1fec...ebdf on /etc/hostname type ext4 ... /dev/disk/by-uuid/1fec...ebdf on /etc/hosts type ext4 ... tmpfs on /etc/resolv.conf type tmpfs ... 这种机制可以让宿主主机 DNS 信息发生更新后，所有 Docker 容器的 DNS 配置通过 /etc/resolv.conf 文件立刻得到更新。 配置全部容器的 DNS ，也可以在 /etc/docker/daemon.json 文件中增加以下内容来设置。 { \"dns\" : [ \"114.114.114.114\", \"8.8.8.8\" ] } 这样每次启动的容器 DNS 自动配置为 114.114.114.114 和 8.8.8.8。使用以下命令来证明其已经生效。 $ docker run -it --rm ubuntu:18.04 cat etc/resolv.conf nameserver 114.114.114.114 nameserver 8.8.8.8 如果用户想要手动指定容器的配置，可以在使用 docker run 命令启动容器时加入如下参数： -h HOSTNAME 或者 --hostname=HOSTNAME 设定容器的主机名，它会被写到容器内的 /etc/hostname 和 /etc/hosts。但它在容器外部看不到，既不会在 docker container ls 中显示，也不会在其他的容器的 /etc/hosts 看到。 --dns=IP_ADDRESS 添加 DNS 服务器到容器的 /etc/resolv.conf 中，让容器用这个服务器来解析所有不在 /etc/hosts 中的主机名。 --dns-search=DOMAIN 设定容器的搜索域，当设定搜索域为 .example.com 时，在搜索一个名为 host 的主机时，DNS 不仅搜索 host，还会搜索 host.example.com。 注意：如果在容器启动时没有指定最后两个参数，Docker 会默认用主机上的 /etc/resolv.conf 来配置容器。 Copyright © Zhenhai Gao 2021 all right reserved发布时间： 2024-06-10 23:03:15 "},"docker/advanced-network/":{"url":"docker/advanced-network/","title":"高级网络配置","keywords":"","body":"高级网络配置高级网络配置 注意：本章属于 Docker 高级配置，如果您是初学者，您可以暂时跳过本章节，直接学习 Docker Compose 一节。 本章将介绍 Docker 的一些高级网络配置和选项。 当 Docker 启动时，会自动在主机上创建一个 docker0 虚拟网桥，实际上是 Linux 的一个 bridge，可以理解为一个软件交换机。它会在挂载到它的网口之间进行转发。 同时，Docker 随机分配一个本地未占用的私有网段（在 RFC1918 中定义）中的一个地址给 docker0 接口。比如典型的 172.17.42.1，掩码为 255.255.0.0。此后启动的容器内的网口也会自动分配一个同一网段（172.17.0.0/16）的地址。 当创建一个 Docker 容器的时候，同时会创建了一对 veth pair 接口（当数据包发送到一个接口时，另外一个接口也可以收到相同的数据包）。这对接口一端在容器内，即 eth0；另一端在本地并被挂载到 docker0 网桥，名称以 veth 开头（例如 vethAQI2QT）。通过这种方式，主机可以跟容器通信，容器之间也可以相互通信。Docker 就创建了在主机和所有容器之间一个虚拟共享网络。 接下来的部分将介绍在一些场景中，Docker 所有的网络定制配置。以及通过 Linux 命令来调整、补充、甚至替换 Docker 默认的网络配置。 Copyright © Zhenhai Gao 2021 all right reserved发布时间： 2024-06-10 23:03:15 "},"docker/advanced-network/quick-guide.html":{"url":"docker/advanced-network/quick-guide.html","title":"快速配置指南","keywords":"","body":"快速配置指南快速配置指南 下面是一个跟 Docker 网络相关的命令列表。 其中有些命令选项只有在 Docker 服务启动的时候才能配置，而且不能马上生效。 -b BRIDGE 或 --bridge=BRIDGE 指定容器挂载的网桥 --bip=CIDR 定制 docker0 的掩码 -H SOCKET... 或 --host=SOCKET... Docker 服务端接收命令的通道 --icc=true|false 是否支持容器之间进行通信 --ip-forward=true|false 请看下文容器之间的通信 --iptables=true|false 是否允许 Docker 添加 iptables 规则 --mtu=BYTES 容器网络中的 MTU 下面2个命令选项既可以在启动服务时指定，也可以在启动容器时指定。在 Docker 服务启动的时候指定则会成为默认值，后面执行 docker run 时可以覆盖设置的默认值。 --dns=IP_ADDRESS... 使用指定的DNS服务器 --dns-search=DOMAIN... 指定DNS搜索域 最后这些选项只有在 docker run 执行时使用，因为它是针对容器的特性内容。 -h HOSTNAME 或 --hostname=HOSTNAME 配置容器主机名 --link=CONTAINER_NAME:ALIAS 添加到另一个容器的连接 --net=bridge|none|container:NAME_or_ID|host 配置容器的桥接模式 -p SPEC 或 --publish=SPEC 映射容器端口到宿主主机 -P or --publish-all=true|false 映射容器所有端口到宿主主机 Copyright © Zhenhai Gao 2021 all right reserved发布时间： 2024-06-10 23:03:15 "},"docker/advanced-network/access-control.html":{"url":"docker/advanced-network/access-control.html","title":"容器访问控制","keywords":"","body":"容器访问控制容器访问外部网络容器之间访问访问所有端口访问指定端口容器访问控制 容器的访问控制，主要通过 Linux 上的 iptables 防火墙来进行管理和实现。iptables 是 Linux 上默认的防火墙软件，在大部分发行版中都自带。 容器访问外部网络 容器要想访问外部网络，需要本地系统的转发支持。在Linux 系统中，检查转发是否打开。 $sysctl net.ipv4.ip_forward net.ipv4.ip_forward = 1 如果为 0，说明没有开启转发，则需要手动打开。 $sysctl -w net.ipv4.ip_forward=1 如果在启动 Docker 服务的时候设定 --ip-forward=true, Docker 就会自动设定系统的 ip_forward 参数为 1。 容器之间访问 容器之间相互访问，需要两方面的支持。 容器的网络拓扑是否已经互联。默认情况下，所有容器都会被连接到 docker0 网桥上。 本地系统的防火墙软件 -- iptables 是否允许通过。 访问所有端口 当启动 Docker 服务（即 dockerd）的时候，默认会添加一条转发策略到本地主机 iptables 的 FORWARD 链上。策略为通过（ACCEPT）还是禁止（DROP）取决于配置--icc=true（缺省值）还是 --icc=false。当然，如果手动指定 --iptables=false 则不会添加 iptables 规则。 可见，默认情况下，不同容器之间是允许网络互通的。如果为了安全考虑，可以在 /etc/docker/daemon.json 文件中配置 {\"icc\": false} 来禁止它。 访问指定端口 在通过 -icc=false 关闭网络访问后，还可以通过 --link=CONTAINER_NAME:ALIAS 选项来访问容器的开放端口。 例如，在启动 Docker 服务时，可以同时使用 icc=false --iptables=true 参数来关闭允许相互的网络访问，并让 Docker 可以修改系统中的 iptables 规则。 此时，系统中的 iptables 规则可能是类似 $ sudo iptables -nL ... Chain FORWARD (policy ACCEPT) target prot opt source destination DROP all -- 0.0.0.0/0 0.0.0.0/0 ... 之后，启动容器（docker run）时使用 --link=CONTAINER_NAME:ALIAS 选项。Docker 会在 iptable 中为 两个容器分别添加一条 ACCEPT 规则，允许相互访问开放的端口（取决于 Dockerfile 中的 EXPOSE 指令）。 当添加了 --link=CONTAINER_NAME:ALIAS 选项后，添加了 iptables 规则。 $ sudo iptables -nL ... Chain FORWARD (policy ACCEPT) target prot opt source destination ACCEPT tcp -- 172.17.0.2 172.17.0.3 tcp spt:80 ACCEPT tcp -- 172.17.0.3 172.17.0.2 tcp dpt:80 DROP all -- 0.0.0.0/0 0.0.0.0/0 注意：--link=CONTAINER_NAME:ALIAS 中的 CONTAINER_NAME 目前必须是 Docker 分配的名字，或使用 --name 参数指定的名字。主机名则不会被识别。 Copyright © Zhenhai Gao 2021 all right reserved发布时间： 2024-06-10 23:03:15 "},"docker/advanced-network/port-mapping.html":{"url":"docker/advanced-network/port-mapping.html","title":"端口映射实现","keywords":"","body":"映射容器端口到宿主主机的实现容器访问外部实现外部访问容器实现映射容器端口到宿主主机的实现 默认情况下，容器可以主动访问到外部网络的连接，但是外部网络无法访问到容器。 容器访问外部实现 容器所有到外部网络的连接，源地址都会被 NAT 成本地系统的 IP 地址。这是使用 iptables 的源地址伪装操作实现的。 查看主机的 NAT 规则。 $ sudo iptables -t nat -nL ... Chain POSTROUTING (policy ACCEPT) target prot opt source destination MASQUERADE all -- 172.17.0.0/16 !172.17.0.0/16 ... 其中，上述规则将所有源地址在 172.17.0.0/16 网段，目标地址为其他网段（外部网络）的流量动态伪装为从系统网卡发出。MASQUERADE 跟传统 SNAT 的好处是它能动态从网卡获取地址。 外部访问容器实现 容器允许外部访问，可以在 docker run 时候通过 -p 或 -P 参数来启用。 不管用那种办法，其实也是在本地的 iptable 的 nat 表中添加相应的规则。 使用 -P 时： $ iptables -t nat -nL ... Chain DOCKER (2 references) target prot opt source destination DNAT tcp -- 0.0.0.0/0 0.0.0.0/0 tcp dpt:49153 to:172.17.0.2:80 使用 -p 80:80 时： $ iptables -t nat -nL Chain DOCKER (2 references) target prot opt source destination DNAT tcp -- 0.0.0.0/0 0.0.0.0/0 tcp dpt:80 to:172.17.0.2:80 注意： 这里的规则映射了 0.0.0.0，意味着将接受主机来自所有接口的流量。用户可以通过 -p IP:host_port:container_port 或 -p IP::port 来指定允许访问容器的主机上的 IP、接口等，以制定更严格的规则。 如果希望永久绑定到某个固定的 IP 地址，可以在 Docker 配置文件 /etc/docker/daemon.json 中添加如下内容。 { \"ip\": \"0.0.0.0\" } Copyright © Zhenhai Gao 2021 all right reserved发布时间： 2024-06-10 23:03:15 "},"docker/advanced-network/docker0.html":{"url":"docker/advanced-network/docker0.html","title":"配置 docker0 网桥","keywords":"","body":"配置 docker0 网桥配置 docker0 网桥 Docker 服务默认会创建一个 docker0 网桥（其上有一个 docker0 内部接口），它在内核层连通了其他的物理或虚拟网卡，这就将所有容器和本地主机都放到同一个物理网络。 Docker 默认指定了 docker0 接口 的 IP 地址和子网掩码，让主机和容器之间可以通过网桥相互通信，它还给出了 MTU（接口允许接收的最大传输单元），通常是 1500 Bytes，或宿主主机网络路由上支持的默认值。这些值都可以在服务启动的时候进行配置。 --bip=CIDR IP 地址加掩码格式，例如 192.168.1.5/24 --mtu=BYTES 覆盖默认的 Docker mtu 配置 也可以在配置文件中配置 DOCKER_OPTS，然后重启服务。 由于目前 Docker 网桥是 Linux 网桥，用户可以使用 brctl show 来查看网桥和端口连接信息。 $ sudo brctl show bridge name bridge id STP enabled interfaces docker0 8000.3a1d7362b4ee no veth65f9 vethdda6 *注：brctl 命令在 Debian、Ubuntu 中可以使用 sudo apt-get install bridge-utils 来安装。 每次创建一个新容器的时候，Docker 从可用的地址段中选择一个空闲的 IP 地址分配给容器的 eth0 端口。使用本地主机上 docker0 接口的 IP 作为所有容器的默认网关。 $ sudo docker run -i -t --rm base /bin/bash $ ip addr show eth0 24: eth0: mtu 1500 qdisc pfifo_fast state UP group default qlen 1000 link/ether 32:6f:e0:35:57:91 brd ff:ff:ff:ff:ff:ff inet 172.17.0.3/16 scope global eth0 valid_lft forever preferred_lft forever inet6 fe80::306f:e0ff:fe35:5791/64 scope link valid_lft forever preferred_lft forever $ ip route default via 172.17.42.1 dev eth0 172.17.0.0/16 dev eth0 proto kernel scope link src 172.17.0.3 Copyright © Zhenhai Gao 2021 all right reserved发布时间： 2024-06-10 23:03:15 "},"docker/advanced-network/bridge.html":{"url":"docker/advanced-network/bridge.html","title":"自定义网桥","keywords":"","body":"自定义网桥自定义网桥 除了默认的 docker0 网桥，用户也可以指定网桥来连接各个容器。 在启动 Docker 服务的时候，使用 -b BRIDGE或--bridge=BRIDGE 来指定使用的网桥。 如果服务已经运行，那需要先停止服务，并删除旧的网桥。 $ sudo systemctl stop docker $ sudo ip link set dev docker0 down $ sudo brctl delbr docker0 然后创建一个网桥 bridge0。 $ sudo brctl addbr bridge0 $ sudo ip addr add 192.168.5.1/24 dev bridge0 $ sudo ip link set dev bridge0 up 查看确认网桥创建并启动。 $ ip addr show bridge0 4: bridge0: mtu 1500 qdisc noop state UP group default link/ether 66:38:d0:0d:76:18 brd ff:ff:ff:ff:ff:ff inet 192.168.5.1/24 scope global bridge0 valid_lft forever preferred_lft forever 在 Docker 配置文件 /etc/docker/daemon.json 中添加如下内容，即可将 Docker 默认桥接到创建的网桥上。 { \"bridge\": \"bridge0\", } 启动 Docker 服务。 新建一个容器，可以看到它已经桥接到了 bridge0 上。 可以继续用 brctl show 命令查看桥接的信息。另外，在容器中可以使用 ip addr 和 ip route 命令来查看 IP 地址配置和路由信息。 Copyright © Zhenhai Gao 2021 all right reserved发布时间： 2024-06-10 23:03:15 "},"docker/advanced-network/example.html":{"url":"docker/advanced-network/example.html","title":"工具和示例","keywords":"","body":"工具和示例pipeworkplayground工具和示例 在介绍自定义网络拓扑之前，你可能会对一些外部工具和例子感兴趣： pipework Jérôme Petazzoni 编写了一个叫 pipework 的 shell 脚本，可以帮助用户在比较复杂的场景中完成容器的连接。 playground Brandon Rhodes 创建了一个提供完整的 Docker 容器网络拓扑管理的 Python库，包括路由、NAT 防火墙；以及一些提供 HTTP SMTP POP IMAP Telnet SSH FTP 的服务器。 Copyright © Zhenhai Gao 2021 all right reserved发布时间： 2024-06-10 23:03:15 "},"docker/advanced-network/config-file.html":{"url":"docker/advanced-network/config-file.html","title":"编辑网络配置文件","keywords":"","body":"编辑网络配置文件编辑网络配置文件 Docker 1.2.0 开始支持在运行中的容器里编辑 /etc/hosts, /etc/hostname 和 /etc/resolv.conf 文件。 但是这些修改是临时的，只在运行的容器中保留，容器终止或重启后并不会被保存下来，也不会被 docker commit 提交。 Copyright © Zhenhai Gao 2021 all right reserved发布时间： 2024-06-10 23:03:15 "},"docker/advanced-network/ptp.html":{"url":"docker/advanced-network/ptp.html","title":"实例：创建一个点到点连接","keywords":"","body":"示例：创建一个点到点连接示例：创建一个点到点连接 默认情况下，Docker 会将所有容器连接到由 docker0 提供的虚拟子网中。 用户有时候需要两个容器之间可以直连通信，而不用通过主机网桥进行桥接。 解决办法很简单：创建一对 peer 接口，分别放到两个容器中，配置成点到点链路类型即可。 首先启动 2 个容器： $ docker run -i -t --rm --net=none base /bin/bash root@1f1f4c1f931a:/# $ docker run -i -t --rm --net=none base /bin/bash root@12e343489d2f:/# 找到进程号，然后创建网络命名空间的跟踪文件。 $ docker inspect -f '{{.State.Pid}}' 1f1f4c1f931a 2989 $ docker inspect -f '{{.State.Pid}}' 12e343489d2f 3004 $ sudo mkdir -p /var/run/netns $ sudo ln -s /proc/2989/ns/net /var/run/netns/2989 $ sudo ln -s /proc/3004/ns/net /var/run/netns/3004 创建一对 peer 接口，然后配置路由 $ sudo ip link add A type veth peer name B $ sudo ip link set A netns 2989 $ sudo ip netns exec 2989 ip addr add 10.1.1.1/32 dev A $ sudo ip netns exec 2989 ip link set A up $ sudo ip netns exec 2989 ip route add 10.1.1.2/32 dev A $ sudo ip link set B netns 3004 $ sudo ip netns exec 3004 ip addr add 10.1.1.2/32 dev B $ sudo ip netns exec 3004 ip link set B up $ sudo ip netns exec 3004 ip route add 10.1.1.1/32 dev B 现在这 2 个容器就可以相互 ping 通，并成功建立连接。点到点链路不需要子网和子网掩码。 此外，也可以不指定 --net=none 来创建点到点链路。这样容器还可以通过原先的网络来通信。 利用类似的办法，可以创建一个只跟主机通信的容器。但是一般情况下，更推荐使用 --icc=false 来关闭容器之间的通信。 Copyright © Zhenhai Gao 2021 all right reserved发布时间： 2024-06-10 23:03:15 "},"docker/buildx/":{"url":"docker/buildx/","title":"Docker Buildx","keywords":"","body":"Docker BuildxDocker Buildx Docker Buildx 是一个 docker CLI 插件，其扩展了 docker 命令，支持 Moby BuildKit 提供的功能。提供了与 docker build 相同的用户体验，并增加了许多新功能。 该功能仅适用于 Docker v19.03+ 版本 Copyright © Zhenhai Gao 2021 all right reserved发布时间： 2024-06-10 23:03:15 "},"docker/buildx/buildkit.html":{"url":"docker/buildx/buildkit.html","title":"BuildKit","keywords":"","body":"使用 BuildKit 构建镜像Dockerfile 新增指令详解RUN --mount=type=cacheRUN --mount=type=bindRUN --mount=type=tmpfsRUN --mount=type=secretRUN --mount=type=sshdocker-compose build 使用 Buildkit官方文档使用 BuildKit 构建镜像 BuildKit 是下一代的镜像构建组件，在 https://github.com/moby/buildkit 开源。 注意：如果您的镜像构建使用的是云服务商提供的镜像构建服务（腾讯云容器服务、阿里云容器服务等），由于上述服务提供商的 Docker 版本低于 18.09，BuildKit 无法使用，将造成镜像构建失败。建议使用 BuildKit 构建镜像时使用一个新的 Dockerfile 文件（例如 Dockerfile.buildkit） 目前，Docker Hub 自动构建已经支持 buildkit，具体请参考 https://github.com/docker-practice/docker-hub-buildx Dockerfile 新增指令详解 启用 BuildKit 之后，我们可以使用下面几个新的 Dockerfile 指令来加快镜像构建。 RUN --mount=type=cache 目前，几乎所有的程序都会使用依赖管理工具，例如 Go 中的 go mod、Node.js 中的 npm 等等，当我们构建一个镜像时，往往会重复的从互联网中获取依赖包，难以缓存，大大降低了镜像的构建效率。 例如一个前端工程需要用到 npm： FROM node:alpine as builder WORKDIR /app COPY package.json /app/ RUN npm i --registry=https://registry.npm.taobao.org \\ && rm -rf ~/.npm COPY src /app/src RUN npm run build FROM nginx:alpine COPY --from=builder /app/dist /app/dist 使用多阶段构建，构建的镜像中只包含了目标文件夹 dist，但仍然存在一些问题，当 package.json 文件变动时，RUN npm i && rm -rf ~/.npm 这一层会重新执行，变更多次后，生成了大量的中间层镜像。 为解决这个问题，进一步的我们可以设想一个类似 数据卷 的功能，在镜像构建时把 node_modules 文件夹挂载上去，在构建完成后，这个 node_modules 文件夹会自动卸载，实际的镜像中并不包含 node_modules 这个文件夹，这样我们就省去了每次获取依赖的时间，大大增加了镜像构建效率，同时也避免了生成了大量的中间层镜像。 BuildKit 提供了 RUN --mount=type=cache 指令，可以实现上边的设想。 # syntax = docker/dockerfile:experimental FROM node:alpine as builder WORKDIR /app COPY package.json /app/ RUN --mount=type=cache,target=/app/node_modules,id=my_app_npm_module,sharing=locked \\ --mount=type=cache,target=/root/.npm,id=npm_cache \\ npm i --registry=https://registry.npm.taobao.org COPY src /app/src RUN --mount=type=cache,target=/app/node_modules,id=my_app_npm_module,sharing=locked \\ # --mount=type=cache,target=/app/dist,id=my_app_dist,sharing=locked \\ npm run build FROM nginx:alpine # COPY --from=builder /app/dist /app/dist # 为了更直观的说明 from 和 source 指令，这里使用 RUN 指令 RUN --mount=type=cache,target=/tmp/dist,from=builder,source=/app/dist \\ # --mount=type=cache,target/tmp/dist,from=my_app_dist,sharing=locked \\ mkdir -p /app/dist && cp -r /tmp/dist/* /app/dist 由于 BuildKit 为实验特性，每个 Dockerfile 文件开头都必须加上如下指令 # syntax = docker/dockerfile:experimental 第一个 RUN 指令执行后，id 为 my_app_npm_module 的缓存文件夹挂载到了 /app/node_modules 文件夹中。多次执行也不会产生多个中间层镜像。 第二个 RUN 指令执行时需要用到 node_modules 文件夹，node_modules 已经挂载，命令也可以正确执行。 第三个 RUN 指令将上一阶段产生的文件复制到指定位置，from 指明缓存的来源，这里 builder 表示缓存来源于构建的第一阶段，source 指明缓存来源的文件夹。 上面的 Dockerfile 中 --mount=type=cache,... 中指令作用如下： Option Description id id 设置一个标志，以便区分缓存。 target (必填项) 缓存的挂载目标文件夹。 ro,readonly 只读，缓存文件夹不能被写入。 sharing 有 shared private locked 值可供选择。sharing 设置当一个缓存被多次使用时的表现，由于 BuildKit 支持并行构建，当多个步骤使用同一缓存时（同一 id）会发生冲突。shared 表示多个步骤可以同时读写，private 表示当多个步骤使用同一缓存时，每个步骤使用不同的缓存，locked 表示当一个步骤完成释放缓存后，后一个步骤才能继续使用该缓存。 from 缓存来源（构建阶段），不填写时为空文件夹。 source 来源的文件夹路径。 RUN --mount=type=bind 该指令可以将一个镜像（或上一构建阶段）的文件挂载到指定位置。 # syntax = docker/dockerfile:experimental RUN --mount=type=bind,from=php:alpine,source=/usr/local/bin/docker-php-entrypoint,target=/docker-php-entrypoint \\ cat /docker-php-entrypoint RUN --mount=type=tmpfs 该指令可以将一个 tmpfs 文件系统挂载到指定位置。 # syntax = docker/dockerfile:experimental RUN --mount=type=tmpfs,target=/temp \\ mount | grep /temp RUN --mount=type=secret 该指令可以将一个文件(例如密钥)挂载到指定位置。 # syntax = docker/dockerfile:experimental RUN --mount=type=secret,id=aws,target=/root/.aws/credentials \\ cat /root/.aws/credentials $ docker build -t test --secret id=aws,src=$HOME/.aws/credentials . RUN --mount=type=ssh 该指令可以挂载 ssh 密钥。 # syntax = docker/dockerfile:experimental FROM alpine RUN apk add --no-cache openssh-client RUN mkdir -p -m 0700 ~/.ssh && ssh-keyscan gitlab.com >> ~/.ssh/known_hosts RUN --mount=type=ssh ssh git@gitlab.com | tee /hello $ eval $(ssh-agent) $ ssh-add ~/.ssh/id_rsa (Input your passphrase here) $ docker build -t test --ssh default=$SSH_AUTH_SOCK . docker-compose build 使用 Buildkit 设置 COMPOSE_DOCKER_CLI_BUILD=1 环境变量即可使用。 官方文档 https://github.com/moby/buildkit/blob/master/frontend/dockerfile/docs/experimental.md Copyright © Zhenhai Gao 2021 all right reserved发布时间： 2024-06-10 23:03:15 "},"docker/buildx/buildx.html":{"url":"docker/buildx/buildx.html","title":"使用 buildx 构建镜像","keywords":"","body":"使用 Buildx 构建镜像使用官方文档使用 Buildx 构建镜像 使用 你可以直接使用 docker buildx build 命令构建镜像。 $ docker buildx build . [+] Building 8.4s (23/32) => ... Buildx 使用 BuildKit 引擎 进行构建，支持许多新的功能，具体参考 Buildkit 一节。 官方文档 https://docs.docker.com/engine/reference/commandline/buildx/ Copyright © Zhenhai Gao 2021 all right reserved发布时间： 2024-06-10 23:03:15 "},"docker/buildx/multi-arch-images.html":{"url":"docker/buildx/multi-arch-images.html","title":"使用 buildx 构建多种系统架构支持的 Docker 镜像","keywords":"","body":"使用 buildx 构建多种系统架构支持的 Docker 镜像新建 builder 实例构建镜像架构相关变量使用举例使用 buildx 构建多种系统架构支持的 Docker 镜像 在之前的版本中构建多种系统架构支持的 Docker 镜像，要想使用统一的名字必须使用 $ docker manifest 命令。 在 Docker 19.03+ 版本中可以使用 $ docker buildx build 命令使用 BuildKit 构建镜像。该命令支持 --platform 参数可以同时构建支持多种系统架构的 Docker 镜像，大大简化了构建步骤。 新建 builder 实例 Docker for Linux 不支持构建 arm 架构镜像，我们可以运行一个新的容器让其支持该特性，Docker 桌面版无需进行此项设置。 $ docker run --rm --privileged tonistiigi/binfmt:latest --install all 由于 Docker 默认的 builder 实例不支持同时指定多个 --platform，我们必须首先创建一个新的 builder 实例。同时由于国内拉取镜像较缓慢，我们可以使用配置了 镜像加速地址 的 dockerpracticesig/buildkit:master 镜像替换官方镜像。 如果你有私有的镜像加速器，可以基于 https://github.com/docker-practice/buildx 构建自己的 buildkit 镜像并使用它。 # 适用于国内环境 $ docker buildx create --use --name=mybuilder-cn --driver docker-container --driver-opt image=dockerpracticesig/buildkit:master # 适用于腾讯云环境(腾讯云主机、coding.net 持续集成) $ docker buildx create --use --name=mybuilder-cn --driver docker-container --driver-opt image=dockerpracticesig/buildkit:master-tencent # $ docker buildx create --name mybuilder --driver docker-container $ docker buildx use mybuilder 构建镜像 新建 Dockerfile 文件。 FROM --platform=$TARGETPLATFORM alpine RUN uname -a > /os.txt CMD cat /os.txt 使用 $ docker buildx build 命令构建镜像，注意将 myusername 替换为自己的 Docker Hub 用户名。 --push 参数表示将构建好的镜像推送到 Docker 仓库。 $ docker buildx build --platform linux/arm,linux/arm64,linux/amd64 -t myusername/hello . --push # 查看镜像信息 $ docker buildx imagetools inspect myusername/hello 在不同架构运行该镜像，可以得到该架构的信息。 # arm $ docker run -it --rm myusername/hello Linux buildkitsandbox 4.9.125-linuxkit #1 SMP Fri Sep 7 08:20:28 UTC 2018 armv7l Linux # arm64 $ docker run -it --rm myusername/hello Linux buildkitsandbox 4.9.125-linuxkit #1 SMP Fri Sep 7 08:20:28 UTC 2018 aarch64 Linux # amd64 $ docker run -it --rm myusername/hello Linux buildkitsandbox 4.9.125-linuxkit #1 SMP Fri Sep 7 08:20:28 UTC 2018 x86_64 Linux 架构相关变量 Dockerfile 支持如下架构相关的变量 TARGETPLATFORM 构建镜像的目标平台，例如 linux/amd64, linux/arm/v7, windows/amd64。 TARGETOS TARGETPLATFORM 的 OS 类型，例如 linux, windows TARGETARCH TARGETPLATFORM 的架构类型，例如 amd64, arm TARGETVARIANT TARGETPLATFORM 的变种，该变量可能为空，例如 v7 BUILDPLATFORM 构建镜像主机平台，例如 linux/amd64 BUILDOS BUILDPLATFORM 的 OS 类型，例如 linux BUILDARCH BUILDPLATFORM 的架构类型，例如 amd64 BUILDVARIANT BUILDPLATFORM 的变种，该变量可能为空，例如 v7 使用举例 例如我们要构建支持 linux/arm/v7 和 linux/amd64 两种架构的镜像。假设已经生成了两个平台对应的二进制文件： bin/dist-linux-arm bin/dist-linux-amd64 那么 Dockerfile 可以这样书写： FROM scratch # 使用变量必须申明 ARG TARGETOS ARG TARGETARCH COPY bin/dist-${TARGETOS}-${TARGETARCH} /dist ENTRYPOINT [\"dist\"] Copyright © Zhenhai Gao 2021 all right reserved发布时间： 2024-06-10 23:03:15 "},"docker/docker-compose/":{"url":"docker/docker-compose/","title":"Docker Compose","keywords":"","body":"Docker Compose 项目Docker Compose 项目 Docker Compose 是 Docker 官方编排（Orchestration）项目之一，负责快速的部署分布式应用。 本章将介绍 Compose 项目情况以及安装和使用。 Copyright © Zhenhai Gao 2021 all right reserved发布时间： 2024-06-10 23:03:15 "},"docker/docker-compose/introduction.html":{"url":"docker/docker-compose/introduction.html","title":"简介","keywords":"","body":"Compose 简介Compose 简介 Compose 项目是 Docker 官方的开源项目，负责实现对 Docker 容器集群的快速编排。从功能上看，跟 OpenStack 中的 Heat 十分类似。 其代码目前在 https://github.com/docker/compose 上开源。 Compose 定位是 「定义和运行多个 Docker 容器的应用（Defining and running multi-container Docker applications）」，其前身是开源项目 Fig。 通过第一部分中的介绍，我们知道使用一个 Dockerfile 模板文件，可以让用户很方便的定义一个单独的应用容器。然而，在日常工作中，经常会碰到需要多个容器相互配合来完成某项任务的情况。例如要实现一个 Web 项目，除了 Web 服务容器本身，往往还需要再加上后端的数据库服务容器，甚至还包括负载均衡容器等。 Compose 恰好满足了这样的需求。它允许用户通过一个单独的 docker-compose.yml 模板文件（YAML 格式）来定义一组相关联的应用容器为一个项目（project）。 Compose 中有两个重要的概念： 服务 (service)：一个应用的容器，实际上可以包括若干运行相同镜像的容器实例。 项目 (project)：由一组关联的应用容器组成的一个完整业务单元，在 docker-compose.yml 文件中定义。 Compose 的默认管理对象是项目，通过子命令对项目中的一组容器进行便捷地生命周期管理。 Compose 项目由 Python 编写，实现上调用了 Docker 服务提供的 API 来对容器进行管理。因此，只要所操作的平台支持 Docker API，就可以在其上利用 Compose 来进行编排管理。 Copyright © Zhenhai Gao 2021 all right reserved发布时间： 2024-06-10 23:03:15 "},"docker/docker-compose/v2.html":{"url":"docker/docker-compose/v2.html","title":"Compose v2","keywords":"","body":"Compose V2官方文档Compose V2 目前 Docker 官方用 GO 语言 重写 了 Docker Compose，并将其作为了 docker cli 的子命令，称为 Compose V2。你可以参照官方文档安装，然后将熟悉的 docker-compose 命令替换为 docker compose，即可使用 Docker Compose。 官方文档 Compose V2 beta Copyright © Zhenhai Gao 2021 all right reserved发布时间： 2024-06-10 23:03:15 "},"docker/docker-compose/install.html":{"url":"docker/docker-compose/install.html","title":"安装与卸载","keywords":"","body":"安装与卸载二进制包PIP 安装bash 补全命令卸载安装与卸载 Compose 支持 Linux、macOS、Windows 10 三大平台。 Compose 可以通过 Python 的包管理工具 pip 进行安装，也可以直接下载编译好的二进制文件使用，甚至能够直接在 Docker 容器中运行。 Docker Desktop for Mac/Windows 自带 docker-compose 二进制文件，安装 Docker 之后可以直接使用。 $ docker-compose --version docker-compose version 1.27.4, build 40524192 Linux 系统请使用以下介绍的方法安装。 二进制包 在 Linux 上的也安装十分简单，从 官方 GitHub Release 处直接下载编译好的二进制文件即可。 例如，在 Linux 64 位系统上直接下载对应的二进制包。 $ sudo curl -L https://github.com/docker/compose/releases/download/1.27.4/docker-compose-`uname -s`-`uname -m` > /usr/local/bin/docker-compose # 国内用户可以使用以下方式加快下载 $ sudo curl -L https://download.fastgit.org/docker/compose/releases/download/1.27.4/docker-compose-`uname -s`-`uname -m` > /usr/local/bin/docker-compose $ sudo chmod +x /usr/local/bin/docker-compose PIP 安装 注： x86_64 架构的 Linux 建议按照上边的方法下载二进制包进行安装，如果您计算机的架构是 ARM (例如，树莓派)，再使用 pip 安装。 这种方式是将 Compose 当作一个 Python 应用来从 pip 源中安装。 执行安装命令： $ sudo pip install -U docker-compose 可以看到类似如下输出，说明安装成功。 Collecting docker-compose Downloading docker-compose-1.27.4.tar.gz (149kB): 149kB downloaded ... Successfully installed docker-compose cached-property requests texttable websocket-client docker-py dockerpty six enum34 backports.ssl-match-hostname ipaddress bash 补全命令 $ curl -L https://raw.githubusercontent.com/docker/compose/1.27.4/contrib/completion/bash/docker-compose > /etc/bash_completion.d/docker-compose 卸载 如果是二进制包方式安装的，删除二进制文件即可。 $ sudo rm /usr/local/bin/docker-compose 如果是通过 pip 安装的，则执行如下命令即可删除。 $ sudo pip uninstall docker-compose Copyright © Zhenhai Gao 2021 all right reserved发布时间： 2024-06-10 23:03:15 "},"docker/docker-compose/usage.html":{"url":"docker/docker-compose/usage.html","title":"使用","keywords":"","body":"使用术语场景web 应用Dockerfiledocker-compose.yml运行 compose 项目使用 术语 首先介绍几个术语。 服务 (service)：一个应用容器，实际上可以运行多个相同镜像的实例。 项目 (project)：由一组关联的应用容器组成的一个完整业务单元。 可见，一个项目可以由多个服务（容器）关联而成，Compose 面向项目进行管理。 场景 最常见的项目是 web 网站，该项目应该包含 web 应用和缓存。 下面我们用 Python 来建立一个能够记录页面访问次数的 web 网站。 web 应用 新建文件夹，在该目录中编写 app.py 文件 from flask import Flask from redis import Redis app = Flask(__name__) redis = Redis(host='redis', port=6379) @app.route('/') def hello(): count = redis.incr('hits') return 'Hello World! 该页面已被访问 {} 次。\\n'.format(count) if __name__ == \"__main__\": app.run(host=\"0.0.0.0\", debug=True) Dockerfile 编写 Dockerfile 文件，内容为 FROM python:3.6-alpine ADD . /code WORKDIR /code RUN pip install redis flask CMD [\"python\", \"app.py\"] docker-compose.yml 编写 docker-compose.yml 文件，这个是 Compose 使用的主模板文件。 version: '3' services: web: build: . ports: - \"5000:5000\" redis: image: \"redis:alpine\" 运行 compose 项目 $ docker-compose up 此时访问本地 5000 端口，每次刷新页面，计数就会加 1。 Copyright © Zhenhai Gao 2021 all right reserved发布时间： 2024-06-10 23:03:15 "},"docker/docker-compose/commands.html":{"url":"docker/docker-compose/commands.html","title":"命令说明","keywords":"","body":"Compose 命令说明命令对象与格式命令选项命令使用说明buildconfigdownexechelpimageskilllogspauseportpspullpushrestartrmrunscalestartstoptopunpauseupversion参考资料Compose 命令说明 命令对象与格式 对于 Compose 来说，大部分命令的对象既可以是项目本身，也可以指定为项目中的服务或者容器。如果没有特别的说明，命令对象将是项目，这意味着项目中所有的服务都会受到命令影响。 执行 docker-compose [COMMAND] --help 或者 docker-compose help [COMMAND] 可以查看具体某个命令的使用格式。 docker-compose 命令的基本的使用格式是 docker-compose [-f=...] [options] [COMMAND] [ARGS...] 命令选项 -f, --file FILE 指定使用的 Compose 模板文件，默认为 docker-compose.yml，可以多次指定。 -p, --project-name NAME 指定项目名称，默认将使用所在目录名称作为项目名。 --verbose 输出更多调试信息。 -v, --version 打印版本并退出。 命令使用说明 build 格式为 docker-compose build [options] [SERVICE...]。 构建（重新构建）项目中的服务容器。 服务容器一旦构建后，将会带上一个标记名，例如对于 web 项目中的一个 db 容器，可能是 web_db。 可以随时在项目目录下运行 docker-compose build 来重新构建服务。 选项包括： --force-rm 删除构建过程中的临时容器。 --no-cache 构建镜像过程中不使用 cache（这将加长构建过程）。 --pull 始终尝试通过 pull 来获取更新版本的镜像。 config 验证 Compose 文件格式是否正确，若正确则显示配置，若格式错误显示错误原因。 down 此命令将会停止 up 命令所启动的容器，并移除网络 exec 进入指定的容器。 help 获得一个命令的帮助。 images 列出 Compose 文件中包含的镜像。 kill 格式为 docker-compose kill [options] [SERVICE...]。 通过发送 SIGKILL 信号来强制停止服务容器。 支持通过 -s 参数来指定发送的信号，例如通过如下指令发送 SIGINT 信号。 $ docker-compose kill -s SIGINT logs 格式为 docker-compose logs [options] [SERVICE...]。 查看服务容器的输出。默认情况下，docker-compose 将对不同的服务输出使用不同的颜色来区分。可以通过 --no-color 来关闭颜色。 该命令在调试问题的时候十分有用。 pause 格式为 docker-compose pause [SERVICE...]。 暂停一个服务容器。 port 格式为 docker-compose port [options] SERVICE PRIVATE_PORT。 打印某个容器端口所映射的公共端口。 选项： --protocol=proto 指定端口协议，tcp（默认值）或者 udp。 --index=index 如果同一服务存在多个容器，指定命令对象容器的序号（默认为 1）。 ps 格式为 docker-compose ps [options] [SERVICE...]。 列出项目中目前的所有容器。 选项： -q 只打印容器的 ID 信息。 pull 格式为 docker-compose pull [options] [SERVICE...]。 拉取服务依赖的镜像。 选项： --ignore-pull-failures 忽略拉取镜像过程中的错误。 push 推送服务依赖的镜像到 Docker 镜像仓库。 restart 格式为 docker-compose restart [options] [SERVICE...]。 重启项目中的服务。 选项： -t, --timeout TIMEOUT 指定重启前停止容器的超时（默认为 10 秒）。 rm 格式为 docker-compose rm [options] [SERVICE...]。 删除所有（停止状态的）服务容器。推荐先执行 docker-compose stop 命令来停止容器。 选项： -f, --force 强制直接删除，包括非停止状态的容器。一般尽量不要使用该选项。 -v 删除容器所挂载的数据卷。 run 格式为 docker-compose run [options] [-p PORT...] [-e KEY=VAL...] SERVICE [COMMAND] [ARGS...]。 在指定服务上执行一个命令。 例如： $ docker-compose run ubuntu ping docker.com 将会启动一个 ubuntu 服务容器，并执行 ping docker.com 命令。 默认情况下，如果存在关联，则所有关联的服务将会自动被启动，除非这些服务已经在运行中。 该命令类似启动容器后运行指定的命令，相关卷、链接等等都将会按照配置自动创建。 两个不同点： 给定命令将会覆盖原有的自动运行命令； 不会自动创建端口，以避免冲突。 如果不希望自动启动关联的容器，可以使用 --no-deps 选项，例如 $ docker-compose run --no-deps web python manage.py shell 将不会启动 web 容器所关联的其它容器。 选项： -d 后台运行容器。 --name NAME 为容器指定一个名字。 --entrypoint CMD 覆盖默认的容器启动指令。 -e KEY=VAL 设置环境变量值，可多次使用选项来设置多个环境变量。 -u, --user=\"\" 指定运行容器的用户名或者 uid。 --no-deps 不自动启动关联的服务容器。 --rm 运行命令后自动删除容器，d 模式下将忽略。 -p, --publish=[] 映射容器端口到本地主机。 --service-ports 配置服务端口并映射到本地主机。 -T 不分配伪 tty，意味着依赖 tty 的指令将无法运行。 scale 格式为 docker-compose scale [options] [SERVICE=NUM...]。 设置指定服务运行的容器个数。 通过 service=num 的参数来设置数量。例如： $ docker-compose scale web=3 db=2 将启动 3 个容器运行 web 服务，2 个容器运行 db 服务。 一般的，当指定数目多于该服务当前实际运行容器，将新创建并启动容器；反之，将停止容器。 选项： -t, --timeout TIMEOUT 停止容器时候的超时（默认为 10 秒）。 start 格式为 docker-compose start [SERVICE...]。 启动已经存在的服务容器。 stop 格式为 docker-compose stop [options] [SERVICE...]。 停止已经处于运行状态的容器，但不删除它。通过 docker-compose start 可以再次启动这些容器。 选项： -t, --timeout TIMEOUT 停止容器时候的超时（默认为 10 秒）。 top 查看各个服务容器内运行的进程。 unpause 格式为 docker-compose unpause [SERVICE...]。 恢复处于暂停状态中的服务。 up 格式为 docker-compose up [options] [SERVICE...]。 该命令十分强大，它将尝试自动完成包括构建镜像，（重新）创建服务，启动服务，并关联服务相关容器的一系列操作。 链接的服务都将会被自动启动，除非已经处于运行状态。 可以说，大部分时候都可以直接通过该命令来启动一个项目。 默认情况，docker-compose up 启动的容器都在前台，控制台将会同时打印所有容器的输出信息，可以很方便进行调试。 当通过 Ctrl-C 停止命令时，所有容器将会停止。 如果使用 docker-compose up -d，将会在后台启动并运行所有的容器。一般推荐生产环境下使用该选项。 默认情况，如果服务容器已经存在，docker-compose up 将会尝试停止容器，然后重新创建（保持使用 volumes-from 挂载的卷），以保证新启动的服务匹配 docker-compose.yml 文件的最新内容。如果用户不希望容器被停止并重新创建，可以使用 docker-compose up --no-recreate。这样将只会启动处于停止状态的容器，而忽略已经运行的服务。如果用户只想重新部署某个服务，可以使用 docker-compose up --no-deps -d 来重新创建服务并后台停止旧服务，启动新服务，并不会影响到其所依赖的服务。 选项： -d 在后台运行服务容器。 --no-color 不使用颜色来区分不同的服务的控制台输出。 --no-deps 不启动服务所链接的容器。 --force-recreate 强制重新创建容器，不能与 --no-recreate 同时使用。 --no-recreate 如果容器已经存在了，则不重新创建，不能与 --force-recreate 同时使用。 --no-build 不自动构建缺失的服务镜像。 -t, --timeout TIMEOUT 停止容器时候的超时（默认为 10 秒）。 version 格式为 docker-compose version。 打印版本信息。 参考资料 官方文档 Copyright © Zhenhai Gao 2021 all right reserved发布时间： 2024-06-10 23:03:15 "},"docker/docker-compose/compose-file.html":{"url":"docker/docker-compose/compose-file.html","title":"Compose 模板文件","keywords":"","body":"Compose 模板文件buildcap_add, cap_dropcommandconfigscgroup_parentcontainer_namedeploydevicesdepends_ondnsdns_searchtmpfsenv_fileenvironmentexposeexternal_linksextra_hostshealthcheckimagelabelslinksloggingnetwork_modenetworkspidportssecretssecurity_optstop_signalsysctlsulimitsvolumes其它指令读取变量参考资料Compose 模板文件 模板文件是使用 Compose 的核心，涉及到的指令关键字也比较多。但大家不用担心，这里面大部分指令跟 docker run 相关参数的含义都是类似的。 默认的模板文件名称为 docker-compose.yml，格式为 YAML 格式。 version: \"3\" services: webapp: image: examples/web ports: - \"80:80\" volumes: - \"/data\" 注意每个服务都必须通过 image 指令指定镜像或 build 指令（需要 Dockerfile）等来自动构建生成镜像。 如果使用 build 指令，在 Dockerfile 中设置的选项(例如：CMD, EXPOSE, VOLUME, ENV 等) 将会自动被获取，无需在 docker-compose.yml 中重复设置。 下面分别介绍各个指令的用法。 build 指定 Dockerfile 所在文件夹的路径（可以是绝对路径，或者相对 docker-compose.yml 文件的路径）。 Compose 将会利用它自动构建这个镜像，然后使用这个镜像。 version: '3' services: webapp: build: ./dir 你也可以使用 context 指令指定 Dockerfile 所在文件夹的路径。 使用 dockerfile 指令指定 Dockerfile 文件名。 使用 arg 指令指定构建镜像时的变量。 version: '3' services: webapp: build: context: ./dir dockerfile: Dockerfile-alternate args: buildno: 1 使用 cache_from 指定构建镜像的缓存 build: context: . cache_from: - alpine:latest - corp/web_app:3.14 cap_add, cap_drop 指定容器的内核能力（capacity）分配。 例如，让容器拥有所有能力可以指定为： cap_add: - ALL 去掉 NET_ADMIN 能力可以指定为： cap_drop: - NET_ADMIN command 覆盖容器启动后默认执行的命令。 command: echo \"hello world\" configs 仅用于 Swarm mode，详细内容请查看 Swarm mode 一节。 cgroup_parent 指定父 cgroup 组，意味着将继承该组的资源限制。 例如，创建了一个 cgroup 组名称为 cgroups_1。 cgroup_parent: cgroups_1 container_name 指定容器名称。默认将会使用 项目名称_服务名称_序号 这样的格式。 container_name: docker-web-container 注意: 指定容器名称后，该服务将无法进行扩展（scale），因为 Docker 不允许多个容器具有相同的名称。 deploy 仅用于 Swarm mode，详细内容请查看 Swarm mode 一节 devices 指定设备映射关系。 devices: - \"/dev/ttyUSB1:/dev/ttyUSB0\" depends_on 解决容器的依赖、启动先后的问题。以下例子中会先启动 redis db 再启动 web version: '3' services: web: build: . depends_on: - db - redis redis: image: redis db: image: postgres 注意：web 服务不会等待 redis db 「完全启动」之后才启动。 dns 自定义 DNS 服务器。可以是一个值，也可以是一个列表。 dns: 8.8.8.8 dns: - 8.8.8.8 - 114.114.114.114 dns_search 配置 DNS 搜索域。可以是一个值，也可以是一个列表。 dns_search: example.com dns_search: - domain1.example.com - domain2.example.com tmpfs 挂载一个 tmpfs 文件系统到容器。 tmpfs: /run tmpfs: - /run - /tmp env_file 从文件中获取环境变量，可以为单独的文件路径或列表。 如果通过 docker-compose -f FILE 方式来指定 Compose 模板文件，则 env_file 中变量的路径会基于模板文件路径。 如果有变量名称与 environment 指令冲突，则按照惯例，以后者为准。 env_file: .env env_file: - ./common.env - ./apps/web.env - /opt/secrets.env 环境变量文件中每一行必须符合格式，支持 # 开头的注释行。 # common.env: Set development environment PROG_ENV=development environment 设置环境变量。你可以使用数组或字典两种格式。 只给定名称的变量会自动获取运行 Compose 主机上对应变量的值，可以用来防止泄露不必要的数据。 environment: RACK_ENV: development SESSION_SECRET: environment: - RACK_ENV=development - SESSION_SECRET 如果变量名称或者值中用到 true|false，yes|no 等表达 布尔 含义的词汇，最好放到引号里，避免 YAML 自动解析某些内容为对应的布尔语义。这些特定词汇，包括 y|Y|yes|Yes|YES|n|N|no|No|NO|true|True|TRUE|false|False|FALSE|on|On|ON|off|Off|OFF expose 暴露端口，但不映射到宿主机，只被连接的服务访问。 仅可以指定内部端口为参数 expose: - \"3000\" - \"8000\" external_links 注意：不建议使用该指令。 链接到 docker-compose.yml 外部的容器，甚至并非 Compose 管理的外部容器。 external_links: - redis_1 - project_db_1:mysql - project_db_1:postgresql extra_hosts 类似 Docker 中的 --add-host 参数，指定额外的 host 名称映射信息。 extra_hosts: - \"googledns:8.8.8.8\" - \"dockerhub:52.1.157.61\" 会在启动后的服务容器中 /etc/hosts 文件中添加如下两条条目。 8.8.8.8 googledns 52.1.157.61 dockerhub healthcheck 通过命令检查容器是否健康运行。 healthcheck: test: [\"CMD\", \"curl\", \"-f\", \"http://localhost\"] interval: 1m30s timeout: 10s retries: 3 image 指定为镜像名称或镜像 ID。如果镜像在本地不存在，Compose 将会尝试拉取这个镜像。 image: ubuntu image: orchardup/postgresql image: a4bc65fd labels 为容器添加 Docker 元数据（metadata）信息。例如可以为容器添加辅助说明信息。 labels: com.startupteam.description: \"webapp for a startup team\" com.startupteam.department: \"devops department\" com.startupteam.release: \"rc3 for v1.0\" links 注意：不推荐使用该指令。 logging 配置日志选项。 logging: driver: syslog options: syslog-address: \"tcp://192.168.0.42:123\" 目前支持三种日志驱动类型。 driver: \"json-file\" driver: \"syslog\" driver: \"none\" options 配置日志驱动的相关参数。 options: max-size: \"200k\" max-file: \"10\" network_mode 设置网络模式。使用和 docker run 的 --network 参数一样的值。 network_mode: \"bridge\" network_mode: \"host\" network_mode: \"none\" network_mode: \"service:[service name]\" network_mode: \"container:[container name/id]\" networks 配置容器连接的网络。 version: \"3\" services: some-service: networks: - some-network - other-network networks: some-network: other-network: pid 跟主机系统共享进程命名空间。打开该选项的容器之间，以及容器和宿主机系统之间可以通过进程 ID 来相互访问和操作。 pid: \"host\" ports 暴露端口信息。 使用宿主端口：容器端口 (HOST:CONTAINER) 格式，或者仅仅指定容器的端口（宿主将会随机选择端口）都可以。 ports: - \"3000\" - \"8000:8000\" - \"49100:22\" - \"127.0.0.1:8001:8001\" 注意：当使用 HOST:CONTAINER 格式来映射端口时，如果你使用的容器端口小于 60 并且没放到引号里，可能会得到错误结果，因为 YAML 会自动解析 xx:yy 这种数字格式为 60 进制。为避免出现这种问题，建议数字串都采用引号包括起来的字符串格式。 secrets 存储敏感数据，例如 mysql 服务密码。 version: \"3.1\" services: mysql: image: mysql environment: MYSQL_ROOT_PASSWORD_FILE: /run/secrets/db_root_password secrets: - db_root_password - my_other_secret secrets: my_secret: file: ./my_secret.txt my_other_secret: external: true security_opt 指定容器模板标签（label）机制的默认属性（用户、角色、类型、级别等）。例如配置标签的用户名和角色名。 security_opt: - label:user:USER - label:role:ROLE stop_signal 设置另一个信号来停止容器。在默认情况下使用的是 SIGTERM 停止容器。 stop_signal: SIGUSR1 sysctls 配置容器内核参数。 sysctls: net.core.somaxconn: 1024 net.ipv4.tcp_syncookies: 0 sysctls: - net.core.somaxconn=1024 - net.ipv4.tcp_syncookies=0 ulimits 指定容器的 ulimits 限制值。 例如，指定最大进程数为 65535，指定文件句柄数为 20000（软限制，应用可以随时修改，不能超过硬限制） 和 40000（系统硬限制，只能 root 用户提高）。 ulimits: nproc: 65535 nofile: soft: 20000 hard: 40000 volumes 数据卷所挂载路径设置。可以设置为宿主机路径(HOST:CONTAINER)或者数据卷名称(VOLUME:CONTAINER)，并且可以设置访问模式 （HOST:CONTAINER:ro）。 该指令中路径支持相对路径。 volumes: - /var/lib/mysql - cache/:/tmp/cache - ~/configs:/etc/configs/:ro 如果路径为数据卷名称，必须在文件中配置数据卷。 version: \"3\" services: my_src: image: mysql:8.0 volumes: - mysql_data:/var/lib/mysql volumes: mysql_data: 其它指令 此外，还有包括 domainname, entrypoint, hostname, ipc, mac_address, privileged, read_only, shm_size, restart, stdin_open, tty, user, working_dir 等指令，基本跟 docker run 中对应参数的功能一致。 指定服务容器启动后执行的入口文件。 entrypoint: /code/entrypoint.sh 指定容器中运行应用的用户名。 user: nginx 指定容器中工作目录。 working_dir: /code 指定容器中搜索域名、主机名、mac 地址等。 domainname: your_website.com hostname: test mac_address: 08-00-27-00-0C-0A 允许容器中运行一些特权命令。 privileged: true 指定容器退出后的重启策略为始终重启。该命令对保持服务始终运行十分有效，在生产环境中推荐配置为 always 或者 unless-stopped。 restart: always 以只读模式挂载容器的 root 文件系统，意味着不能对容器内容进行修改。 read_only: true 打开标准输入，可以接受外部输入。 stdin_open: true 模拟一个伪终端。 tty: true 读取变量 Compose 模板文件支持动态读取主机的系统环境变量和当前目录下的 .env 文件中的变量。 例如，下面的 Compose 文件将从运行它的环境中读取变量 ${MONGO_VERSION} 的值，并写入执行的指令中。 version: \"3\" services: db: image: \"mongo:${MONGO_VERSION}\" 如果执行 MONGO_VERSION=3.2 docker-compose up 则会启动一个 mongo:3.2 镜像的容器；如果执行 MONGO_VERSION=2.8 docker-compose up 则会启动一个 mongo:2.8 镜像的容器。 若当前目录存在 .env 文件，执行 docker-compose 命令时将从该文件中读取变量。 在当前目录新建 .env 文件并写入以下内容。 # 支持 # 号注释 MONGO_VERSION=3.6 执行 docker-compose up 则会启动一个 mongo:3.6 镜像的容器。 参考资料 官方文档 awesome-compose Copyright © Zhenhai Gao 2021 all right reserved发布时间： 2024-06-10 23:03:15 "},"docker/docker-compose/django.html":{"url":"docker/docker-compose/django.html","title":"实战 Django","keywords":"","body":"使用 Django使用 Django 本小节内容适合 Python 开发人员阅读。 我们现在将使用 Docker Compose 配置并运行一个 Django/PostgreSQL 应用。 在一切工作开始前，需要先编辑好三个必要的文件。 第一步，因为应用将要运行在一个满足所有环境依赖的 Docker 容器里面，那么我们可以通过编辑 Dockerfile 文件来指定 Docker 容器要安装内容。内容如下： FROM python:3 ENV PYTHONUNBUFFERED 1 RUN mkdir /code WORKDIR /code COPY requirements.txt /code/ RUN pip install -r requirements.txt COPY . /code/ 以上内容指定应用将使用安装了 Python 以及必要依赖包的镜像。更多关于如何编写 Dockerfile 文件的信息可以查看 Dockerfile 使用。 第二步，在 requirements.txt 文件里面写明需要安装的具体依赖包名。 Django>=2.0,=2.7, 第三步，docker-compose.yml 文件将把所有的东西关联起来。它描述了应用的构成（一个 web 服务和一个数据库）、使用的 Docker 镜像、镜像之间的连接、挂载到容器的卷，以及服务开放的端口。 version: \"3\" services: db: image: postgres environment: POSTGRES_PASSWORD: 'postgres' web: build: . command: python manage.py runserver 0.0.0.0:8000 volumes: - .:/code ports: - \"8000:8000\" 查看 docker-compose.yml 章节 了解更多详细的工作机制。 现在我们就可以使用 docker-compose run 命令启动一个 Django 应用了。 $ docker-compose run web django-admin startproject django_example . 由于 web 服务所使用的镜像并不存在，所以 Compose 会首先使用 Dockerfile 为 web 服务构建一个镜像，接着使用这个镜像在容器里运行 django-admin startproject django_example 指令。 这将在当前目录生成一个 Django 应用。 $ ls Dockerfile docker-compose.yml django_example manage.py requirements.txt 如果你的系统是 Linux,记得更改文件权限。 $ sudo chown -R $USER:$USER . 首先，我们要为应用设置好数据库的连接信息。用以下内容替换 django_example/settings.py 文件中 DATABASES = ... 定义的节点内容。 DATABASES = { 'default': { 'ENGINE': 'django.db.backends.postgresql', 'NAME': 'postgres', 'USER': 'postgres', 'HOST': 'db', 'PORT': 5432, 'PASSWORD': 'postgres', } } 这些信息是在 postgres 镜像固定设置好的。然后，运行 docker-compose up ： $ docker-compose up django_db_1 is up-to-date Creating django_web_1 ... Creating django_web_1 ... done Attaching to django_db_1, django_web_1 db_1 | The files belonging to this database system will be owned by user \"postgres\". db_1 | This user must also own the server process. db_1 | db_1 | The database cluster will be initialized with locale \"en_US.utf8\". db_1 | The default database encoding has accordingly been set to \"UTF8\". db_1 | The default text search configuration will be set to \"english\". web_1 | Performing system checks... web_1 | web_1 | System check identified no issues (0 silenced). web_1 | web_1 | November 23, 2017 - 06:21:19 web_1 | Django version 1.11.7, using settings 'django_example.settings' web_1 | Starting development server at http://0.0.0.0:8000/ web_1 | Quit the server with CONTROL-C. 这个 Django 应用已经开始在你的 Docker 守护进程里监听着 8000 端口了。打开 127.0.0.1:8000 即可看到 Django 欢迎页面。 你还可以在 Docker 上运行其它的管理命令，例如对于同步数据库结构这种事，在运行完 docker-compose up 后，在另外一个终端进入文件夹运行以下命令即可： $ docker-compose run web python manage.py syncdb Copyright © Zhenhai Gao 2021 all right reserved发布时间： 2024-06-10 23:03:15 "},"docker/docker-compose/rails.html":{"url":"docker/docker-compose/rails.html","title":"实战 Rails","keywords":"","body":"使用 Rails使用 Rails 本小节内容适合 Ruby 开发人员阅读。 我们现在将使用 Compose 配置并运行一个 Rails/PostgreSQL 应用。 在一切工作开始前，需要先设置好三个必要的文件。 首先，因为应用将要运行在一个满足所有环境依赖的 Docker 容器里面，那么我们可以通过编辑 Dockerfile 文件来指定 Docker 容器要安装内容。内容如下： FROM ruby RUN apt-get update -qq && apt-get install -y build-essential libpq-dev RUN mkdir /myapp WORKDIR /myapp ADD Gemfile /myapp/Gemfile RUN bundle install ADD . /myapp 以上内容指定应用将使用安装了 Ruby、Bundler 以及其依赖件的镜像。更多关于如何编写 Dockerfile 文件的信息可以查看 Dockerfile 使用。 下一步，我们需要一个引导加载 Rails 的文件 Gemfile 。 等一会儿它还会被 rails new 命令覆盖重写。 source 'https://rubygems.org' gem 'rails', '4.0.2' 最后，docker-compose.yml 文件才是最神奇的地方。 docker-compose.yml 文件将把所有的东西关联起来。它描述了应用的构成（一个 web 服务和一个数据库）、每个镜像的来源（数据库运行在使用预定义的 PostgreSQL 镜像，web 应用侧将从本地目录创建）、镜像之间的连接，以及服务开放的端口。 version: \"3\" services: db: image: postgres ports: - \"5432\" web: build: . command: bundle exec rackup -p 3000 volumes: - .:/myapp ports: - \"3000:3000\" 所有文件就绪后，我们就可以通过使用 docker-compose run 命令生成应用的骨架了。 $ docker-compose run web rails new . --force --database=postgresql --skip-bundle Compose 会先使用 Dockerfile 为 web 服务创建一个镜像，接着使用这个镜像在容器里运行 rails new 和它之后的命令。一旦这个命令运行完后，应该就可以看一个崭新的应用已经生成了。 $ ls Dockerfile app docker-compose.yml tmp Gemfile bin lib vendor Gemfile.lock condocker-compose log README.rdoc condocker-compose.ru public Rakefile db test 在新的 Gemfile 文件去掉加载 therubyracer 的行的注释，这样我们便可以使用 Javascript 运行环境： gem 'therubyracer', platforms: :ruby 现在我们已经有一个新的 Gemfile 文件，需要再重新创建镜像。（这个会步骤会改变 Dockerfile 文件本身，所以需要重建一次）。 $ docker-compose build 应用现在就可以启动了，但配置还未完成。Rails 默认读取的数据库目标是 localhost ，我们需要手动指定容器的 db 。同样的，还需要把用户名修改成和 postgres 镜像预定的一致。 打开最新生成的 database.yml 文件。用以下内容替换： development: &default adapter: postgresql encoding: unicode database: postgres pool: 5 username: postgres password: host: db test: 现在就可以启动应用了。 $ docker-compose up 如果一切正常，你应该可以看到 PostgreSQL 的输出，几秒后可以看到这样的重复信息： myapp_web_1 | [2014-01-17 17:16:29] INFO WEBrick 1.3.1 myapp_web_1 | [2014-01-17 17:16:29] INFO ruby 2.0.0 (2013-11-22) [x86_64-linux-gnu] myapp_web_1 | [2014-01-17 17:16:29] INFO WEBrick::HTTPServer#start: pid=1 port=3000 最后， 我们需要做的是创建数据库，打开另一个终端，运行： $ docker-compose run web rake db:create 这个 web 应用已经开始在你的 docker 守护进程里面监听着 3000 端口了。 Copyright © Zhenhai Gao 2021 all right reserved发布时间： 2024-06-10 23:03:15 "},"docker/docker-compose/wordpress.html":{"url":"docker/docker-compose/wordpress.html","title":"实战 WordPress","keywords":"","body":"使用 WordPress创建空文件夹创建 docker-compose.yml 文件构建并运行项目使用 WordPress 本小节内容适合 PHP 开发人员阅读。 Compose 可以很便捷的让 Wordpress 运行在一个独立的环境中。 创建空文件夹 假设新建一个名为 wordpress 的文件夹，然后进入这个文件夹。 创建 docker-compose.yml 文件 docker-compose.yml 文件将开启一个 wordpress 服务和一个独立的 MySQL 实例： version: \"3\" services: db: image: mysql:8.0 command: - --default_authentication_plugin=mysql_native_password - --character-set-server=utf8mb4 - --collation-server=utf8mb4_unicode_ci volumes: - db_data:/var/lib/mysql restart: always environment: MYSQL_ROOT_PASSWORD: somewordpress MYSQL_DATABASE: wordpress MYSQL_USER: wordpress MYSQL_PASSWORD: wordpress wordpress: depends_on: - db image: wordpress:latest ports: - \"8000:80\" restart: always environment: WORDPRESS_DB_HOST: db:3306 WORDPRESS_DB_USER: wordpress WORDPRESS_DB_PASSWORD: wordpress volumes: db_data: 构建并运行项目 运行 docker-compose up -d Compose 就会拉取镜像再创建我们所需要的镜像，然后启动 wordpress 和数据库容器。 接着浏览器访问 127.0.0.1:8000 端口就能看到 WordPress 安装界面了。 Copyright © Zhenhai Gao 2021 all right reserved发布时间： 2024-06-10 23:03:15 "},"docker/docker-compose/lnmp.html":{"url":"docker/docker-compose/lnmp.html","title":"实战 LNMP","keywords":"","body":"使用 compose 搭建 LNMP 环境使用 compose 搭建 LNMP 环境 本项目的维护者 khs1994 的开源项目 khs1994-docker/lnmp 使用 Docker Compose 搭建了一套 LNMP 环境，各位开发者可以参考该项目在 Docker 或 Kubernetes 中运行 LNMP。 Copyright © Zhenhai Gao 2021 all right reserved发布时间： 2024-06-10 23:03:15 "},"docker/security/":{"url":"docker/security/","title":"安全","keywords":"","body":"安全安全 评估 Docker 的安全性时，主要考虑三个方面: 由内核的命名空间和控制组机制提供的容器内在安全 Docker 程序（特别是服务端）本身的抗攻击性 内核安全性的加强机制对容器安全性的影响 Copyright © Zhenhai Gao 2021 all right reserved发布时间： 2024-06-10 23:03:15 "},"docker/security/kernel-ns.html":{"url":"docker/security/kernel-ns.html","title":"内核命名空间","keywords":"","body":"内核命名空间内核命名空间 Docker 容器和 LXC 容器很相似，所提供的安全特性也差不多。当用 docker run 启动一个容器时，在后台 Docker 为容器创建了一个独立的命名空间和控制组集合。 命名空间提供了最基础也是最直接的隔离，在容器中运行的进程不会被运行在主机上的进程和其它容器发现和作用。 每个容器都有自己独有的网络栈，意味着它们不能访问其他容器的 sockets 或接口。不过，如果主机系统上做了相应的设置，容器可以像跟主机交互一样的和其他容器交互。当指定公共端口或使用 links 来连接 2 个容器时，容器就可以相互通信了（可以根据配置来限制通信的策略）。 从网络架构的角度来看，所有的容器通过本地主机的网桥接口相互通信，就像物理机器通过物理交换机通信一样。 那么，内核中实现命名空间和私有网络的代码是否足够成熟？ 内核命名空间从 2.6.15 版本（2008 年 7 月发布）之后被引入，数年间，这些机制的可靠性在诸多大型生产系统中被实践验证。 实际上，命名空间的想法和设计提出的时间要更早，最初是为了在内核中引入一种机制来实现 OpenVZ 的特性。 而 OpenVZ 项目早在 2005 年就发布了，其设计和实现都已经十分成熟。 Copyright © Zhenhai Gao 2021 all right reserved发布时间： 2024-06-10 23:03:15 "},"docker/security/control-group.html":{"url":"docker/security/control-group.html","title":"控制组","keywords":"","body":"控制组控制组 控制组是 Linux 容器机制的另外一个关键组件，负责实现资源的审计和限制。 它提供了很多有用的特性；以及确保各个容器可以公平地分享主机的内存、CPU、磁盘 IO 等资源；当然，更重要的是，控制组确保了当容器内的资源使用产生压力时不会连累主机系统。 尽管控制组不负责隔离容器之间相互访问、处理数据和进程，它在防止拒绝服务（DDOS）攻击方面是必不可少的。尤其是在多用户的平台（比如公有或私有的 PaaS）上，控制组十分重要。例如，当某些应用程序表现异常的时候，可以保证一致地正常运行和性能。 控制组机制始于 2006 年，内核从 2.6.24 版本开始被引入。 Copyright © Zhenhai Gao 2021 all right reserved发布时间： 2024-06-10 23:03:15 "},"docker/security/daemon-sec.html":{"url":"docker/security/daemon-sec.html","title":"服务端防护","keywords":"","body":"Docker服务端的防护Docker服务端的防护 运行一个容器或应用程序的核心是通过 Docker 服务端。Docker 服务的运行目前需要 root 权限，因此其安全性十分关键。 首先，确保只有可信的用户才可以访问 Docker 服务。Docker 允许用户在主机和容器间共享文件夹，同时不需要限制容器的访问权限，这就容易让容器突破资源限制。例如，恶意用户启动容器的时候将主机的根目录/映射到容器的 /host 目录中，那么容器理论上就可以对主机的文件系统进行任意修改了。这听起来很疯狂？但是事实上几乎所有虚拟化系统都允许类似的资源共享，而没法禁止用户共享主机根文件系统到虚拟机系统。 这将会造成很严重的安全后果。因此，当提供容器创建服务时（例如通过一个 web 服务器），要更加注意进行参数的安全检查，防止恶意的用户用特定参数来创建一些破坏性的容器。 为了加强对服务端的保护，Docker 的 REST API（客户端用来跟服务端通信）在 0.5.2 之后使用本地的 Unix 套接字机制替代了原先绑定在 127.0.0.1 上的 TCP 套接字，因为后者容易遭受跨站脚本攻击。现在用户使用 Unix 权限检查来加强套接字的访问安全。 用户仍可以利用 HTTP 提供 REST API 访问。建议使用安全机制，确保只有可信的网络或 VPN，或证书保护机制（例如受保护的 stunnel 和 ssl 认证）下的访问可以进行。此外，还可以使用 HTTPS 和证书 来加强保护。 最近改进的 Linux 命名空间机制将可以实现使用非 root 用户来运行全功能的容器。这将从根本上解决了容器和主机之间共享文件系统而引起的安全问题。 终极目标是改进 2 个重要的安全特性： 将容器的 root 用户 映射到本地主机上的非 root 用户，减轻容器和主机之间因权限提升而引起的安全问题； 允许 Docker 服务端在 非 root 权限(rootless 模式) 下运行，利用安全可靠的子进程来代理执行需要特权权限的操作。这些子进程将只允许在限定范围内进行操作，例如仅仅负责虚拟网络设定或文件系统管理、配置操作等。 最后，建议采用专用的服务器来运行 Docker 和相关的管理服务（例如管理服务比如 ssh 监控和进程监控、管理工具 nrpe、collectd 等）。其它的业务服务都放到容器中去运行。 Copyright © Zhenhai Gao 2021 all right reserved发布时间： 2024-06-10 23:03:15 "},"docker/security/kernel-capability.html":{"url":"docker/security/kernel-capability.html","title":"内核能力机制","keywords":"","body":"内核能力机制内核能力机制 能力机制（Capability） 是 Linux 内核一个强大的特性，可以提供细粒度的权限访问控制。 Linux 内核自 2.2 版本起就支持能力机制，它将权限划分为更加细粒度的操作能力，既可以作用在进程上，也可以作用在文件上。 例如，一个 Web 服务进程只需要绑定一个低于 1024 的端口的权限，并不需要 root 权限。那么它只需要被授权 net_bind_service 能力即可。此外，还有很多其他的类似能力来避免进程获取 root 权限。 默认情况下，Docker 启动的容器被严格限制只允许使用内核的一部分能力。 使用能力机制对加强 Docker 容器的安全有很多好处。通常，在服务器上会运行一堆需要特权权限的进程，包括有 ssh、cron、syslogd、硬件管理工具模块（例如负载模块）、网络配置工具等等。容器跟这些进程是不同的，因为几乎所有的特权进程都由容器以外的支持系统来进行管理。 ssh 访问被主机上ssh服务来管理； cron 通常应该作为用户进程执行，权限交给使用它服务的应用来处理； 日志系统可由 Docker 或第三方服务管理； 硬件管理无关紧要，容器中也就无需执行 udevd 以及类似服务； 网络管理也都在主机上设置，除非特殊需求，容器不需要对网络进行配置。 从上面的例子可以看出，大部分情况下，容器并不需要“真正的” root 权限，容器只需要少数的能力即可。为了加强安全，容器可以禁用一些没必要的权限。 完全禁止任何 mount 操作； 禁止直接访问本地主机的套接字； 禁止访问一些文件系统的操作，比如创建新的设备、修改文件属性等； 禁止模块加载。 这样，就算攻击者在容器中取得了 root 权限，也不能获得本地主机的较高权限，能进行的破坏也有限。 默认情况下，Docker采用 白名单 机制，禁用必需功能之外的其它权限。 当然，用户也可以根据自身需求来为 Docker 容器启用额外的权限。 Copyright © Zhenhai Gao 2021 all right reserved发布时间： 2024-06-10 23:03:15 "},"docker/security/other-feature.html":{"url":"docker/security/other-feature.html","title":"其它安全特性","keywords":"","body":"其它安全特性其它安全特性 除了能力机制之外，还可以利用一些现有的安全机制来增强使用 Docker 的安全性，例如 TOMOYO, AppArmor, Seccomp, SELinux, GRSEC 等。 Docker 当前默认只启用了能力机制。用户可以采用多种方案来加强 Docker 主机的安全，例如： 在内核中启用 GRSEC 和 PAX，这将增加很多编译和运行时的安全检查；通过地址随机化避免恶意探测等。并且，启用该特性不需要 Docker 进行任何配置。 使用一些有增强安全特性的容器模板，比如带 AppArmor 的模板和 Redhat 带 SELinux 策略的模板。这些模板提供了额外的安全特性。 用户可以自定义访问控制机制来定制安全策略。 跟其它添加到 Docker 容器的第三方工具一样（比如网络拓扑和文件系统共享），有很多类似的机制，在不改变 Docker 内核情况下就可以加固现有的容器。 Copyright © Zhenhai Gao 2021 all right reserved发布时间： 2024-06-10 23:03:15 "},"docker/security/summary.html":{"url":"docker/security/summary.html","title":"总结","keywords":"","body":"总结总结 总体来看，Docker 容器还是十分安全的，特别是在容器内不使用 root 权限来运行进程的话。 另外，用户可以使用现有工具，比如 Apparmor, Seccomp, SELinux, GRSEC 来增强安全性；甚至自己在内核中实现更复杂的安全机制。 Copyright © Zhenhai Gao 2021 all right reserved发布时间： 2024-06-10 23:03:15 "},"docker/underly/":{"url":"docker/underly/","title":"底层实现","keywords":"","body":"底层实现底层实现 Docker 底层的核心技术包括 Linux 上的命名空间（Namespaces）、控制组（Control groups）、Union 文件系统（Union file systems）和容器格式（Container format）。 我们知道，传统的虚拟机通过在宿主主机中运行 hypervisor 来模拟一整套完整的硬件环境提供给虚拟机的操作系统。虚拟机系统看到的环境是可限制的，也是彼此隔离的。 这种直接的做法实现了对资源最完整的封装，但很多时候往往意味着系统资源的浪费。 例如，以宿主机和虚拟机系统都为 Linux 系统为例，虚拟机中运行的应用其实可以利用宿主机系统中的运行环境。 我们知道，在操作系统中，包括内核、文件系统、网络、PID、UID、IPC、内存、硬盘、CPU 等等，所有的资源都是应用进程直接共享的。 要想实现虚拟化，除了要实现对内存、CPU、网络IO、硬盘IO、存储空间等的限制外，还要实现文件系统、网络、PID、UID、IPC等等的相互隔离。 前者相对容易实现一些，后者则需要宿主机系统的深入支持。 随着 Linux 系统对于命名空间功能的完善实现，程序员已经可以实现上面的所有需求，让某些进程在彼此隔离的命名空间中运行。大家虽然都共用一个内核和某些运行时环境（例如一些系统命令和系统库），但是彼此却看不到，都以为系统中只有自己的存在。这种机制就是容器（Container），利用命名空间来做权限的隔离控制，利用 cgroups 来做资源分配。 Copyright © Zhenhai Gao 2021 all right reserved发布时间： 2024-06-10 23:03:15 "},"docker/underly/arch.html":{"url":"docker/underly/arch.html","title":"基本架构","keywords":"","body":"基本架构基本架构 Docker 采用了 C/S 架构，包括客户端和服务端。Docker 守护进程 （Daemon）作为服务端接受来自客户端的请求，并处理这些请求（创建、运行、分发容器）。 客户端和服务端既可以运行在一个机器上，也可通过 socket 或者 RESTful API 来进行通信。 Docker 守护进程一般在宿主主机后台运行，等待接收来自客户端的消息。 Docker 客户端则为用户提供一系列可执行命令，用户用这些命令实现跟 Docker 守护进程交互。 Copyright © Zhenhai Gao 2021 all right reserved发布时间： 2024-06-10 23:03:15 "},"docker/underly/namespace.html":{"url":"docker/underly/namespace.html","title":"命名空间","keywords":"","body":"命名空间pid 命名空间net 命名空间ipc 命名空间mnt 命名空间uts 命名空间user 命名空间命名空间 命名空间是 Linux 内核一个强大的特性。每个容器都有自己单独的命名空间，运行在其中的应用都像是在独立的操作系统中运行一样。命名空间保证了容器之间彼此互不影响。 pid 命名空间 不同用户的进程就是通过 pid 命名空间隔离开的，且不同命名空间中可以有相同 pid。所有的 LXC 进程在 Docker 中的父进程为 Docker 进程，每个 LXC 进程具有不同的命名空间。同时由于允许嵌套，因此可以很方便的实现嵌套的 Docker 容器。 net 命名空间 有了 pid 命名空间，每个命名空间中的 pid 能够相互隔离，但是网络端口还是共享 host 的端口。网络隔离是通过 net 命名空间实现的， 每个 net 命名空间有独立的 网络设备，IP 地址，路由表，/proc/net 目录。这样每个容器的网络就能隔离开来。Docker 默认采用 veth 的方式，将容器中的虚拟网卡同 host 上的一 个Docker 网桥 docker0 连接在一起。 ipc 命名空间 容器中进程交互还是采用了 Linux 常见的进程间交互方法(interprocess communication - IPC)， 包括信号量、消息队列和共享内存等。然而同 VM 不同的是，容器的进程间交互实际上还是 host 上具有相同 pid 命名空间中的进程间交互，因此需要在 IPC 资源申请时加入命名空间信息，每个 IPC 资源有一个唯一的 32 位 id。 mnt 命名空间 类似 chroot，将一个进程放到一个特定的目录执行。mnt 命名空间允许不同命名空间的进程看到的文件结构不同，这样每个命名空间 中的进程所看到的文件目录就被隔离开了。同 chroot 不同，每个命名空间中的容器在 /proc/mounts 的信息只包含所在命名空间的 mount point。 uts 命名空间 UTS(\"UNIX Time-sharing System\") 命名空间允许每个容器拥有独立的 hostname 和 domain name， 使其在网络上可以被视作一个独立的节点而非 主机上的一个进程。 user 命名空间 每个容器可以有不同的用户和组 id， 也就是说可以在容器内用容器内部的用户执行程序而非主机上的用户。 *注：更多关于 Linux 上命名空间的信息，请阅读 这篇文章。 Copyright © Zhenhai Gao 2021 all right reserved发布时间： 2024-06-10 23:03:15 "},"docker/underly/cgroups.html":{"url":"docker/underly/cgroups.html","title":"控制组","keywords":"","body":"控制组控制组 控制组（cgroups）是 Linux 内核的一个特性，主要用来对共享资源进行隔离、限制、审计等。只有能控制分配到容器的资源，才能避免当多个容器同时运行时的对系统资源的竞争。 控制组技术最早是由 Google 的程序员在 2006 年提出，Linux 内核自 2.6.24 开始支持。 控制组可以提供对容器的内存、CPU、磁盘 IO 等资源的限制和审计管理。 Copyright © Zhenhai Gao 2021 all right reserved发布时间： 2024-06-10 23:03:15 "},"docker/underly/ufs.html":{"url":"docker/underly/ufs.html","title":"联合文件系统","keywords":"","body":"联合文件系统联合文件系统 联合文件系统（UnionFS）是一种分层、轻量级并且高性能的文件系统，它支持对文件系统的修改作为一次提交来一层层的叠加，同时可以将不同目录挂载到同一个虚拟文件系统下(unite several directories into a single virtual filesystem)。 联合文件系统是 Docker 镜像的基础。镜像可以通过分层来进行继承，基于基础镜像（没有父镜像），可以制作各种具体的应用镜像。 另外，不同 Docker 容器就可以共享一些基础的文件系统层，同时再加上自己独有的改动层，大大提高了存储的效率。 Docker 中使用的 AUFS（Advanced Multi-Layered Unification Filesystem）就是一种联合文件系统。 AUFS 支持为每一个成员目录（类似 Git 的分支）设定只读（readonly）、读写（readwrite）和写出（whiteout-able）权限, 同时 AUFS 里有一个类似分层的概念, 对只读权限的分支可以逻辑上进行增量地修改(不影响只读部分的)。 Docker 目前支持的联合文件系统包括 OverlayFS, AUFS, Btrfs, VFS, ZFS 和 Device Mapper。 各 Linux 发行版 Docker 推荐使用的存储驱动如下表。 Linux 发行版 Docker 推荐使用的存储驱动 Docker on Ubuntu overlay2 (16.04 +) Docker on Debian overlay2 (Debian Stretch), aufs, devicemapper Docker on CentOS overlay2 Docker on Fedora overlay2 在可能的情况下，推荐 使用 overlay2 存储驱动，overlay2 是目前 Docker 默认的存储驱动，以前则是 aufs。你可以通过配置来使用以上提到的其他类型的存储驱动。 Copyright © Zhenhai Gao 2021 all right reserved发布时间： 2024-06-10 23:03:15 "},"docker/underly/container-format.html":{"url":"docker/underly/container-format.html","title":"容器格式","keywords":"","body":"容器格式容器格式 最初，Docker 采用了 LXC 中的容器格式。从 0.7 版本以后开始去除 LXC，转而使用自行开发的 libcontainer，从 1.11 开始，则进一步演进为使用 runC 和 containerd。 Copyright © Zhenhai Gao 2021 all right reserved发布时间： 2024-06-10 23:03:15 "},"docker/underly/network.html":{"url":"docker/underly/network.html","title":"网络","keywords":"","body":"Docker 网络实现基本原理创建网络参数网络配置细节Docker 网络实现 Docker 的网络实现其实就是利用了 Linux 上的网络命名空间和虚拟网络设备（特别是 veth pair）。建议先熟悉了解这两部分的基本概念再阅读本章。 基本原理 首先，要实现网络通信，机器需要至少一个网络接口（物理接口或虚拟接口）来收发数据包；此外，如果不同子网之间要进行通信，需要路由机制。 Docker 中的网络接口默认都是虚拟的接口。虚拟接口的优势之一是转发效率较高。 Linux 通过在内核中进行数据复制来实现虚拟接口之间的数据转发，发送接口的发送缓存中的数据包被直接复制到接收接口的接收缓存中。对于本地系统和容器内系统看来就像是一个正常的以太网卡，只是它不需要真正同外部网络设备通信，速度要快很多。 Docker 容器网络就利用了这项技术。它在本地主机和容器内分别创建一个虚拟接口，并让它们彼此连通（这样的一对接口叫做 veth pair）。 创建网络参数 Docker 创建一个容器的时候，会执行如下操作： 创建一对虚拟接口，分别放到本地主机和新容器中； 本地主机一端桥接到默认的 docker0 或指定网桥上，并具有一个唯一的名字，如 veth65f9； 容器一端放到新容器中，并修改名字作为 eth0，这个接口只在容器的命名空间可见； 从网桥可用地址段中获取一个空闲地址分配给容器的 eth0，并配置默认路由到桥接网卡 veth65f9。 完成这些之后，容器就可以使用 eth0 虚拟网卡来连接其他容器和其他网络。 可以在 docker run 的时候通过 --net 参数来指定容器的网络配置，有4个可选值： --net=bridge 这个是默认值，连接到默认的网桥。 --net=host 告诉 Docker 不要将容器网络放到隔离的命名空间中，即不要容器化容器内的网络。此时容器使用本地主机的网络，它拥有完全的本地主机接口访问权限。容器进程可以跟主机其它 root 进程一样可以打开低范围的端口，可以访问本地网络服务比如 D-bus，还可以让容器做一些影响整个主机系统的事情，比如重启主机。因此使用这个选项的时候要非常小心。如果进一步的使用 --privileged=true，容器会被允许直接配置主机的网络堆栈。 --net=container:NAME_or_ID 让 Docker 将新建容器的进程放到一个已存在容器的网络栈中，新容器进程有自己的文件系统、进程列表和资源限制，但会和已存在的容器共享 IP 地址和端口等网络资源，两者进程可以直接通过 lo 环回接口通信。 --net=none 让 Docker 将新容器放到隔离的网络栈中，但是不进行网络配置。之后，用户可以自己进行配置。 网络配置细节 用户使用 --net=none 后，可以自行配置网络，让容器达到跟平常一样具有访问网络的权限。通过这个过程，可以了解 Docker 配置网络的细节。 首先，启动一个 /bin/bash 容器，指定 --net=none 参数。 $ docker run -i -t --rm --net=none base /bin/bash root@63f36fc01b5f:/# 在本地主机查找容器的进程 id，并为它创建网络命名空间。 $ docker inspect -f '{{.State.Pid}}' 63f36fc01b5f 2778 $ pid=2778 $ sudo mkdir -p /var/run/netns $ sudo ln -s /proc/$pid/ns/net /var/run/netns/$pid 检查桥接网卡的 IP 和子网掩码信息。 $ ip addr show docker0 21: docker0: ... inet 172.17.42.1/16 scope global docker0 ... 创建一对 “veth pair” 接口 A 和 B，绑定 A 到网桥 docker0，并启用它 $ sudo ip link add A type veth peer name B $ sudo brctl addif docker0 A $ sudo ip link set A up 将B放到容器的网络命名空间，命名为 eth0，启动它并配置一个可用 IP（桥接网段）和默认网关。 $ sudo ip link set B netns $pid $ sudo ip netns exec $pid ip link set dev B name eth0 $ sudo ip netns exec $pid ip link set eth0 up $ sudo ip netns exec $pid ip addr add 172.17.42.99/16 dev eth0 $ sudo ip netns exec $pid ip route add default via 172.17.42.1 以上，就是 Docker 配置网络的具体过程。 当容器结束后，Docker 会清空容器，容器内的 eth0 会随网络命名空间一起被清除，A 接口也被自动从 docker0 卸载。 此外，用户可以使用 ip netns exec 命令来在指定网络命名空间中进行配置，从而配置容器内的网络。 Copyright © Zhenhai Gao 2021 all right reserved发布时间： 2024-06-10 23:03:15 "},"docker/cases/os/":{"url":"docker/cases/os/","title":"实战案例 - 操作系统","keywords":"","body":"操作系统操作系统 目前常用的 Linux 发行版主要包括 Debian/Ubuntu 系列和 CentOS/Fedora 系列。 前者以自带软件包版本较新而出名；后者则宣称运行更稳定一些。选择哪个操作系统取决于读者的具体需求。 使用 Docker，读者只需要一个命令就能快速获取一个 Linux 发行版镜像，这是以往包括各种虚拟化技术都难以实现的。这些镜像一般都很精简，但是可以支持完整 Linux 系统的大部分功能。 本章将介绍如何使用 Docker 安装和使用 Busybox、Alphine、Debian/Ubuntu、CentOS/Fedora 等操作系统。 Copyright © Zhenhai Gao 2021 all right reserved发布时间： 2024-06-10 23:03:15 "},"docker/cases/os/busybox.html":{"url":"docker/cases/os/busybox.html","title":"Busybox","keywords":"","body":"Busybox简介获取官方镜像运行 busybox相关资源Busybox 简介 BusyBox 是一个集成了一百多个最常用 Linux 命令和工具（如 cat、echo、grep、mount、telnet 等）的精简工具箱，它只需要几 MB 的大小，很方便进行各种快速验证，被誉为“Linux 系统的瑞士军刀”。 BusyBox 可运行于多款 POSIX 环境的操作系统中，如 Linux（包括 Android）、Hurd、FreeBSD 等。 获取官方镜像 可以使用 docker pull 指令下载 busybox:latest 镜像： $ docker pull busybox:latest latest: Pulling from library/busybox 5c4213be9af9: Pull complete Digest: sha256:c6b45a95f932202dbb27c31333c4789f45184a744060f6e569cc9d2bf1b9ad6f Status: Downloaded newer image for busybox:latest docker.io/library/busybox:latest 下载后，可以看到 busybox 镜像只有 2.433 MB： $ docker image ls REPOSITORY TAG IMAGE ID CREATED VIRTUAL SIZE busybox latest e72ac664f4f0 6 weeks ago 2.433 MB 运行 busybox 启动一个 busybox 容器，并在容器中执行 grep 命令。 $ docker run -it busybox / # grep BusyBox v1.22.1 (2014-05-22 23:22:11 UTC) multi-call binary. Usage: grep [-HhnlLoqvsriwFE] [-m N] [-A/B/C N] PATTERN/-e PATTERN.../-f FILE [FILE]... Search for PATTERN in FILEs (or stdin) -H Add 'filename:' prefix -h Do not add 'filename:' prefix -n Add 'line_no:' prefix -l Show only names of files that match -L Show only names of files that don't match -c Show only count of matching lines -o Show only the matching part of line -q Quiet. Return 0 if PATTERN is found, 1 otherwise -v Select non-matching lines -s Suppress open and read errors -r Recurse -i Ignore case -w Match whole words only -x Match whole lines only -F PATTERN is a literal (not regexp) -E PATTERN is an extended regexp -m N Match up to N times per file -A N Print N lines of trailing context -B N Print N lines of leading context -C N Same as '-A N -B N' -e PTRN Pattern to match -f FILE Read pattern from file 查看容器内的挂载信息。 / # mount overlay on / type overlay (rw,relatime,lowerdir=/var/lib/docker/overlay2/l/BOTCI5RF24AMC4A2UWF4N6ZWFP:/var/lib/docker/overlay2/l/TWVP5T5DMKJGXZOROR7CAPWGFP,upperdir=/var/lib/docker/overlay2/801ef0bf6cce35288dbb8fe00a4f9cc47760444693bfdf339ed0bdcf926e12a3/diff,workdir=/var/lib/docker/overlay2/801ef0bf6cce35288dbb8fe00a4f9cc47760444693bfdf339ed0bdcf926e12a3/work) proc on /proc type proc (rw,nosuid,nodev,noexec,relatime) tmpfs on /dev type tmpfs (rw,nosuid,size=65536k,mode=755) devpts on /dev/pts type devpts (rw,nosuid,noexec,relatime,gid=5,mode=620,ptmxmode=666) sysfs on /sys type sysfs (ro,nosuid,nodev,noexec,relatime) tmpfs on /sys/fs/cgroup type tmpfs (ro,nosuid,nodev,noexec,relatime,mode=755) cgroup on /sys/fs/cgroup/systemd type cgroup (ro,nosuid,nodev,noexec,relatime,xattr,release_agent=/lib/systemd/systemd-cgroups-agent,name=systemd) cgroup on /sys/fs/cgroup/net_cls,net_prio type cgroup (ro,nosuid,nodev,noexec,relatime,net_cls,net_prio) cgroup on /sys/fs/cgroup/freezer type cgroup (ro,nosuid,nodev,noexec,relatime,freezer) cgroup on /sys/fs/cgroup/cpu,cpuacct type cgroup (ro,nosuid,nodev,noexec,relatime,cpu,cpuacct) cgroup on /sys/fs/cgroup/cpuset type cgroup (ro,nosuid,nodev,noexec,relatime,cpuset) cgroup on /sys/fs/cgroup/blkio type cgroup (ro,nosuid,nodev,noexec,relatime,blkio) cgroup on /sys/fs/cgroup/perf_event type cgroup (ro,nosuid,nodev,noexec,relatime,perf_event) cgroup on /sys/fs/cgroup/memory type cgroup (ro,nosuid,nodev,noexec,relatime,memory) cgroup on /sys/fs/cgroup/devices type cgroup (ro,nosuid,nodev,noexec,relatime,devices) cgroup on /sys/fs/cgroup/pids type cgroup (ro,nosuid,nodev,noexec,relatime,pids) mqueue on /dev/mqueue type mqueue (rw,nosuid,nodev,noexec,relatime) shm on /dev/shm type tmpfs (rw,nosuid,nodev,noexec,relatime,size=65536k) /dev/vda1 on /etc/resolv.conf type ext3 (rw,noatime,data=ordered) /dev/vda1 on /etc/hostname type ext3 (rw,noatime,data=ordered) /dev/vda1 on /etc/hosts type ext3 (rw,noatime,data=ordered) devpts on /dev/console type devpts (rw,nosuid,noexec,relatime,gid=5,mode=620,ptmxmode=666) proc on /proc/bus type proc (ro,relatime) proc on /proc/fs type proc (ro,relatime) proc on /proc/irq type proc (ro,relatime) proc on /proc/sys type proc (ro,relatime) proc on /proc/sysrq-trigger type proc (ro,relatime) tmpfs on /proc/acpi type tmpfs (ro,relatime) tmpfs on /proc/kcore type tmpfs (rw,nosuid,size=65536k,mode=755) tmpfs on /proc/keys type tmpfs (rw,nosuid,size=65536k,mode=755) tmpfs on /proc/timer_list type tmpfs (rw,nosuid,size=65536k,mode=755) tmpfs on /proc/sched_debug type tmpfs (rw,nosuid,size=65536k,mode=755) tmpfs on /sys/firmware type tmpfs (ro,relatime) busybox 镜像虽然小巧，但包括了大量常见的 Linux 命令，读者可以用它快速熟悉 Linux 命令。 相关资源 Busybox 官网：https://busybox.net/ Busybox 官方仓库：https://git.busybox.net/busybox/ Busybox 官方镜像：https://hub.docker.com/_/busybox/ Busybox 官方仓库：https://github.com/docker-library/busybox Copyright © Zhenhai Gao 2021 all right reserved发布时间： 2024-06-10 23:03:15 "},"docker/cases/os/alpine.html":{"url":"docker/cases/os/alpine.html","title":"Alpine","keywords":"","body":"Alpine简介获取并使用官方镜像迁移至 Alpine 基础镜像相关资源Alpine 简介 Alpine 操作系统是一个面向安全的轻型 Linux 发行版。它不同于通常 Linux 发行版，Alpine 采用了 musl libc 和 busybox 以减小系统的体积和运行时资源消耗，但功能上比 busybox 又完善的多，因此得到开源社区越来越多的青睐。在保持瘦身的同时，Alpine 还提供了自己的包管理工具 apk，可以通过 https://pkgs.alpinelinux.org/packages 网站上查询包信息，也可以直接通过 apk 命令直接查询和安装各种软件。 Alpine 由非商业组织维护的，支持广泛场景的 Linux发行版，它特别为资深/重度Linux用户而优化，关注安全，性能和资源效能。Alpine 镜像可以适用于更多常用场景，并且是一个优秀的可以适用于生产的基础系统/环境。 Alpine Docker 镜像也继承了 Alpine Linux 发行版的这些优势。相比于其他 Docker 镜像，它的容量非常小，仅仅只有 5 MB 左右（对比 Ubuntu 系列镜像接近 200 MB），且拥有非常友好的包管理机制。官方镜像来自 docker-alpine 项目。 目前 Docker 官方已开始推荐使用 Alpine 替代之前的 Ubuntu 做为基础镜像环境。这样会带来多个好处。包括镜像下载速度加快，镜像安全性提高，主机之间的切换更方便，占用更少磁盘空间等。 下表是官方镜像的大小比较： REPOSITORY TAG IMAGE ID VIRTUAL SIZE alpine latest 4e38e38c8ce0 4.799 MB debian latest 4d6ce913b130 84.98 MB ubuntu latest b39b81afc8ca 188.3 MB centos latest 8efe422e6104 210 MB 获取并使用官方镜像 由于镜像很小，下载时间往往很短，读者可以直接使用 docker run 指令直接运行一个 Alpine 容器，并指定运行的 Linux 指令，例如： $ docker run alpine echo '123' 123 迁移至 Alpine 基础镜像 目前，大部分 Docker 官方镜像都已经支持 Alpine 作为基础镜像，可以很容易进行迁移。 例如： ubuntu/debian -> alpine python:3 -> python:3-alpine ruby:2.6 -> ruby:2.6-alpine 另外，如果使用 Alpine 镜像替换 Ubuntu 基础镜像，安装软件包时需要用 apk 包管理器替换 apt 工具，如 $ apk add --no-cache Alpine 中软件安装包的名字可能会与其他发行版有所不同，可以在 https://pkgs.alpinelinux.org/packages 网站搜索并确定安装包名称。如果需要的安装包不在主索引内，但是在测试或社区索引中。那么可以按照以下方法使用这些安装包。 $ echo \"http://dl-cdn.alpinelinux.org/alpine/edge/testing\" >> /etc/apk/repositories $ apk --update add --no-cache 由于在国内访问 apk 仓库较缓慢，建议在使用 apk 之前先替换仓库地址为国内镜像。 RUN sed -i \"s/dl-cdn.alpinelinux.org/mirrors.aliyun.com/g\" /etc/apk/repositories \\ && apk add --no-cache 相关资源 Alpine 官网：https://www.alpinelinux.org/ Alpine 官方仓库：https://github.com/alpinelinux Alpine 官方镜像：https://hub.docker.com/_/alpine/ Alpine 官方镜像仓库：https://github.com/gliderlabs/docker-alpine Copyright © Zhenhai Gao 2021 all right reserved发布时间： 2024-06-10 23:03:15 "},"docker/cases/os/debian.html":{"url":"docker/cases/os/debian.html","title":"Debian Ubuntu","keywords":"","body":"Debian/UbuntuDebian 系统简介使用 Debian 官方镜像Ubuntu 系统简介使用 Ubuntu 官方镜像相关资源Debian/Ubuntu Debian 和 Ubuntu 都是目前较为流行的 Debian 系 的服务器操作系统，十分适合研发场景。Docker Hub 上提供了官方镜像，国内各大容器云服务也基本都提供了相应的支持。 Debian 系统简介 Debian 是由 GPL 和其他自由软件许可协议授权的自由软件组成的操作系统，由 Debian 计划（Debian Project） 组织维护。Debian 计划 是一个独立的、分散的组织，由 3000 人志愿者组成，接受世界多个非盈利组织的资金支持，Software in the Public Interest 提供支持并持有商标作为保护机构。Debian 以其坚守 Unix 和自由软件的精神，以及其给予用户的众多选择而闻名。现时 Debian 包括了超过 25,000 个软件包并支持 12 个计算机系统结构。 Debian 作为一个大的系统组织框架，其下有多种不同操作系统核心的分支计划，主要为采用 Linux 核心的 Debian GNU/Linux 系统，其他还有采用 GNU Hurd 核心的 Debian GNU/Hurd 系统、采用 FreeBSD 核心的 Debian GNU/kFreeBSD 系统，以及采用 NetBSD 核心的 Debian GNU/NetBSD 系统。甚至还有利用 Debian 的系统架构和工具，采用 OpenSolaris 核心构建而成的 Nexenta OS 系统。在这些 Debian 系统中，以采用 Linux 核心的 Debian GNU/Linux 最为著名。 众多的 Linux 发行版，例如 Ubuntu、Knoppix 和 Linspire 及 Xandros 等，都基于 Debian GNU/Linux。 使用 Debian 官方镜像 官方提供了大家熟知的 debian 镜像以及面向科研领域的 neurodebian 镜像。可以使用 docker run 直接运行 Debian 镜像。 $ docker run -it debian bash root@668e178d8d69:/# cat /etc/issue Debian GNU/Linux 8 Debian 镜像很适合作为基础镜像，构建自定义镜像。 Ubuntu 系统简介 Ubuntu 是一个以桌面应用为主的 GNU/Linux 操作系统，其名称来自非洲南部祖鲁语或豪萨语的“ubuntu”一词（官方译名“友帮拓”，另有“吾帮托”、“乌班图”、“有奔头”或“乌斑兔”等译名）。Ubuntu 意思是“人性”以及“我的存在是因为大家的存在”，是非洲传统的一种价值观，类似华人社会的“仁爱”思想。 Ubuntu 基于 Debian 发行版和 GNOME/Unity 桌面环境，与 Debian 的不同在于它每 6 个月会发布一个新版本，每 2 年推出一个长期支持 （Long Term Support，LTS） 版本，一般支持 3 年时间。 使用 Ubuntu 官方镜像 下面以 ubuntu:18.04 为例，演示如何使用该镜像安装一些常用软件。 首先使用 -ti 参数启动容器，登录 bash，查看 ubuntu 的发行版本号。 $ docker run -ti ubuntu:18.04 /bin/bash root@7d93de07bf76:/# cat /etc/os-release NAME=\"Ubuntu\" VERSION=\"18.04.1 LTS (Bionic Beaver)\" ID=ubuntu ID_LIKE=debian PRETTY_NAME=\"Ubuntu 18.04.1 LTS\" VERSION_ID=\"18.04\" HOME_URL=\"https://www.ubuntu.com/\" SUPPORT_URL=\"https://help.ubuntu.com/\" BUG_REPORT_URL=\"https://bugs.launchpad.net/ubuntu/\" PRIVACY_POLICY_URL=\"https://www.ubuntu.com/legal/terms-and-policies/privacy-policy\" VERSION_CODENAME=bionic UBUNTU_CODENAME=bionic 当试图直接使用 apt-get 安装一个软件的时候，会提示 E: Unable to locate package。 root@7d93de07bf76:/# apt-get install curl Reading package lists... Done Building dependency tree Reading state information... Done E: Unable to locate package curl 这并非系统不支持 apt-get 命令。Docker 镜像在制作时为了精简清除了 apt 仓库信息，因此需要先执行 apt-get update 命令来更新仓库信息。更新信息后即可成功通过 apt-get 命令来安装软件。 root@7d93de07bf76:/# apt-get update Get:1 http://archive.ubuntu.com/ubuntu bionic InRelease [242 kB] Get:2 http://security.ubuntu.com/ubuntu bionic-security InRelease [88.7 kB] Get:3 http://security.ubuntu.com/ubuntu bionic-security/multiverse amd64 Packages [7348 B] Get:4 http://security.ubuntu.com/ubuntu bionic-security/universe amd64 Packages [823 kB] Get:5 http://archive.ubuntu.com/ubuntu bionic-updates InRelease [88.7 kB] Get:6 http://archive.ubuntu.com/ubuntu bionic-backports InRelease [74.6 kB] Get:7 http://archive.ubuntu.com/ubuntu bionic/universe amd64 Packages [11.3 MB] Get:8 http://security.ubuntu.com/ubuntu bionic-security/restricted amd64 Packages [31.0 kB] Get:9 http://security.ubuntu.com/ubuntu bionic-security/main amd64 Packages [835 kB] Get:10 http://archive.ubuntu.com/ubuntu bionic/restricted amd64 Packages [13.5 kB] Get:11 http://archive.ubuntu.com/ubuntu bionic/main amd64 Packages [1344 kB] Get:12 http://archive.ubuntu.com/ubuntu bionic/multiverse amd64 Packages [186 kB] Get:13 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 Packages [1127 kB] Get:14 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 Packages [1350 kB] Get:15 http://archive.ubuntu.com/ubuntu bionic-updates/multiverse amd64 Packages [11.4 kB] Get:16 http://archive.ubuntu.com/ubuntu bionic-updates/restricted amd64 Packages [44.7 kB] Get:17 http://archive.ubuntu.com/ubuntu bionic-backports/main amd64 Packages [2496 B] Get:18 http://archive.ubuntu.com/ubuntu bionic-backports/universe amd64 Packages [4252 B] Fetched 17.6 MB in 1min 25s (207 kB/s) Reading package lists... Done 首先，安装 curl 工具。 root@7d93de07bf76:/# apt-get install curl Reading package lists... Done Building dependency tree Reading state information... Done The following additional packages will be installed: ca-certificates krb5-locales libasn1-8-heimdal libcurl4 libgssapi-krb5-2 libgssapi3-heimdal libhcrypto4-heimdal libheimbase1-heimdal libheimntlm0-heimdal libhx509-5-heimdal libk5crypto3 libkeyutils1 libkrb5-26-heimdal libkrb5-3 libkrb5support0 libldap-2.4-2 libldap-common libnghttp2-14 libpsl5 libroken18-heimdal librtmp1 libsasl2-2 libsasl2-modules libsasl2-modules-db libsqlite3-0 libssl1.1 libwind0-heimdal openssl publicsuffix ... root@7d93de07bf76:/# curl curl: try 'curl --help' or 'curl --manual' for more information 接下来，再安装 apache 服务。 root@7d93de07bf76:/# apt-get install -y apache2 Reading package lists... Done Building dependency tree Reading state information... Done The following additional packages will be installed: apache2-bin apache2-data apache2-utils file libapr1 libaprutil1 libaprutil1-dbd-sqlite3 libaprutil1-ldap libexpat1 libgdbm-compat4 libgdbm5 libicu60 liblua5.2-0 libmagic-mgc libmagic1 libperl5.26 libxml2 mime-support netbase perl perl-modules-5.26 ssl-cert xz-utils ... 启动这个 apache 服务，然后使用 curl 来测试本地访问。 root@7d93de07bf76:/# service apache2 start * Starting web server apache2 AH00558: apache2: Could not reliably determine the server's fully qualified domain name, using 172.17.0.2. Set the 'ServerName' directive globally to suppress this message * root@7d93de07bf76:/# curl 127.0.0.1 Apache2 Ubuntu Default Page: It works ... 配合使用 -p 参数对外映射服务端口，可以允许容器外来访问该服务。 相关资源 Debian 官网：https://www.debian.org/ Neuro Debian 官网：http://neuro.debian.net/ Debian 官方仓库：https://github.com/Debian Debian 官方镜像：https://hub.docker.com/_/debian/ Debian 官方镜像仓库：https://github.com/tianon/docker-brew-debian/ Ubuntu 官网：https://ubuntu.com Ubuntu 官方仓库：https://github.com/ubuntu Ubuntu 官方镜像：https://hub.docker.com/_/ubuntu/ Ubuntu 官方镜像仓库：https://github.com/tianon/docker-brew-ubuntu-core Copyright © Zhenhai Gao 2021 all right reserved发布时间： 2024-06-10 23:03:15 "},"docker/cases/os/centos.html":{"url":"docker/cases/os/centos.html","title":"CentOS Fedora","keywords":"","body":"CentOS/FedoraCentOS 系统简介使用 CentOS 官方镜像Fedora 系统简介使用 Fedora 官方镜像相关资源CentOS/Fedora CentOS 系统简介 CentOS 和 Fedora 都是基于 Redhat 的常见 Linux 分支。CentOS 是目前企业级服务器的常用操作系统；Fedora 则主要面向个人桌面用户。 CentOS（Community Enterprise Operating System，中文意思是：社区企业操作系统），它是基于 Red Hat Enterprise Linux 源代码编译而成。由于 CentOS 与 Redhat Linux 源于相同的代码基础，所以很多成本敏感且需要高稳定性的公司就使用 CentOS 来替代商业版 Red Hat Enterprise Linux。CentOS 自身不包含闭源软件。 使用 CentOS 官方镜像 使用 docker run 直接运行最新的 CentOS 镜像，并登录 bash。 $ docker run -it centos bash Unable to find image 'centos:latest' locally latest: Pulling from library/centos 3d8673bd162a: Pull complete Digest: sha256:a66ffcb73930584413de83311ca11a4cb4938c9b2521d331026dad970c19adf4 Status: Downloaded newer image for centos:latest [root@43eb3b194d48 /]# cat /etc/redhat-release CentOS Linux release 7.2.1511 (Core) Fedora 系统简介 Fedora 由 Fedora Project 社区开发，红帽公司赞助的 Linux 发行版。它的目标是创建一套新颖、多功能并且自由和开源的操作系统。Fedora 的功能对于用户而言，它是一套功能完备的，可以更新的免费操作系统，而对赞助商 Red Hat 而言，它是许多新技术的测试平台。被认为可用的技术最终会加入到 Red Hat Enterprise Linux 中。 使用 Fedora 官方镜像 使用 docker run 命令直接运行 Fedora 官方镜像，并登录 bash。 $ docker run -it fedora bash Unable to find image 'fedora:latest' locally latest: Pulling from library/fedora 2bf01635e2a0: Pull complete Digest: sha256:64a02df6aac27d1200c2572fe4b9949f1970d05f74d367ce4af994ba5dc3669e Status: Downloaded newer image for fedora:latest [root@196ca341419b /]# cat /etc/redhat-release Fedora release 24 (Twenty Four) 相关资源 Fedora 官网：https://getfedora.org/ Fedora 官方仓库：https://github.com/fedora-infra Fedora 官方镜像：https://hub.docker.com/_/fedora/ Fedora 官方镜像仓库：https://github.com/fedora-cloud/docker-brew-fedora CentOS 官网：https://www.centos.org CentOS 官方仓库：https://github.com/CentOS CentOS 官方镜像：https://hub.docker.com/_/centos/ CentOS 官方镜像仓库：https://github.com/CentOS/CentOS-Dockerfiles Copyright © Zhenhai Gao 2021 all right reserved发布时间： 2024-06-10 23:03:15 "},"docker/cases/os/summary.html":{"url":"docker/cases/os/summary.html","title":"本章小结","keywords":"","body":"本章小结本章小结 本章讲解了典型操作系统镜像的下载和使用。 除了官方的镜像外，在 Docker Hub 上还有许多第三方组织或个人上传的 Docker 镜像。 读者可以根据具体情况来选择。一般来说： 官方镜像体积都比较小，只带有一些基本的组件。 精简的系统有利于安全、稳定和高效的运行，也适合进行个性化定制。 出于安全考虑，几乎所有官方制作的镜像都没有安装 SSH 服务，无法通过用户名和密码直接登录到容器中。 Copyright © Zhenhai Gao 2021 all right reserved发布时间： 2024-06-10 23:03:15 "},"docker/appendix/":{"url":"docker/appendix/","title":"附录","keywords":"","body":"附录附录 Copyright © Zhenhai Gao 2021 all right reserved发布时间： 2024-06-10 23:03:15 "},"docker/appendix/faq/":{"url":"docker/appendix/faq/","title":"附录一：常见问题总结","keywords":"","body":"常见问题总结镜像相关如何批量清理临时镜像文件？如何查看镜像支持的环境变量？本地的镜像文件都存放在哪里？构建 Docker 镜像应该遵循哪些原则？碰到网络问题，无法 pull 镜像，命令行指定 http_proxy 无效？容器相关容器退出后，通过 docker container ls 命令查看不到，数据会丢失么？如何停止所有正在运行的容器？如何批量清理已经停止的容器？如何获取某个容器的 PID 信息？如何获取某个容器的 IP 地址？如何给容器指定一个固定 IP 地址，而不是每次重启容器 IP 地址都会变？如何临时退出一个正在交互的容器的终端，而不终止它？使用 docker port 命令映射容器的端口时，系统报错“Error: No public port '80' published for xxx”？可以在一个容器中同时运行多个应用进程么？如何控制容器占用系统资源（CPU、内存）的份额？仓库相关仓库（Repository）、注册服务器（Registry）、注册索引（Index） 有何关系？配置相关Docker 的配置文件放在哪里，如何修改配置？如何更改 Docker 的默认存储位置？使用内存和 swap 限制启动容器时候报警告：\"WARNING: Your kernel does not support cgroup swap limit. WARNING: Your kernel does not support swap limit capabilities. Limitation discarded.\"？Docker 与虚拟化Docker 与 LXC（Linux Container）有何不同？Docker 与 Vagrant 有何不同？开发环境中 Docker 和 Vagrant 该如何选择？其它Docker 能在非 Linux 平台（比如 Windows 或 macOS ）上运行么？如何将一台宿主主机的 Docker 环境迁移到另外一台宿主主机？如何进入 Docker 容器的网络命名空间？如何获取容器绑定到本地那个 veth 接口上？常见问题总结 镜像相关 如何批量清理临时镜像文件？ 答：可以使用 docker image prune 命令。 如何查看镜像支持的环境变量？ 答：可以使用 docker run IMAGE env 命令。 本地的镜像文件都存放在哪里？ 答：与 Docker 相关的本地资源默认存放在 /var/lib/docker/ 目录下，以 overlay2 文件系统为例，其中 containers 目录存放容器信息，image 目录存放镜像信息，overlay2 目录下存放具体的镜像层文件。 构建 Docker 镜像应该遵循哪些原则？ 答：整体原则上，尽量保持镜像功能的明确和内容的精简，要点包括 尽量选取满足需求但较小的基础系统镜像，例如大部分时候可以选择 alpine 镜像，仅有不足六兆大小； 清理编译生成文件、安装包的缓存等临时文件； 安装各个软件时候要指定准确的版本号，并避免引入不需要的依赖； 从安全角度考虑，应用要尽量使用系统的库和依赖； 如果安装应用时候需要配置一些特殊的环境变量，在安装后要还原不需要保持的变量值； 使用 Dockerfile 创建镜像时候要添加 .dockerignore 文件或使用干净的工作目录。 更多内容请查看 Dockerfile 最佳实践 碰到网络问题，无法 pull 镜像，命令行指定 http_proxy 无效？ 答：在 Docker 配置文件中添加 export http_proxy=\"http://:\"，之后重启 Docker 服务即可。 容器相关 容器退出后，通过 docker container ls 命令查看不到，数据会丢失么？ 答：容器退出后会处于终止（exited）状态，此时可以通过 docker container ls -a 查看。其中的数据也不会丢失，还可以通过 docker start 命令来启动它。只有删除掉容器才会清除所有数据。 如何停止所有正在运行的容器？ 答：可以使用 docker stop $(docker container ls -q) 命令。 如何批量清理已经停止的容器？ 答：可以使用 docker container prune 命令。 如何获取某个容器的 PID 信息？ 答：可以使用 docker inspect --format '{{ .State.Pid }}' 如何获取某个容器的 IP 地址？ 答：可以使用 docker inspect --format '{{ .NetworkSettings.IPAddress }}' 如何给容器指定一个固定 IP 地址，而不是每次重启容器 IP 地址都会变？ 答：使用以下命令启动容器可以使容器 IP 固定不变 $ docker network create -d bridge --subnet 172.25.0.0/16 my-net $ docker run --network=my-net --ip=172.25.3.3 -itd --name=my-container busybox 如何临时退出一个正在交互的容器的终端，而不终止它？ 答：按 Ctrl-p Ctrl-q。如果按 Ctrl-c 往往会让容器内应用进程终止，进而会终止容器。 使用 docker port 命令映射容器的端口时，系统报错“Error: No public port '80' published for xxx”？ 答： 创建镜像时 Dockerfile 要通过 EXPOSE 指定正确的开放端口； 容器启动时指定 PublishAllPort = true。 可以在一个容器中同时运行多个应用进程么？ 答：一般并不推荐在同一个容器内运行多个应用进程。如果有类似需求，可以通过一些额外的进程管理机制，比如 supervisord 来管理所运行的进程。可以参考 https://docs.docker.com/config/containers/multi-service_container/ 。 如何控制容器占用系统资源（CPU、内存）的份额？ 答：在使用 docker create 命令创建容器或使用 docker run 创建并启动容器的时候，可以使用 -c|--cpu-shares[=0] 参数来调整容器使用 CPU 的权重；使用 -m|--memory[=MEMORY] 参数来调整容器使用内存的大小。 仓库相关 仓库（Repository）、注册服务器（Registry）、注册索引（Index） 有何关系？ 首先，仓库是存放一组关联镜像的集合，比如同一个应用的不同版本的镜像。 注册服务器是存放实际的镜像文件的地方。注册索引则负责维护用户的账号、权限、搜索、标签等的管理。因此，注册服务器利用注册索引来实现认证等管理。 配置相关 Docker 的配置文件放在哪里，如何修改配置？ 答：使用 systemd 的系统（如 Ubuntu 16.04、Centos 等）的配置文件在 /etc/docker/daemon.json。 如何更改 Docker 的默认存储位置？ 答：Docker 的默认存储位置是 /var/lib/docker，如果希望将 Docker 的本地文件存储到其他分区，可以使用 Linux 软连接的方式来完成，或者在启动 daemon 时通过 -g 参数指定，或者修改配置文件 /etc/docker/daemon.json 的 \"data-root\" 项 。可以使用 docker system info | grep \"Root Dir\" 查看当前使用的存储位置。 例如，如下操作将默认存储位置迁移到 /storage/docker。 [root@s26 ~]# df -h Filesystem Size Used Avail Use% Mounted on /dev/mapper/VolGroup-lv_root 50G 5.3G 42G 12% / tmpfs 48G 228K 48G 1% /dev/shm /dev/sda1 485M 40M 420M 9% /boot /dev/mapper/VolGroup-lv_home 222G 188M 210G 1% /home /dev/sdb2 2.7T 323G 2.3T 13% /storage [root@s26 ~]# service docker stop [root@s26 ~]# cd /var/lib/ [root@s26 lib]# mv docker /storage/ [root@s26 lib]# ln -s /storage/docker/ docker [root@s26 lib]# ls -la docker lrwxrwxrwx. 1 root root 15 11月 17 13:43 docker -> /storage/docker [root@s26 lib]# service docker start 使用内存和 swap 限制启动容器时候报警告：\"WARNING: Your kernel does not support cgroup swap limit. WARNING: Your kernel does not support swap limit capabilities. Limitation discarded.\"？ 答：这是因为系统默认没有开启对内存和 swap 使用的统计功能，引入该功能会带来性能的下降。要开启该功能，可以采取如下操作： 编辑 /etc/default/grub 文件（Ubuntu 系统为例），配置 GRUB_CMDLINE_LINUX=\"cgroup_enable=memory swapaccount=1\" 更新 grub：$ sudo update-grub 重启系统，即可。 Docker 与虚拟化 Docker 与 LXC（Linux Container）有何不同？ 答：LXC 利用 Linux 上相关技术实现了容器。Docker 则在如下的几个方面进行了改进： 移植性：通过抽象容器配置，容器可以实现从一个平台移植到另一个平台； 镜像系统：基于 OverlayFS 的镜像系统为容器的分发带来了很多的便利，同时共同的镜像层只需要存储一份，实现高效率的存储； 版本管理：类似于Git的版本管理理念，用户可以更方便的创建、管理镜像文件； 仓库系统：仓库系统大大降低了镜像的分发和管理的成本； 周边工具：各种现有工具（配置管理、云平台）对 Docker 的支持，以及基于 Docker的 PaaS、CI 等系统，让 Docker 的应用更加方便和多样化。 Docker 与 Vagrant 有何不同？ 答：两者的定位完全不同。 Vagrant 类似 Boot2Docker（一款运行 Docker 的最小内核），是一套虚拟机的管理环境。Vagrant 可以在多种系统上和虚拟机软件中运行，可以在 Windows，Mac 等非 Linux 平台上为 Docker 提供支持，自身具有较好的包装性和移植性。 原生的 Docker 自身只能运行在 Linux 平台上，但启动和运行的性能都比虚拟机要快，往往更适合快速开发和部署应用的场景。 简单说：Vagrant 适合用来管理虚拟机，而 Docker 适合用来管理应用环境。 开发环境中 Docker 和 Vagrant 该如何选择？ 答：Docker 不是虚拟机，而是进程隔离，对于资源的消耗很少，但是目前需要 Linux 环境支持。Vagrant 是虚拟机上做的封装，虚拟机本身会消耗资源。 如果本地使用的 Linux 环境，推荐都使用 Docker。 如果本地使用的是 macOS 或者 Windows 环境，那就需要开虚拟机，单一开发环境下 Vagrant 更简单；多环境开发下推荐在 Vagrant 里面再使用 Docker 进行环境隔离。 其它 Docker 能在非 Linux 平台（比如 Windows 或 macOS ）上运行么？ 答：完全可以。安装方法请查看 安装 Docker 一节 如何将一台宿主主机的 Docker 环境迁移到另外一台宿主主机？ 答：停止 Docker 服务。将整个 Docker 存储文件夹复制到另外一台宿主主机，然后调整另外一台宿主主机的配置即可。 如何进入 Docker 容器的网络命名空间？ 答：Docker 在创建容器后，删除了宿主主机上 /var/run/netns 目录中的相关的网络命名空间文件。因此，在宿主主机上是无法看到或访问容器的网络命名空间的。 用户可以通过如下方法来手动恢复它。 首先，使用下面的命令查看容器进程信息，比如这里的 1234。 $ docker inspect --format='{{. State.Pid}} ' $container_id 1234 接下来，在 /proc 目录下，把对应的网络命名空间文件链接到 /var/run/netns 目录。 $ sudo ln -s /proc/1234/ns/net /var/run/netns/ 然后，在宿主主机上就可以看到容器的网络命名空间信息。例如 $ sudo ip netns show 1234 此时，用户可以通过正常的系统命令来查看或操作容器的命名空间了。例如修改容器的 IP 地址信息为 172.17.0.100/16。 $ sudo ip netns exec 1234 ifconfig eth0 172.17.0.100/16 如何获取容器绑定到本地那个 veth 接口上？ 答：Docker 容器启动后，会通过 veth 接口对连接到本地网桥，veth 接口命名跟容器命名毫无关系，十分难以找到对应关系。 最简单的一种方式是通过查看接口的索引号，在容器中执行 ip a 命令，查看到本地接口最前面的接口索引号，如 205，将此值加上 1，即 206，然后在本地主机执行 ip a 命令，查找接口索引号为 206 的接口，两者即为连接的 veth 接口对。 Copyright © Zhenhai Gao 2021 all right reserved发布时间： 2024-06-10 23:03:15 "},"docker/appendix/repo/":{"url":"docker/appendix/repo/","title":"附录二：热门镜像介绍","keywords":"","body":"热门镜像介绍热门镜像介绍 本章将介绍一些热门镜像的功能，使用方法等。包括 Ubuntu、CentOS、MySQL、MongoDB、Redis、Nginx、Wordpress、Node.js 等。 Copyright © Zhenhai Gao 2021 all right reserved发布时间： 2024-06-10 23:03:15 "},"docker/appendix/repo/ubuntu.html":{"url":"docker/appendix/repo/ubuntu.html","title":"Ubuntu","keywords":"","body":"Ubuntu基本信息使用方法DockerfileUbuntu 基本信息 Ubuntu 是流行的 Linux 发行版，其自带软件版本往往较新一些。 该仓库位于 https://hub.docker.com/_/ubuntu/ ，提供了 Ubuntu 从 12.04 ~ 20.04 各个版本的镜像。 使用方法 默认会启动一个最小化的 Ubuntu 环境。 $ docker run --name some-ubuntu -it ubuntu:20.04 root@523c70904d54:/# Dockerfile 请到 https://github.com/docker-library/docs/tree/master/ubuntu 查看。 Copyright © Zhenhai Gao 2021 all right reserved发布时间： 2024-06-10 23:03:15 "},"docker/appendix/repo/centos.html":{"url":"docker/appendix/repo/centos.html","title":"CentOS","keywords":"","body":"CentOS基本信息使用方法DockerfileCentOS 基本信息 CentOS 是流行的 Linux 发行版，其软件包大多跟 RedHat 系列保持一致。 该仓库位于 https://hub.docker.com/_/centos ，提供了 CentOS 从 5 ~ 8 各个版本的镜像。 使用方法 默认会启动一个最小化的 CentOS 环境。 $ docker run --name centos -it centos bash bash-4.2# Dockerfile 请到 https://github.com/docker-library/docs/tree/master/centos 查看。 Copyright © Zhenhai Gao 2021 all right reserved发布时间： 2024-06-10 23:03:15 "},"docker/appendix/repo/nginx.html":{"url":"docker/appendix/repo/nginx.html","title":"Nginx","keywords":"","body":"Nginx基本信息使用方法DockerfileNginx 基本信息 Nginx 是开源的高效的 Web 服务器实现，支持 HTTP、HTTPS、SMTP、POP3、IMAP 等协议。 该仓库位于 https://hub.docker.com/_/nginx/ ，提供了 Nginx 1.0 ~ 1.19.x 各个版本的镜像。 使用方法 下面的命令将作为一个静态页面服务器启动。 $ docker run --name some-nginx -v /some/content:/usr/share/nginx/html:ro -d nginx 用户也可以不使用这种映射方式，通过利用 Dockerfile 来直接将静态页面内容放到镜像中，内容为 FROM nginx COPY static-html-directory /usr/share/nginx/html 之后生成新的镜像，并启动一个容器。 $ docker build -t some-content-nginx . $ docker run --name some-nginx -d some-content-nginx 开放端口，并映射到本地的 8080 端口。 $ docker run --name some-nginx -d -p 8080:80 some-content-nginx Nginx的默认配置文件路径为 /etc/nginx/nginx.conf，可以通过映射它来使用本地的配置文件，例如 $ docker run -d \\ --name some-nginx \\ -p 8080:80 \\ -v /path/nginx.conf:/etc/nginx/nginx.conf:ro \\ nginx Dockerfile 请到 https://github.com/docker-library/docs/tree/master/nginx 查看。 Copyright © Zhenhai Gao 2021 all right reserved发布时间： 2024-06-10 23:03:15 "},"docker/appendix/repo/php.html":{"url":"docker/appendix/repo/php.html","title":"PHP","keywords":"","body":"PHP基本信息使用方法DockerfilePHP 基本信息 PHP（Hypertext Preprocessor 超文本预处理器的字母缩写）是一种被广泛应用的开放源代码的多用途脚本语言，它可嵌入到 HTML 中，尤其适合 web 开发。 该仓库位于 https://hub.docker.com/_/php/ ，提供了 PHP 5.x ~ 8.x 各个版本的镜像。 使用方法 下面的命令将运行一个已有的 PHP 脚本。 $ docker run -it --rm -v \"$PWD\":/app -w /app php:alpine php your-script.php Dockerfile 请到 https://github.com/docker-library/docs/tree/master/php 查看。 Copyright © Zhenhai Gao 2021 all right reserved发布时间： 2024-06-10 23:03:15 "},"docker/appendix/repo/nodejs.html":{"url":"docker/appendix/repo/nodejs.html","title":"Node.js","keywords":"","body":"Node.js基本信息使用方法DockerfileNode.js 基本信息 Node.js 是基于 JavaScript 的可扩展服务端和网络软件开发平台。 该仓库位于 https://hub.docker.com/_/node/ ，提供了 Node.js 0.10 ~ 14.x 各个版本的镜像。 使用方法 在项目中创建一个 Dockerfile。 FROM node:12 # replace this with your application's default port EXPOSE 8888 然后创建镜像，并启动容器。 $ docker build -t my-nodejs-app $ docker run -it --rm --name my-running-app my-nodejs-app 也可以直接运行一个简单容器。 $ docker run -it --rm \\ --name my-running-script \\ # -v \"$(pwd)\":/usr/src/myapp \\ --mount type=bind,src=`$(pwd)`,target=/usr/src/myapp \\ -w /usr/src/myapp \\ node:12-alpine \\ node your-daemon-or-script.js Dockerfile 请到 https://github.com/docker-library/docs/tree/master/node 查看。 Copyright © Zhenhai Gao 2021 all right reserved发布时间： 2024-06-10 23:03:15 "},"docker/appendix/repo/mysql.html":{"url":"docker/appendix/repo/mysql.html","title":"MySQL","keywords":"","body":"MySQL基本信息使用方法DockerfileMySQL 基本信息 MySQL 是开源的关系数据库实现。 该仓库位于 https://hub.docker.com/_/mysql/ ，提供了 MySQL 5.5 ~ 8.x 各个版本的镜像。 使用方法 默认会在 3306 端口启动数据库。 $ docker run --name some-mysql -e MYSQL_ROOT_PASSWORD=mysecretpassword -d mysql 之后就可以使用其它应用来连接到该容器。 $ docker run --name some-app --link some-mysql:mysql -d application-that-uses-mysql 或者通过 mysql 命令行连接。 $ docker run -it --rm \\ --link some-mysql:mysql \\ mysql \\ sh -c 'exec mysql -h\"$MYSQL_PORT_3306_TCP_ADDR\" -P\"$MYSQL_PORT_3306_TCP_PORT\" -uroot -p\"$MYSQL_ENV_MYSQL_ROOT_PASSWORD\"' Dockerfile 请到 https://github.com/docker-library/docs/tree/master/mysql 查看 Copyright © Zhenhai Gao 2021 all right reserved发布时间： 2024-06-10 23:03:15 "},"docker/appendix/repo/wordpress.html":{"url":"docker/appendix/repo/wordpress.html","title":"WordPress","keywords":"","body":"WordPress基本信息使用方法DockerfileWordPress 基本信息 WordPress 是开源的 Blog 和内容管理系统框架，它基于 PHP 和 MySQL。 该仓库位于 https://hub.docker.com/_/wordpress/ ，提供了 WordPress 4.x ~ 5.x 版本的镜像。 使用方法 启动容器需要 MySQL 的支持，默认端口为 80。 $ docker run --name some-wordpress --link some-mysql:mysql -d wordpress 启动 WordPress 容器时可以指定的一些环境变量包括： WORDPRESS_DB_USER 缺省为 root WORDPRESS_DB_PASSWORD 缺省为连接 mysql 容器的环境变量 MYSQL_ROOT_PASSWORD 的值 WORDPRESS_DB_NAME 缺省为 wordpress Dockerfile 请到 https://github.com/docker-library/docs/tree/master/wordpress 查看。 Copyright © Zhenhai Gao 2021 all right reserved发布时间： 2024-06-10 23:03:15 "},"docker/appendix/repo/mongodb.html":{"url":"docker/appendix/repo/mongodb.html","title":"MongoDB","keywords":"","body":"MongoDB基本信息使用方法DockerfileMongoDB 基本信息 MongoDB 是开源的 NoSQL 数据库实现。 该仓库位于 https://hub.docker.com/_/mongo/ ，提供了 MongoDB 2.x ~ 4.x 各个版本的镜像。 使用方法 默认会在 27017 端口启动数据库。 $ docker run --name mongo -d mongo 使用其他应用连接到容器，可以用 $ docker run --name some-app --link some-mongo:mongo -d application-that-uses-mongo 或者通过 mongo $ docker run -it --rm \\ --link some-mongo:mongo \\ mongo \\ sh -c 'exec mongo \"$MONGO_PORT_27017_TCP_ADDR:$MONGO_PORT_27017_TCP_PORT/test\"' Dockerfile 请到 https://github.com/docker-library/docs/tree/master/mongo 查看。 Copyright © Zhenhai Gao 2021 all right reserved发布时间： 2024-06-10 23:03:15 "},"docker/appendix/repo/redis.html":{"url":"docker/appendix/repo/redis.html","title":"Redis","keywords":"","body":"Redis基本信息使用方法DockerfileRedis 基本信息 Redis 是开源的内存 Key-Value 数据库实现。 该仓库位于 https://hub.docker.com/_/redis/ ，提供了 Redis 3.x ~ 6.x 各个版本的镜像。 使用方法 默认会在 6379 端口启动数据库。 $ docker run --name some-redis -d -p 6379:6379 redis 另外还可以启用 持久存储。 $ docker run --name some-redis -d -p 6379:6379 redis redis-server --appendonly yes 默认数据存储位置在 VOLUME/data。可以使用 --volumes-from some-volume-container 或 -v /docker/host/dir:/data 将数据存放到本地。 使用其他应用连接到容器，可以用 $ docker run --name some-app --link some-redis:redis -d application-that-uses-redis 或者通过 redis-cli $ docker run -it --rm \\ --link some-redis:redis \\ redis \\ sh -c 'exec redis-cli -h \"$REDIS_PORT_6379_TCP_ADDR\" -p \"$REDIS_PORT_6379_TCP_PORT\"' Dockerfile 请到 https://github.com/docker-library/docs/tree/master/redis 查看。 Copyright © Zhenhai Gao 2021 all right reserved发布时间： 2024-06-10 23:03:15 "},"docker/appendix/repo/minio.html":{"url":"docker/appendix/repo/minio.html","title":"Minio","keywords":"","body":"minio简单使用离线部署导出镜像导入镜像运行 minio访问 web 管理页面minio MinIO 是一个基于 Apache License v2.0 开源协议的对象存储服务。它兼容亚马逊 S3 云存储服务接口，非常适合于存储大容量非结构化的数据，例如图片、视频、日志文件、备份数据和容器/虚拟机镜像等，而一个对象文件可以是任意大小，从几 kb 到最大 5T 不等。 MinIO 是一个非常轻量的服务,可以很简单的和其他应用的结合，类似 NodeJS, Redis 或者 MySQL。 官方文档 简单使用 测试、开发环境下不考虑数据存储的情况下可以使用下面的命令快速开启服务。 $ docker run -d -p 9000:9000 -p 9090:9090 minio/minio server /data --console-address ':9090' 离线部署 许多生产环境是一般是没有公网资源的，这就需要从有公网资源的服务器上把镜像导出，然后导入到需要运行镜像的内网服务器。 导出镜像 在有公网资源的服务器上下载好minio/minio镜像 $ docker save -o minio.tar minio/minio:latest 使用docker save 的时候，也可以使用image id 来导出，但是那样导出的时候，就会丢失原来的镜像名称，推荐，还是使用镜像名字+tag来导出镜像 导入镜像 把压缩文件复制到内网服务器上，使用下面的命令导入镜像 $ docker load minio.tar 运行 minio 把 /mnt/data 改成要替换的数据目录 替换 MINIO_ROOT_USER 的值 替换 MINIO_ROOT_PASSWORD 的值 替换 name,minio1(可选) 如果 9000、9090 端口冲突,替换端口前面的如 9009:9000 $ sudo docker run -d -p 9000:9000 -p 9090:9090 --name minio1 \\ -e \"MINIO_ROOT_USER=改成自己需要的\" \\ -e \"MINIO_ROOT_PASSWORD=改成自己需要的\" \\ -v /mnt/data:/data \\ --restart=always \\ minio/minio server /data --console-address ':9090' 访问 web 管理页面 http://x.x.x.x:9090 Copyright © Zhenhai Gao 2021 all right reserved发布时间： 2024-06-10 23:03:15 "},"docker/appendix/command/":{"url":"docker/appendix/command/","title":"附录三：Docker 命令查询","keywords":"","body":"Docker 命令查询基本语法Docker 命令查询 基本语法 Docker 命令有两大类，客户端命令和服务端命令。前者是主要的操作接口，后者用来启动 Docker Daemon。 客户端命令：基本命令格式为 docker [OPTIONS] COMMAND [arg...]； 服务端命令：基本命令格式为 dockerd [OPTIONS]。 可以通过 man docker 或 docker help 来查看这些命令。 接下来的小节对这两个命令进行介绍。 Copyright © Zhenhai Gao 2021 all right reserved发布时间： 2024-06-10 23:03:15 "},"docker/appendix/command/docker.html":{"url":"docker/appendix/command/docker.html","title":"客户端命令 - docker","keywords":"","body":"客户端命令(docker)客户端命令选项客户端命令一张图总结 Docker 的命令参考客户端命令(docker) 客户端命令选项 --config=\"\"：指定客户端配置文件，默认为 ~/.docker； -D=true|false：是否使用 debug 模式。默认不开启； -H, --host=[]：指定命令对应 Docker 守护进程的监听接口，可以为 unix 套接字 unix:///path/to/socket，文件句柄 fd://socketfd 或 tcp 套接字 tcp://[host[:port]]，默认为 unix:///var/run/docker.sock； -l, --log-level=\"debug|info|warn|error|fatal\"：指定日志输出级别； --tls=true|false：是否对 Docker 守护进程启用 TLS 安全机制，默认为否； --tlscacert=/.docker/ca.pem：TLS CA 签名的可信证书文件路径； --tlscert=/.docker/cert.pem：TLS 可信证书文件路径； --tlscert=/.docker/key.pem：TLS 密钥文件路径； --tlsverify=true|false：启用 TLS 校验，默认为否。 客户端命令 可以通过 docker COMMAND --help 来查看这些命令的具体用法。 attach：依附到一个正在运行的容器中； build：从一个 Dockerfile 创建一个镜像； commit：从一个容器的修改中创建一个新的镜像； cp：在容器和本地宿主系统之间复制文件中； create：创建一个新容器，但并不运行它； diff：检查一个容器内文件系统的修改，包括修改和增加； events：从服务端获取实时的事件； exec：在运行的容器内执行命令； export：导出容器内容为一个 tar 包； history：显示一个镜像的历史信息； images：列出存在的镜像； import：导入一个文件（典型为 tar 包）路径或目录来创建一个本地镜像； info：显示一些相关的系统信息； inspect：显示一个容器的具体配置信息； kill：关闭一个运行中的容器 (包括进程和所有相关资源)； load：从一个 tar 包中加载一个镜像； login：注册或登录到一个 Docker 的仓库服务器； logout：从 Docker 的仓库服务器登出； logs：获取容器的 log 信息； network：管理 Docker 的网络，包括查看、创建、删除、挂载、卸载等； node：管理 swarm 集群中的节点，包括查看、更新、删除、提升/取消管理节点等； pause：暂停一个容器中的所有进程； port：查找一个 nat 到一个私有网口的公共口； ps：列出主机上的容器； pull：从一个Docker的仓库服务器下拉一个镜像或仓库； push：将一个镜像或者仓库推送到一个 Docker 的注册服务器； rename：重命名一个容器； restart：重启一个运行中的容器； rm：删除给定的若干个容器； rmi：删除给定的若干个镜像； run：创建一个新容器，并在其中运行给定命令； save：保存一个镜像为 tar 包文件； search：在 Docker index 中搜索一个镜像； service：管理 Docker 所启动的应用服务，包括创建、更新、删除等； start：启动一个容器； stats：输出（一个或多个）容器的资源使用统计信息； stop：终止一个运行中的容器； swarm：管理 Docker swarm 集群，包括创建、加入、退出、更新等； tag：为一个镜像打标签； top：查看一个容器中的正在运行的进程信息； unpause：将一个容器内所有的进程从暂停状态中恢复； update：更新指定的若干容器的配置信息； version：输出 Docker 的版本信息； volume：管理 Docker volume，包括查看、创建、删除等； wait：阻塞直到一个容器终止，然后输出它的退出符。 一张图总结 Docker 的命令 参考 官方文档 Copyright © Zhenhai Gao 2021 all right reserved发布时间： 2024-06-10 23:03:15 "},"docker/appendix/command/dockerd.html":{"url":"docker/appendix/command/dockerd.html","title":"服务端命令 - dockerd","keywords":"","body":"服务端命令(dockerd)dockerd 命令选项参考服务端命令(dockerd) dockerd 命令选项 --api-cors-header=\"\"：CORS 头部域，默认不允许 CORS，要允许任意的跨域访问，可以指定为 \"*\"； --authorization-plugin=\"\"：载入认证的插件； -b=\"\"：将容器挂载到一个已存在的网桥上。指定为 none 时则禁用容器的网络，与 --bip 选项互斥； --bip=\"\"：让动态创建的 docker0 网桥采用给定的 CIDR 地址; 与 -b 选项互斥； --cgroup-parent=\"\"：指定 cgroup 的父组，默认 fs cgroup 驱动为 /docker，systemd cgroup 驱动为 system.slice； --cluster-store=\"\"：构成集群（如 Swarm）时，集群键值数据库服务地址； --cluster-advertise=\"\"：构成集群时，自身的被访问地址，可以为 host:port 或 interface:port； --cluster-store-opt=\"\"：构成集群时，键值数据库的配置选项； --config-file=\"/etc/docker/daemon.json\"：daemon 配置文件路径； --containerd=\"\"：containerd 文件的路径； -D, --debug=true|false：是否使用 Debug 模式。缺省为 false； --default-gateway=\"\"：容器的 IPv4 网关地址，必须在网桥的子网段内； --default-gateway-v6=\"\"：容器的 IPv6 网关地址； --default-ulimit=[]：默认的 ulimit 值； --disable-legacy-registry=true|false：是否允许访问旧版本的镜像仓库服务器； --dns=\"\"：指定容器使用的 DNS 服务器地址； --dns-opt=\"\"：DNS 选项； --dns-search=[]：DNS 搜索域； --exec-opt=[]：运行时的执行选项； --exec-root=\"\"：容器执行状态文件的根路径，默认为 /var/run/docker； --fixed-cidr=\"\"：限定分配 IPv4 地址范围； --fixed-cidr-v6=\"\"：限定分配 IPv6 地址范围； -G, --group=\"\"：分配给 unix 套接字的组，默认为 docker； -g, --graph=\"\"：Docker 运行时的根路径，默认为 /var/lib/docker； -H, --host=[]：指定命令对应 Docker daemon 的监听接口，可以为 unix 套接字 unix:///path/to/socket，文件句柄 fd://socketfd 或 tcp 套接字 tcp://[host[:port]]，默认为 unix:///var/run/docker.sock； --icc=true|false：是否启用容器间以及跟 daemon 所在主机的通信。默认为 true。 --insecure-registry=[]：允许访问给定的非安全仓库服务； --ip=\"\"：绑定容器端口时候的默认 IP 地址。缺省为 0.0.0.0； --ip-forward=true|false：是否检查启动在 Docker 主机上的启用 IP 转发服务，默认开启。注意关闭该选项将不对系统转发能力进行任何检查修改； --ip-masq=true|false：是否进行地址伪装，用于容器访问外部网络，默认开启； --iptables=true|false：是否允许 Docker 添加 iptables 规则。缺省为 true； --ipv6=true|false：是否启用 IPv6 支持，默认关闭； -l, --log-level=\"debug|info|warn|error|fatal\"：指定日志输出级别； --label=\"[]\"：添加指定的键值对标注； --log-driver=\"json-file|syslog|journald|gelf|fluentd|awslogs|splunk|etwlogs|gcplogs|none\"：指定日志后端驱动，默认为 json-file； --log-opt=[]：日志后端的选项； --mtu=VALUE：指定容器网络的 mtu； -p=\"\"：指定 daemon 的 PID 文件路径。缺省为 /var/run/docker.pid； --raw-logs：输出原始，未加色彩的日志信息； --registry-mirror=://：指定 docker pull 时使用的注册服务器镜像地址； -s, --storage-driver=\"\"：指定使用给定的存储后端； --selinux-enabled=true|false：是否启用 SELinux 支持。缺省值为 false。SELinux 目前尚不支持 overlay 存储驱动； --storage-opt=[]：驱动后端选项； --tls=true|false：是否对 Docker daemon 启用 TLS 安全机制，默认为否； --tlscacert=/.docker/ca.pem：TLS CA 签名的可信证书文件路径； --tlscert=/.docker/cert.pem：TLS 可信证书文件路径； --tlscert=/.docker/key.pem：TLS 密钥文件路径； --tlsverify=true|false：启用 TLS 校验，默认为否； --userland-proxy=true|false：是否使用用户态代理来实现容器间和出容器的回环通信，默认为 true； --userns-remap=default|uid:gid|user:group|user|uid：指定容器的用户命名空间，默认是创建新的 UID 和 GID 映射到容器内进程。 参考 官方文档 Copyright © Zhenhai Gao 2021 all right reserved发布时间： 2024-06-10 23:03:15 "},"docker/appendix/best-practices.html":{"url":"docker/appendix/best-practices.html","title":"附录四：Dockerfile 最佳实践","keywords":"","body":"Dockerfile 最佳实践一般性的指南和建议容器应该是短暂的使用 .dockerignore 文件使用多阶段构建避免安装不必要的包一个容器只运行一个进程镜像层数尽可能少将多行参数排序构建缓存Dockerfile 指令FROMLABELRUNCMDEXPOSEENVADD 和 COPYENTRYPOINTVOLUMEUSERWORKDIR官方镜像示例Dockerfile 最佳实践 本附录是笔者对 Docker 官方文档中 Best practices for writing Dockerfiles 的理解与翻译。 一般性的指南和建议 容器应该是短暂的 通过 Dockerfile 构建的镜像所启动的容器应该尽可能短暂（生命周期短）。「短暂」意味着可以停止和销毁容器，并且创建一个新容器并部署好所需的设置和配置工作量应该是极小的。 使用 .dockerignore 文件 使用 Dockerfile 构建镜像时最好是将 Dockerfile 放置在一个新建的空目录下。然后将构建镜像所需要的文件添加到该目录中。为了提高构建镜像的效率，你可以在目录下新建一个 .dockerignore 文件来指定要忽略的文件和目录。.dockerignore 文件的排除模式语法和 Git 的 .gitignore 文件相似。 使用多阶段构建 在 Docker 17.05 以上版本中，你可以使用 多阶段构建 来减少所构建镜像的大小。 避免安装不必要的包 为了降低复杂性、减少依赖、减小文件大小、节约构建时间，你应该避免安装任何不必要的包。例如，不要在数据库镜像中包含一个文本编辑器。 一个容器只运行一个进程 应该保证在一个容器中只运行一个进程。将多个应用解耦到不同容器中，保证了容器的横向扩展和复用。例如 web 应用应该包含三个容器：web应用、数据库、缓存。 如果容器互相依赖，你可以使用 Docker 自定义网络 来把这些容器连接起来。 镜像层数尽可能少 你需要在 Dockerfile 可读性（也包括长期的可维护性）和减少层数之间做一个平衡。 将多行参数排序 将多行参数按字母顺序排序（比如要安装多个包时）。这可以帮助你避免重复包含同一个包，更新包列表时也更容易。也便于 PRs 阅读和审查。建议在反斜杠符号 \\ 之前添加一个空格，以增加可读性。 下面是来自 buildpack-deps 镜像的例子： RUN apt-get update && apt-get install -y \\ bzr \\ cvs \\ git \\ mercurial \\ subversion 构建缓存 在镜像的构建过程中，Docker 会遍历 Dockerfile 文件中的指令，然后按顺序执行。在执行每条指令之前，Docker 都会在缓存中查找是否已经存在可重用的镜像，如果有就使用现存的镜像，不再重复创建。如果你不想在构建过程中使用缓存，你可以在 docker build 命令中使用 --no-cache=true 选项。 但是，如果你想在构建的过程中使用缓存，你得明白什么时候会，什么时候不会找到匹配的镜像，遵循的基本规则如下： 从一个基础镜像开始（FROM 指令指定），下一条指令将和该基础镜像的所有子镜像进行匹配，检查这些子镜像被创建时使用的指令是否和被检查的指令完全一样。如果不是，则缓存失效。 在大多数情况下，只需要简单地对比 Dockerfile 中的指令和子镜像。然而，有些指令需要更多的检查和解释。 对于 ADD 和 COPY 指令，镜像中对应文件的内容也会被检查，每个文件都会计算出一个校验和。文件的最后修改时间和最后访问时间不会纳入校验。在缓存的查找过程中，会将这些校验和和已存在镜像中的文件校验和进行对比。如果文件有任何改变，比如内容和元数据，则缓存失效。 除了 ADD 和 COPY 指令，缓存匹配过程不会查看临时容器中的文件来决定缓存是否匹配。例如，当执行完 RUN apt-get -y update 指令后，容器中一些文件被更新，但 Docker 不会检查这些文件。这种情况下，只有指令字符串本身被用来匹配缓存。 一旦缓存失效，所有后续的 Dockerfile 指令都将产生新的镜像，缓存不会被使用。 Dockerfile 指令 下面针对 Dockerfile 中各种指令的最佳编写方式给出建议。 FROM 尽可能使用当前官方仓库作为你构建镜像的基础。推荐使用 Alpine 镜像，因为它被严格控制并保持最小尺寸（目前小于 5 MB），但它仍然是一个完整的发行版。 LABEL 你可以给镜像添加标签来帮助组织镜像、记录许可信息、辅助自动化构建等。每个标签一行，由 LABEL 开头加上一个或多个标签对。下面的示例展示了各种不同的可能格式。# 开头的行是注释内容。 注意：如果你的字符串中包含空格，必须将字符串放入引号中或者对空格使用转义。如果字符串内容本身就包含引号，必须对引号使用转义。 # Set one or more individual labels LABEL com.example.version=\"0.0.1-beta\" LABEL vendor=\"ACME Incorporated\" LABEL com.example.release-date=\"2015-02-12\" LABEL com.example.version.is-production=\"\" 一个镜像可以包含多个标签，但建议将多个标签放入到一个 LABEL 指令中。 # Set multiple labels at once, using line-continuation characters to break long lines LABEL vendor=ACME\\ Incorporated \\ com.example.is-beta= \\ com.example.is-production=\"\" \\ com.example.version=\"0.0.1-beta\" \\ com.example.release-date=\"2015-02-12\" 关于标签可以接受的键值对，参考 Understanding object labels。关于查询标签信息，参考 Managing labels on objects。 RUN 为了保持 Dockerfile 文件的可读性，可理解性，以及可维护性，建议将长的或复杂的 RUN 指令用反斜杠 \\ 分割成多行。 apt-get RUN 指令最常见的用法是安装包用的 apt-get。因为 RUN apt-get 指令会安装包，所以有几个问题需要注意。 不要使用 RUN apt-get upgrade 或 dist-upgrade，因为许多基础镜像中的「必须」包不会在一个非特权容器中升级。如果基础镜像中的某个包过时了，你应该联系它的维护者。如果你确定某个特定的包，比如 foo，需要升级，使用 apt-get install -y foo 就行，该指令会自动升级 foo 包。 永远将 RUN apt-get update 和 apt-get install 组合成一条 RUN 声明，例如： RUN apt-get update && apt-get install -y \\ package-bar \\ package-baz \\ package-foo 将 apt-get update 放在一条单独的 RUN 声明中会导致缓存问题以及后续的 apt-get install 失败。比如，假设你有一个 Dockerfile 文件： FROM ubuntu:18.04 RUN apt-get update RUN apt-get install -y curl 构建镜像后，所有的层都在 Docker 的缓存中。假设你后来又修改了其中的 apt-get install 添加了一个包： FROM ubuntu:18.04 RUN apt-get update RUN apt-get install -y curl nginx Docker 发现修改后的 RUN apt-get update 指令和之前的完全一样。所以，apt-get update 不会执行，而是使用之前的缓存镜像。因为 apt-get update 没有运行，后面的 apt-get install 可能安装的是过时的 curl 和 nginx 版本。 使用 RUN apt-get update && apt-get install -y 可以确保你的 Dockerfiles 每次安装的都是包的最新的版本，而且这个过程不需要进一步的编码或额外干预。这项技术叫作 cache busting。你也可以显示指定一个包的版本号来达到 cache-busting，这就是所谓的固定版本，例如： RUN apt-get update && apt-get install -y \\ package-bar \\ package-baz \\ package-foo=1.3.* 固定版本会迫使构建过程检索特定的版本，而不管缓存中有什么。这项技术也可以减少因所需包中未预料到的变化而导致的失败。 下面是一个 RUN 指令的示例模板，展示了所有关于 apt-get 的建议。 RUN apt-get update && apt-get install -y \\ aufs-tools \\ automake \\ build-essential \\ curl \\ dpkg-sig \\ libcap-dev \\ libsqlite3-dev \\ mercurial \\ reprepro \\ ruby1.9.1 \\ ruby1.9.1-dev \\ s3cmd=1.1.* \\ && rm -rf /var/lib/apt/lists/* 其中 s3cmd 指令指定了一个版本号 1.1.*。如果之前的镜像使用的是更旧的版本，指定新的版本会导致 apt-get udpate 缓存失效并确保安装的是新版本。 另外，清理掉 apt 缓存 var/lib/apt/lists 可以减小镜像大小。因为 RUN 指令的开头为 apt-get udpate，包缓存总是会在 apt-get install 之前刷新。 注意：官方的 Debian 和 Ubuntu 镜像会自动运行 apt-get clean，所以不需要显式的调用 apt-get clean。 CMD CMD 指令用于执行目标镜像中包含的软件，可以包含参数。CMD 大多数情况下都应该以 CMD [\"executable\", \"param1\", \"param2\"...] 的形式使用。因此，如果创建镜像的目的是为了部署某个服务(比如 Apache)，你可能会执行类似于 CMD [\"apache2\", \"-DFOREGROUND\"] 形式的命令。我们建议任何服务镜像都使用这种形式的命令。 多数情况下，CMD 都需要一个交互式的 shell (bash, Python, perl 等)，例如 CMD [\"perl\", \"-de0\"]，或者 CMD [\"PHP\", \"-a\"]。使用这种形式意味着，当你执行类似 docker run -it python 时，你会进入一个准备好的 shell 中。CMD 应该在极少的情况下才能以 CMD [\"param\", \"param\"] 的形式与 ENTRYPOINT 协同使用，除非你和你的镜像使用者都对 ENTRYPOINT 的工作方式十分熟悉。 EXPOSE EXPOSE 指令用于指定容器将要监听的端口。因此，你应该为你的应用程序使用常见的端口。例如，提供 Apache web 服务的镜像应该使用 EXPOSE 80，而提供 MongoDB 服务的镜像使用 EXPOSE 27017。 对于外部访问，用户可以在执行 docker run 时使用一个标志来指示如何将指定的端口映射到所选择的端口。 ENV 为了方便新程序运行，你可以使用 ENV 来为容器中安装的程序更新 PATH 环境变量。例如使用 ENV PATH /usr/local/nginx/bin:$PATH 来确保 CMD [\"nginx\"] 能正确运行。 ENV 指令也可用于为你想要容器化的服务提供必要的环境变量，比如 Postgres 需要的 PGDATA。 最后，ENV 也能用于设置常见的版本号，比如下面的示例： ENV PG_MAJOR 9.3 ENV PG_VERSION 9.3.4 RUN curl -SL http://example.com/postgres-$PG_VERSION.tar.xz | tar -xJC /usr/src/postgress && … ENV PATH /usr/local/postgres-$PG_MAJOR/bin:$PATH 类似于程序中的常量，这种方法可以让你只需改变 ENV 指令来自动的改变容器中的软件版本。 ADD 和 COPY 虽然 ADD 和 COPY 功能类似，但一般优先使用 COPY。因为它比 ADD 更透明。COPY 只支持简单将本地文件拷贝到容器中，而 ADD 有一些并不明显的功能（比如本地 tar 提取和远程 URL 支持）。因此，ADD 的最佳用例是将本地 tar 文件自动提取到镜像中，例如 ADD rootfs.tar.xz。 如果你的 Dockerfile 有多个步骤需要使用上下文中不同的文件。单独 COPY 每个文件，而不是一次性的 COPY 所有文件，这将保证每个步骤的构建缓存只在特定的文件变化时失效。例如： COPY requirements.txt /tmp/ RUN pip install --requirement /tmp/requirements.txt COPY . /tmp/ 如果将 COPY . /tmp/ 放置在 RUN 指令之前，只要 . 目录中任何一个文件变化，都会导致后续指令的缓存失效。 为了让镜像尽量小，最好不要使用 ADD 指令从远程 URL 获取包，而是使用 curl 和 wget。这样你可以在文件提取完之后删掉不再需要的文件来避免在镜像中额外添加一层。比如尽量避免下面的用法： ADD http://example.com/big.tar.xz /usr/src/things/ RUN tar -xJf /usr/src/things/big.tar.xz -C /usr/src/things RUN make -C /usr/src/things all 而是应该使用下面这种方法： RUN mkdir -p /usr/src/things \\ && curl -SL http://example.com/big.tar.xz \\ | tar -xJC /usr/src/things \\ && make -C /usr/src/things all 上面使用的管道操作，所以没有中间文件需要删除。 对于其他不需要 ADD 的自动提取功能的文件或目录，你应该使用 COPY。 ENTRYPOINT ENTRYPOINT 的最佳用处是设置镜像的主命令，允许将镜像当成命令本身来运行（用 CMD 提供默认选项）。 例如，下面的示例镜像提供了命令行工具 s3cmd: ENTRYPOINT [\"s3cmd\"] CMD [\"--help\"] 现在直接运行该镜像创建的容器会显示命令帮助： $ docker run s3cmd 或者提供正确的参数来执行某个命令： $ docker run s3cmd ls s3://mybucket 这样镜像名可以当成命令行的参考。 ENTRYPOINT 指令也可以结合一个辅助脚本使用，和前面命令行风格类似，即使启动工具需要不止一个步骤。 例如，Postgres 官方镜像使用下面的脚本作为 ENTRYPOINT： #!/bin/bash set -e if [ \"$1\" = 'postgres' ]; then chown -R postgres \"$PGDATA\" if [ -z \"$(ls -A \"$PGDATA\")\" ]; then gosu postgres initdb fi exec gosu postgres \"$@\" fi exec \"$@\" 注意：该脚本使用了 Bash 的内置命令 exec，所以最后运行的进程就是容器的 PID 为 1 的进程。这样，进程就可以接收到任何发送给容器的 Unix 信号了。 该辅助脚本被拷贝到容器，并在容器启动时通过 ENTRYPOINT 执行： COPY ./docker-entrypoint.sh / ENTRYPOINT [\"/docker-entrypoint.sh\"] 该脚本可以让用户用几种不同的方式和 Postgres 交互。 你可以很简单地启动 Postgres： $ docker run postgres 也可以执行 Postgres 并传递参数： $ docker run postgres postgres --help 最后，你还可以启动另外一个完全不同的工具，比如 Bash： $ docker run --rm -it postgres bash VOLUME VOLUME 指令用于暴露任何数据库存储文件，配置文件，或容器创建的文件和目录。强烈建议使用 VOLUME 来管理镜像中的可变部分和用户可以改变的部分。 USER 如果某个服务不需要特权执行，建议使用 USER 指令切换到非 root 用户。先在 Dockerfile 中使用类似 RUN groupadd -r postgres && useradd -r -g postgres postgres 的指令创建用户和用户组。 注意：在镜像中，用户和用户组每次被分配的 UID/GID 都是不确定的，下次重新构建镜像时被分配到的 UID/GID 可能会不一样。如果要依赖确定的 UID/GID，你应该显示的指定一个 UID/GID。 你应该避免使用 sudo，因为它不可预期的 TTY 和信号转发行为可能造成的问题比它能解决的问题还多。如果你真的需要和 sudo 类似的功能（例如，以 root 权限初始化某个守护进程，以非 root 权限执行它），你可以使用 gosu。 最后，为了减少层数和复杂度，避免频繁地使用 USER 来回切换用户。 WORKDIR 为了清晰性和可靠性，你应该总是在 WORKDIR 中使用绝对路径。另外，你应该使用 WORKDIR 来替代类似于 RUN cd ... && do-something 的指令，后者难以阅读、排错和维护。 官方镜像示例 这些官方镜像的 Dockerfile 都是参考典范：https://github.com/docker-library/docs Copyright © Zhenhai Gao 2021 all right reserved发布时间： 2024-06-10 23:03:15 "},"docker/appendix/debug.html":{"url":"docker/appendix/debug.html","title":"附录五：如何调试 Docker","keywords":"","body":"如何调试 Docker开启 Debug 模式检查内核日志Docker 不响应时处理重置 Docker 本地数据如何调试 Docker 开启 Debug 模式 在 dockerd 配置文件 daemon.json（默认位于 /etc/docker/）中添加 { \"debug\": true } 重启守护进程。 $ sudo kill -SIGHUP $(pidof dockerd) 此时 dockerd 会在日志中输入更多信息供分析。 检查内核日志 $ sudo dmesg |grep dockerd $ sudo dmesg |grep runc Docker 不响应时处理 可以杀死 dockerd 进程查看其堆栈调用情况。 $ sudo kill -SIGUSR1 $(pidof dockerd) 重置 Docker 本地数据 注意，本操作会移除所有的 Docker 本地数据，包括镜像和容器等。 $ sudo rm -rf /var/lib/docker Copyright © Zhenhai Gao 2021 all right reserved发布时间： 2024-06-10 23:03:15 "},"docker/appendix/resources.html":{"url":"docker/appendix/resources.html","title":"附录六：资源链接","keywords":"","body":"资源链接官方网站实践参考技术交流其它资源链接 官方网站 Docker 官方主页：https://www.docker.com Docker 官方博客：https://www.docker.com/blog/ Docker 官方文档：https://docs.docker.com/ Docker Hub：https://hub.docker.com Docker 的源代码仓库：https://github.com/moby/moby Docker 路线图 https://github.com/docker/roadmap/projects Docker 发布版本历史：https://docs.docker.com/release-notes/ Docker 常见问题：https://docs.docker.com/engine/faq/ Docker 远端应用 API：https://docs.docker.com/develop/sdk/ 实践参考 Dockerfile 参考：https://docs.docker.com/engine/reference/builder/ Dockerfile 最佳实践：https://docs.docker.com/engine/userguide/eng-image/dockerfile_best-practices/ 技术交流 Docker 邮件列表： https://groups.google.com/forum/#!forum/docker-user Docker 的 IRC 频道：https://chat.freenode.net#docker Docker 的 Twitter 主页：https://twitter.com/docker 其它 Docker 的 StackOverflow 问答主页：https://stackoverflow.com/search?q=docker Copyright © Zhenhai Gao 2021 all right reserved发布时间： 2024-06-10 23:03:15 "},"cicd/":{"url":"cicd/","title":"CI/CD","keywords":"","body":"CI/CDCI/CD 持续集成(Continuous integration) 是一种软件开发实践，每次集成都通过自动化的构建（包括编译，发布，自动化测试）来验证，从而尽早地发现集成错误。 持续部署(continuous deployment) 是通过自动化的构建、测试和部署循环来快速交付高质量的产品。 与 Jenkins 不同的是，基于 Docker 的 CI/CD 每一步都运行在 Docker 容器中，所以理论上支持所有的编程语言。 Copyright © Zhenhai Gao 2021 all right reserved发布时间： 2024-06-10 23:03:15 "},"cicd/actions/":{"url":"cicd/actions/","title":"GitHub Actions","keywords":"","body":"GitHub Actions参考资料GitHub Actions GitHub Actions 是 GitHub 推出的一款 CI/CD 工具。 我们可以在每个 job 的 step 中使用 Docker 执行构建步骤。 on: push name: CI jobs: my-job: name: Build runs-on: ubuntu-latest steps: - uses: actions/checkout@master with: fetch-depth: 2 - name: run docker container uses: docker://golang:alpine with: args: go version 参考资料 Actions Docs Copyright © Zhenhai Gao 2021 all right reserved发布时间： 2024-06-10 23:03:15 "},"cicd/drone/":{"url":"cicd/drone/","title":"Drone","keywords":"","body":"DroneDrone 关联项目编写项目源代码推送项目源代码到 GitHub查看项目构建过程及结果参考链接Drone 基于 Docker 的 CI/CD 工具 Drone 所有编译、测试的流程都在 Docker 容器中进行。 开发者只需在项目中包含 .drone.yml 文件，将代码推送到 git 仓库，Drone 就能够自动化的进行编译、测试、发布。 本小节以 GitHub + Drone 来演示 Drone 的工作流程。当然在实际开发过程中，你的代码也许不在 GitHub 托管，那么你可以尝试使用 Gogs + Drone 来进行 CI/CD。 Drone 关联项目 在 Github 新建一个名为 drone-demo 的仓库。 打开我们已经 部署好的 Drone 网站 或者 Drone Cloud，使用 GitHub 账号登录，在界面中关联刚刚新建的 drone-demo 仓库。 编写项目源代码 初始化一个 git 仓库 $ mkdir drone-demo $ cd drone-demo $ git init $ git remote add origin git@github.com:username/drone-demo.git 这里以一个简单的 Go 程序为例，该程序输出 Hello World! 编写 app.go 文件 package main import \"fmt\" func main(){ fmt.Printf(\"Hello World!\\n\"); } 编写 .drone.yml 文件 kind: pipeline type: docker name: build steps: - name: build image: golang:alpine pull: if-not-exists # always never environment: KEY: VALUE commands: - echo $KEY - pwd - ls - CGO_ENABLED=0 GOOS=linux go build -a -installsuffix cgo -o app . - ./app trigger: branch: - master 现在目录结构如下 . ├── .drone.yml └── app.go 推送项目源代码到 GitHub $ git add . $ git commit -m \"test drone ci\" $ git push origin master 查看项目构建过程及结果 打开我们部署好的 Drone 网站或者 Drone Cloud，即可看到构建结果。 当然我们也可以把构建结果上传到 GitHub，Docker Registry，云服务商提供的对象存储，或者生产环境中。 本书 GitBook 也使用 Drone 进行 CI/CD，具体配置信息请查看本书根目录 .drone.yml 文件。 参考链接 Drone Github Drone 文档 Drone 示例 Copyright © Zhenhai Gao 2021 all right reserved发布时间： 2024-06-10 23:03:15 "},"cicd/drone/install.html":{"url":"cicd/drone/install.html","title":"部署 Drone","keywords":"","body":"部署 Drone要求新建 GitHub 应用配置 Drone启动 Drone部署 Drone 要求 拥有公网 IP、域名 (如果你不满足要求，可以尝试在本地使用 Gogs + Drone) 域名 SSL 证书 (目前国内有很多云服务商提供免费证书) 熟悉 Docker 以及 Docker Compose 熟悉 Git 基本命令 对 CI/CD 有一定了解 新建 GitHub 应用 登录 GitHub，在 https://github.com/settings/applications/new 新建一个应用。 接下来查看这个应用的详情，记录 Client ID 和 Client Secret，之后配置 Drone 会用到。 配置 Drone 我们通过使用 Docker Compose 来启动 Drone，编写 docker-compose.yml 文件。 version: '3' services: drone-server: image: drone/drone:2.3.1 ports: - 443:443 - 80:80 volumes: - drone-data:/data:rw - ./ssl:/etc/certs restart: always environment: - DRONE_SERVER_HOST=${DRONE_SERVER_HOST:-https://drone.yeasy.com} - DRONE_SERVER_PROTO=${DRONE_SERVER_PROTO:-https} - DRONE_RPC_SECRET=${DRONE_RPC_SECRET:-secret} - DRONE_GITHUB_SERVER=https://github.com - DRONE_GITHUB_CLIENT_ID=${DRONE_GITHUB_CLIENT_ID} - DRONE_GITHUB_CLIENT_SECRET=${DRONE_GITHUB_CLIENT_SECRET} drone-agent: image: drone/drone-runner-docker:1 restart: always depends_on: - drone-server volumes: - /var/run/docker.sock:/var/run/docker.sock:rw environment: - DRONE_RPC_PROTO=http - DRONE_RPC_HOST=drone-server - DRONE_RPC_SECRET=${DRONE_RPC_SECRET:-secret} - DRONE_RUNNER_NAME=${HOSTNAME:-demo} - DRONE_RUNNER_CAPACITY=2 dns: 114.114.114.114 volumes: drone-data: 新建 .env 文件，输入变量及其值 # 必填 服务器地址，例如 drone.domain.com DRONE_SERVER_HOST= DRONE_SERVER_PROTO=https DRONE_RPC_SECRET=secret HOSTNAME=demo # 必填 在 GitHub 应用页面查看 DRONE_GITHUB_CLIENT_ID= # 必填 在 GitHub 应用页面查看 DRONE_GITHUB_CLIENT_SECRET= 启动 Drone $ docker-compose up -d Copyright © Zhenhai Gao 2021 all right reserved发布时间： 2024-06-10 23:03:15 "},"github/":{"url":"github/","title":"GitHub","keywords":"","body":"GitHubGitHub Copyright © Zhenhai Gao 2021 all right reserved发布时间： 2024-06-10 23:03:15 "},"database/":{"url":"database/","title":"数据库","keywords":"","body":"Copyright © Zhenhai Gao 2021 all right reserved发布时间： 2024-06-10 23:03:15 "},"database/postgresql/":{"url":"database/postgresql/","title":"PostgreSQL","keywords":"","body":"Copyright © Zhenhai Gao 2021 all right reserved发布时间： 2024-06-10 23:03:15 "},"database/postgresql/logging.html":{"url":"database/postgresql/logging.html","title":"日志设置","keywords":"","body":"PostgreSQL 日志设置Log 日志冗余级别PostgreSQL 常用日志参数查询当前数据库日志配置日志保留周期CSV 日志导入到数据库分析创建日志表CSV 日志加载日志检索查询PostgreSQL 日志设置 Log 日志冗余级别 default：默认 terse：表示更加简单的日志信息 verbose：表示更加冗余的日志信息(即: 附带\"文件名和行数) log_error_verbosity = default # terse, default, or verbose messages 修改后, 重启实例后生效, 结果如下, 可以看到日志信息附带了\"文件名\"和\"行数\"信息 2020-03-02 09:34:41.800 CST [9019] LOG: 00000: listening on IPv6 address \"::1\", port 7433 2020-03-02 09:34:41.800 CST [9019] LOCATION: StreamServerPort, pqcomm.c:593 2020-03-02 09:34:41.800 CST [9019] LOG: 00000: listening on IPv4 address \"127.0.0.1\", port 7433 2020-03-02 09:34:41.800 CST [9019] LOCATION: StreamServerPort, pqcomm.c:593 2020-03-02 09:34:41.801 CST [9019] LOG: 00000: listening on Unix socket \"/tmp/.s.PGSQL.7433\" 2020-03-02 09:34:41.801 CST [9019] LOCATION: StreamServerPort, pqcomm.c:587 2020-03-02 09:34:41.814 CST [9020] LOG: 00000: database system was shut down at 2020-03-02 09:34:24 CST 2020-03-02 09:34:41.814 CST [9020] LOCATION: StartupXLOG, xlog.c:6291 2020-03-02 09:34:41.819 CST [9019] LOG: 00000: database system is ready to accept connections 2020-03-02 09:34:41.819 CST [9019] LOCATION: reaper, postmaster.c:2938 PostgreSQL 常用日志参数 项目 默认值 设定值 说明 logging_collector off on 日志收集功能是否启动 log_destination stderr csvlog 日志收集存储方式 log_directory log pg_log 日志收集存储路径 log_filename postgresql-%Y-%m-%d.log postgresql-%Y-%m-%d_%H%M%S.log 日志文件命名格式 log_timezone RPC RPC 日志时区 log_rotation_age 1440 7d 单个日志文件生存周期，默认1天 log_rotation_size 10240 100MB 单个日志文件大小 log_truncate_on_retation off off log_rotation_age触发切换下一个日志，存在则附加，否则将覆盖 log_min_messages warning warning 日志输出级别 log_min_duration_statement -1 3000 -1表示不可用，0将记录所有SQL语句和它们的耗时，>0只记录那些耗时超过（或等于）这个值（ms）的SQL语句。 log_checkpoints off on 记录Checkpoint信息 log_connections off on 是否记录连接日志 log_disconnections off on 是否记录连接断开日志 log_duration off off 记录每条SQL语句执行完成消耗的时间 log_line_prefix %m[%p] %e: %t [%p]: [%l-1] user = %u,db = %d,remote = %r app = %a 日志输出格式； log_lock_waits off on 控制当一个会话等待时间超过deadlock_timeout而被锁时是否产生一个日志信息。可判断是否存在锁等待问题 log_statement none ddl 控制记录哪些SQL语句。可选值：none=>不记录、ddl=>Create table之类的、mod=>DML语句、all=>记录所有 log_line_prefix 参数说明 %a = application name 应用名称 %u = user name 用户名称 %d = database name 数据库名称 %r = remote host and port 远程主机与端口 %h = remote host 远程主机 %p = process ID 进程号 %t = timestamp without milliseconds 时间戳格式 %m = timestamp with millisecond 时间戳格式 %n = timestamp with milliseconds (as a Unix epoch) 时间戳格式 %i = command tag 命令标签 %e = SQL state SQL语句状态 查询当前数据库日志配置 select name,setting,short_desc from pg_settings where name like 'log_%'; 日志保留周期 通常我们会对日志进行定期保留以保证不会撑爆磁盘容量，此时需要考虑日志保留周期。 核心参数： 项目 默认值 设定值 说明 log_truncate_on_retation off off log_rotation_age触发切换下一个日志，存在则附加，否则将覆盖 log_rotation_age 1440 7d 单个日志文件生存周期，默认1天 log_rotation_size 10240 100MB 单个日志文件大小 每分钟创建文件，保留1小时 log_destination = 'csvlog' logging_collector = on log_directory = 'log' log_filename = 'postgresql-%M.log' log_truncate_on_rotation = on log_rotation_age = 1min log_rotation_size = 100MB 每小时一个文件，保留一天 log_destination = 'csvlog' logging_collector = on log_directory = 'log' log_filename = 'postgresql-%H.log' log_truncate_on_rotation = on log_rotation_age = 1hour log_rotation_size = 100MB 每天一个文件，保留一个月 log_destination = 'csvlog' logging_collector = on log_directory = 'log' log_filename = 'postgresql-%d.log' log_truncate_on_rotation = on log_rotation_age = 1day log_rotation_size = 100MB 每个月一个文件，保留一年 log_destination = 'csvlog' logging_collector = on log_directory = 'log' log_filename = 'postgresql-%m.log' log_truncate_on_rotation = on log_rotation_age = 1month log_rotation_size = 100MB 每天一个文件，保留一年 log_destination = 'csvlog' logging_collector = on log_directory = 'log' log_filename = 'postgresql-%m-%d.log' log_truncate_on_rotation = on log_rotation_age = 1day log_rotation_size = 100MB CSV 日志导入到数据库分析 创建日志表 CREATE TABLE postgres_log ( log_time timestamp(3) with time zone, user_name text, database_name text, process_id integer, connection_from text, session_id text, session_line_num bigint, command_tag text, session_start_time timestamp with time zone, virtual_transaction_id text, transaction_id bigint, error_severity text, sql_state_code text, message text, detail text, hint text, internal_query text, internal_query_pos integer, context text, query text, query_pos integer, location text, application_name text, PRIMARY KEY (session_id, session_line_num) ); CSV 日志加载 \\copy postgres_log from ‘' with csv; 日志检索查询 // csv日志区间范围 select min(log_time),max(log_time) from postgres_log; // 模糊检索字段信息 select log_time,database_name,user_name,application_name,message from postgres_log where message like '%duration%'; Copyright © Zhenhai Gao 2021 all right reserved发布时间： 2024-06-10 23:03:15 "},"database/postgresql/backup-restore/":{"url":"database/postgresql/backup-restore/","title":"备份/恢复","keywords":"","body":"Copyright © Zhenhai Gao 2021 all right reserved发布时间： 2024-06-10 23:03:15 "},"database/postgresql/backup-restore/wal-g.html":{"url":"database/postgresql/backup-restore/wal-g.html","title":"WAL-G","keywords":"","body":"WAL-G for PostgreSQL数据备份基础备份WAL 备份/还原数据还原恢复 S3 上备份的数据参考WAL-G for PostgreSQL WAL-G 是一款开源数据库 wal 管理工具，提供了高性能的 wal 备份/还原能力，为了能更深入的介绍 WAL-G，我们先聊聊 WAL-E. WAL-E 是由 Heroku 公司设计的 PostgreSQL 备份工具，基于 Python 开发。基于 PostgresSQL 的连续归档和 PITR 能力，WAL-E 主要有以下几个功能： 在 archive_command 中设置 wal-push，将 WAL 文件压缩保存到第三方存储系统中(通常是S3)。 在 restore_command 中设置 wal-pull，PostgresSQL 可以在恢复模式下从第三方存储系统中获取 WAL。 通过 backup-push/catchup-push 创建全量/增量的 BaseBackup，实现数据库的 Clone (类似于 pg_basebackup)。 通过 backup-fetch/catchup-fetch 获取全量/增量的 BaseBackup，实现数据库的恢复。 WAL-G 使用 Golang 重写了 WAL-E 的所有功能，并且进行了大量优化，相比 WAL-E 有以下优势： 4倍以上的性能提升（作者 Blog 中提到，WAL-E 的主要瓶颈在于需要通过PIPE实现多进程的数据流） 支持 LZ4，LZMA，Brotli 等多种压缩算法，默认使用 Brotli 对多线程有更好支持 支持 Postgres/MySQL/MariaDB/MSSQLServer/MongoDB/Redis 等数据库 兼容 WAL-E 的数据格式 支持非独占的创建 Basebackup（non-exclusive base backups） 官方给出的WAL-E和WAL-G性能对比： 名称 平均吞吐 标准差 中位数 WAL-E 323Mb/s 236 307Mb/s WAL-G 838Mb/s 4.2 838Mb/s 数据备份 基础备份 WAL-G 主要通过手工或者定时任务的方式创建 BaseBackup，并在有需要时从 BaseBackup 将数据库恢复到指定目录 创建基础备份 WAL-G 支持远程连接到 Postgres创建 BaseBackup，此时 WAL-G 通过 replication 的方式连接数据库，Postgres 需要在 pg_hba.conf 中添加相应的权限 创建一个BaseBackup，并且推送到S3中： wal-g \\ --pghost xx.xx.xx.xx \\ --pgport 5432 \\ --pgdatabase postgres \\ --pgsslmode require \\ --pguser postgres \\ --pgpassword xxxxxx \\ --aws-s3-force-path-style true \\ # minio对S3协议的兼容配置 --walg-s3-prefix s3://wal-g/postgres-ins \\ # wal-g表示minio上的bucket名称，postgres-ins存储路径 --aws-endpoint http://minio.example.com \\ # s3连接地址 --aws-access-key accesskey \\ # minio 认证信息 --aws-secret-access-key secretaccesskey \\ # minio 认证信息 backup-push --full 执行完毕后登录到S3，可以看到生成的BaseBackup以及对应元数据文件： WAL 备份/还原 WAL-G 备份和还原 WAL 的操作主要通过 PostgreSQL 来完成，参考 PostgreSQL 官方文档中PITR的说明，用户可以在 PostgreSQL 中指定以下内容来设置WAL-G 备份配置： archive_mode: 'on' archive_timeout: 300s archive_command: 'envdir /etc/wal-g.d/env wal-g wal-push %p' 还原配置： restore_command: 'envdir /etc/wal-g.d/env wal-g wal-fetch \"%f\" \"%p\"' 上述配置中： postgres 运行在 Master 状态时，会调用 archive_command 归档 wal 文件。 postgres 运行在 Recovery 状态时，会调用 restore_command 恢复 wal 文件。 数据还原 恢复 S3 上备份的数据 通过 BaseBackup 文件可以还原数据库，执行以下命令查看 S3 上的 BaseBackup 文件 wal-g \\ --aws-s3-force-path-style true \\ --walg-s3-prefix s3://wal-g/postgres-ins \\ --aws-endpoint http://minio.example.com \\ --aws-access-key accesskey \\ --aws-secret-access-key secretaccesskey \\ backup-list 指定要恢复的BaseBackup名称，即可在指定目录还原数据库文件： wal-g \\ --aws-s3-force-path-style true \\ --walg-s3-prefix s3://wal-g/postgres-ins \\ --aws-endpoint http://minio.example.com \\ --aws-access-key accesskey \\ --aws-secret-access-key secretaccesskey \\ backup-fetch /home/postgres/pgdata base_000000020000000000000268 参考 https://github.com/wal-g/wal-g https://wal-g.readthedocs.io/#configuration Copyright © Zhenhai Gao 2021 all right reserved发布时间： 2024-06-10 23:03:15 "}}